[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.16.0","content-config-digest","cfb64f3785a45daf","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://olivergilan.com\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":{\"type\":\"shiki\",\"excludeLangs\":[\"math\"]},\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":true,\"transformers\":[]},\"remarkPlugins\":[],\"rehypePlugins\":[],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true,\"allowedDomains\":[]},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false,\"failOnPrerenderConflict\":false,\"svgo\":false},\"legacy\":{\"collections\":false}}","blog",["Map",11,12,23,24,34,35,45,46,56,57,67,68,78,79,88,89,99,100,110,111,120,121,131,132,142,143,153,154,164,165,175,176,186,187,197,198,207,208,217,218,228,229,238,239,248,249,259,260,270,271],"how-to-create-a-blog-in-hugo",{"id":11,"data":13,"body":19,"filePath":20,"digest":21,"deferredRender":22},{"title":14,"slug":11,"date_published":15,"description":16,"thumbnail":17,"tags":18},"How to Create a Blog from Scratch with Hugo",["Date","2022-03-03T00:00:00.000Z"],"Hugo is a static site generator built in Golang. Fast compile times and a powerful templating engine makes it a powerful option for creating sites like a blog.","Hugo_SSG.png",[],"import Aside from '../components/Aside.astro';\n\nIn this post I'll walk you through creating the personal blog you're currently reading using Hugo. When choosing my stack for this blog I had a few requirements in mind: low maintenance, high performance/low bundle sizes, simple clean interface with reusable components, and markdown support. Hugo meets all these requirements with blazing fast compile times as well as no reliance on JavaScript or other libraries that could lead to bloated bundles. It supports a ton of different themes but also has the ability to create very simple themes from scratch with reusable components. And it supports markdown which is my preffered method for writing blog posts. So all I need to do is write a new post in markdown, add it to a specific directory, and push to GitHub and Hugo will generate the necessary html to be served.\n\nFor the purposes of this blog I'll use GitHub actions to generate the site and host it on GitHub pages.\n\n## Getting Started\n\nTo get started [install Hugo](https://gohugo.io/getting-started/installing). I'm on Mac so I used Homebrew:\n```Shell\nbrew install hugo\n```\n\nOnce it's installed use the hugo cli to scaffold a new site for you.\n\n```bash\nhugo new site blogname\n```\n\nYou now have the scaffolding for a new site! You can run the site locally using `hugo server` but you won't see anything just yet! Let's create our site!\n\nAt this point you can add an existing theme to your site but I will create me own. Keep in mind, I didn't use a theme because I wanted to create something ultra simple and creating it from scratch helps me understand how Hugo works in greater detail. If you want to create a more complex site or you just want to create something fast I recommend starting with a theme and you can always modify it later but at least you have a base to start from. You can view a list of themes [here](https://themes.gohugo.io/) and choose one you like. Download the theme's source code and add it the `themes` directory of your site. Then initialize git.\n\n```bash\ncd blogname\ngit init\ngit submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke\n```\n\nAnd set the theme in the config.toml file.\n\n\n```toml\ntheme = \"ananke\"\n```\n\nLike I said, I didn't use a theme so I will leave my themes directory empty and create a site from scratch.\n\nNow let's set some of the key settings in our configuration file. Open the `config.toml` file and set your baseUrl, language, and title. For me, the title of my blog is simply my name.\n\n```toml\nbaseURL = 'https://olivergilan.com/'\nlanguageCode = 'en-us'\ntitle = 'Oliver Gilan'\n```\n\n## Hugo Core Concepts\n\nIt's important to understand the directory structure of Hugo. The scaffolding generator for Hugo created a few important directories to understand. The themes directory as previously mentioned handles all the code.\n\n* `content/` handles all the content of your site. This is where I'll be putting my markdown files for my blog.\n\n* `layouts/` will hold your html files that are used to render the content for any given page. This is where we will create the templates for our site.\n\n* `static/` holds your static files like custom css files or javascript files we might want to reference from our layouts.\n\nHow you structure your content within these directories will determine how Hugo generates your site. For example, for my blog I only want a couple pages: I want\n\n1. A homepage which will act as my \"About\" page\n2. A blog page that lists all my posts in chronological order\n3. A page for each blog post\n\nSo in my content directory I create a `blog/` directory and an `_index.md` file. Within the blog directory I will put each post as a markdown file. This very post that you're reading now is located at `content/blog/CreateABlogWithHugo.md`.\n\nIf you want more pages, create more directories. For example if you want your \"About\" to be separate from your homepage create an `about/` directory next to `blog/`. If you want a contact page create a `contact/` directory. Each directory under `content/` tells Hugo to generate a page of some sort to render that content.\n\n\u003CAside>\n**FYI:** To create a new markdown file in content, use the CLI command `hugo new [path]`\nfor example: `hugo new blog/firstpost.md`\nThis generates the markdown file preloaded with front matter fields that you can fill in.\nThis generator uses the file in `archetypes/default.md` as a template. You can add more fields in that template file to suit your needs. I left it as is for now.\n\u003C/Aside>\n\nBecause my site is simple I decided to keep all my css in one file but you can of course split it up. Add any CSS or JS files you want to the `static/` directory. I added mine to `static/css/style.css` as well as the fonts my site will use to `static/fonts/`. You can of course load your fonts from an external service like Google fonts but I choose to serve them with my site.\n\nSo now you have some content in your content directory and you have your css, javascript, or any other static files in your static directory. Now let's actually build the template files that tell Hugo how to render your content!\n\n## Building the Template\n\nThe first part of the template I want to build is the navigation bar. This will be present on all of the pages in my site and won't change. To get started create the following files within the layouts directory:\n\n`layout/_default/baseof.html`\n\n`layout/partials/header.html`\n\n`baseof.html` will be the base template that holds the other templates. You can think of this as the root component in a framework like React. All that I'll put in that file is the following:\n\n\n```html\n\u003C!DOCTYPE html>\n\u003Chtml>\n\t\u003Chead>\n\t\t\u003Cmeta charset=\"utf-8\" />\n\t\t\u003Clink rel=\"stylesheet\" href=\"/css/style.css\" />\n\t\t\u003Ctitle>{{ block \"title\" . }} {{ .Site.Title }} {{ end }}\u003C/title>\n\t\t{{ block \"head\" . }} {{ end }}\n\t\u003C/head>\n\t\u003Cbody>\n\t\t\u003C!-- Code that all your templates share, like a header -->\n\t\t{{ block \"main\" . }}\n\t\t\u003C!-- The part of the page that begins to differ between templates -->\n\t\t{{ end }} {{ block \"footer\" . }}\n\t\t\u003C!-- More shared code, perhaps a footer but that can be overridden if need be in -->\n\t\t{{ end }}\n\t\u003C/body>\n\u003C/html>\n```\n\nYou can see I link to the stylesheet here so that every other page has access to the css. The parts that say `{{ block [name] }}` tell Hugo to render another layout in that location. If Hugo cannot find an appropriate layout to render in place of a block statement it will fallback to the default which you can set by adding any content you want between the beginning of the block and the `{{ end }}` statement. Notice how in the `\u003Ctitle>` tag I tell Hugo to render the site's title as the default. `.Site.Title` will evaluate to whatever you set as the title in the config file.\n\nNow let's implement the header component. Notice that it's located in a directory called \"partials.\" In Hugo a partial is a reusable component that can be plugged into any layout in a similar way to a React component.\nIn `header.html` add the following code:\n\n```html\n\u003Cheader>\n\t\u003Cnav>\n\t\t\u003Ca href=\"{{.Site.BaseURL}}\">\n\t\t\t\u003Ch1 class=\"site-title\">{{ .Site.Title }}\u003C/h1>\n\t\t\u003C/a>\n\t\t\u003Cul class=\"section-list\">\u003C/ul>\n\t\u003C/nav>\n\u003C/header>\n```\n\n### Working with Menus\n\nNotice how in the above header partial I don't actually have the unordered list implemented. I could of course manually create each `\u003Cli>` element and point it to the designated page but I'd rather have Hugo dynamically render that menu for me. This makes it easier to update in the future.\n\nWe can do this with some updates to the config of the site. Add the following:\n\n```toml\nsectionPagesMenu = \"main\"\n```\n\nThis tells Hugo to take every section page of the site and create menu called `main` . The only section page I have right now is for my `content/blog/` directory so right now Hugo has one menu `main` with an element for that blog page. We can make the partial use that dynamic menu with the following code:\n\n\n```html\n\u003Cheader>\n\t\u003Cnav>\n\t\t\u003Ca href=\"{{.Site.BaseURL}}\">\n\t\t\t\u003Ch1 class=\"site-title\">{{ .Site.Title }}\u003C/h1>\n\t\t\u003C/a>\n\t\t\u003Cul class=\"section-list\">\n\t\t\t{{ range .Site.Menus.main }}\n\t\t\t\u003Cli class=\"section-item horizontal-list\">\n\t\t\t\t\u003Ca class=\"section-link small-thick\" href=\"{{.URL}}\"\n\t\t\t\t\t>{{.Title}}\u003C/a\n\t\t\t\t>\n\t\t\t\u003C/li>\n\t\t\t{{ end }}\n\t\t\u003C/ul>\n\t\u003C/nav>\n\u003C/header>\n```\n\nThis takes the `main` menu and for each item in it renders a `\u003Cli>` tag with a link to that page's URL and it's title.\n\nBy default Hugo pluralizes the titles which I do not want because I want the menu to say `Blog` not `Blogs`. To disable the pluralization add the following to your config file:\n\n```toml\npluralizelisttitles = false\n```\n\nI also want to add more links to external sites such as my GitHub. Hugo can't automatically add that to the menu because I don't have a page for it but I can manually add it through the config with the following:\n\n\n```toml\n[menu]\n[[menu.main]]\n\tidentifier = \"github\"\n\tname = \"GitHub\"\n\ttitle = \"GitHub\"\n\turl = \"https://github.com/olivergilan\"\n```\n\nThis manually adds another element to the main menu so that it gets rendered using the given title and url fields. Now if I ever want to add, remove, or update an element on my navigation bar I can just quickly edit my config file without modifying the html code.\n\n### Target Blank\n\nOne last feature I want to add is to open certain links in a new tab. If a user clicks a link to my blog page or any other page within my site it should navigate within the same tab but if a user clicks my GitHub link I want it to open in a new tab so they can easily switch back to my site if they want to. This can be achieved by adding the following code:\n\n\n```toml\n[menu]\n[[menu.main]]\n\tidentifier = \"github\"\n\tname = \"GitHub\"\n\ttitle = \"GitHub\"\n\turl = \"https://github.com/olivergilan\"\n\t[menu.main.params]\n\t\ttargetBlank = true\n```\n\n\n```html\n\u003Cheader>\n\t\u003Cnav>\n\t\t\u003Ca href=\"{{.Site.BaseURL}}\">\n\t\t\t\u003Ch1 class=\"site-title\">{{ .Site.Title }}\u003C/h1>\n\t\t\u003C/a>\n\t\t\u003Cul class=\"section-list\">\n\t\t\t{{ range .Site.Menus.main }}\n\t\t\t\u003Cli class=\"section-item horizontal-list\">\n\t\t\t\t\u003Ca\n\t\t\t\t\tclass=\"section-link small-thick\"\n\t\t\t\t\thref=\"{{.URL}}\"\n\t\t\t\t\t{{ with .Params.targetBlank }}target=\"_blank\"{{ end }}>\n\t\t\t\t\t\t{{ .Title }}\n\t\t\t\t\t\u003C/a>\n\t\t\t\u003C/li>\n\t\t\t{{ end }}\n\t\t\u003C/ul>\n\t\u003C/nav>\n\u003C/header>\n```\n\nThis adds a paramer to that specific menu item with name `targetBlank` and value `true`. Then within the partial for each menu item I check if it has that parameter and if it does I add the `target=\"_blank\"` attribute to the href element. This will make the link open in a new tab! Now I have a working navbar/header! I can add it to my `layouts/defaults/baseof.html` file so that it appears at the top of every page on my site and add some css to style it how I want.\n\n```html\n\u003C!DOCTYPE html>\n\u003Chtml>\n\t\u003Chead>\n\t\t\u003Cmeta charset=\"utf-8\" />\n\t\t\u003Clink rel=\"stylesheet\" href=\"/css/style.css\" />\n\t\t\u003Ctitle>{{ block \"title\" . }} {{ .Site.Title }} {{ end }}\u003C/title>\n\t\t{{ block \"head\" . }} {{ end }}\n\t\u003C/head>\n\t\u003Cbody>\n\t\t{{ partial \"header\" . }}\n\t\t\u003C!-- Code that all your templates share, like a header -->\n\t\t{{ block \"main\" . }}\n\t\t\u003C!-- The part of the page that begins to differ between templates -->\n\t\t{{ end }} {{ block \"footer\" . }}\n\t\t\u003C!-- More shared code, perhaps a footer but that can be overridden if need be in -->\n\t\t{{ end }}\n\t\u003C/body>\n\u003C/html>\n```\n\nUsing `{{ partial \"header\" . }}` tells Hugo to look in the partials directory, find the file with that name and render it. Don't forget the period after the partial name, that's not a typo. That period passes in the current context so when the code within the partial uses `.Site.Title` or `.Site.Menus...` it's doing so with that context being passed in. And now we have a working header with a navigation menu that can be reused on every page!\n\n### Post Page\n\nSo now you've got the scaffolding of your site created and you have a navigation bar that will appear at the top of every page. Let's spend some time creating the template for each blog post as this is where people will be spending the most time on your site.\nCreate a new file `layouts/blog/single.html`. This will be used by Hugo to render individual pages in the blog section of the site.\n\nThis is the code I have in my template:\n\n```html\n{{ define \"head\" }}\n\u003Clink rel=\"stylesheet\" href=\"/css/post.css\" />\n{{ end }} {{ define \"main\" }}\n\u003Csection id=\"main\">\n\t\u003Ch1 id=\"title\">{{ .Title }}\u003C/h1>\n\t\u003Csection class=\"post-metadata\">\n\t\t\u003Ch4 id=\"date\">{{ .Date.Format \"Mon Jan 2, 2006\" }}\u003C/h4>\n\t\t\u003Ch5 id=\"wordcount\">{{ .WordCount }} Words\u003C/h5>\n\t\u003C/section>\n\t\u003Cdiv>\n\t\t\u003Carticle id=\"content\">{{ .Content }}\u003C/article>\n\t\u003C/div>\n\u003C/section>\n{{ end }} {{ define \"footer\" }} {{ partial \"footer\" . }} {{ end }}\n```\n\nPretty straightforward but to quickly go over it. Each \"define\" block implements one of the \"block\" statements in the `baseof.html` file we created earlier. The head block allows me to inject custom properties into the pages head tag. In this case I made a separate css file for css relating only to blog posts and I link that here. Then in the main block I create the post itself. Notice how I use varriables like .Title, .WordCount, .Content, and the .Date.Format function. These are all provided by Hugo automatically. For example the beginning of this blog post has the following Front Matter:\n\n\n```markdown\n---\ntitle: \"How to Create a Blog from Scratch with Hugo\"\n\ndate: 2022-02-05T10:04:15-05:00\n\ndraft: true\n---\n```\n\nThat \"title\" field is then used by Hugo for the .Title variable when rendering the page for that post. The Content parameter takes whatever I wrote in the Markdown file and generates the blog page's content from it. Everything else here is pretty much standard. You can open dev tools in chrome and look at what sort of elements get rendered from your markdown and then just use css to style your blog posts however you'd like.\n\nBecause this is a technical blog one of the important elements for posts will be the inclusion of code blocks. Adding code blocks can be achieved in Hugo using [Shortcodes](https://gohugo.io/content-management/shortcodes/). Hugo has a built-in [Highlight](https://gohugo.io/content-management/syntax-highlighting/#highlight-shortcode) shortcode that can be used to add syntax highlighting to a block of code in your markdown file (can also be activated using code fences instead of the shortcode tag). In my opinion the highlight shortcode is a bit limited: it will highlight your code but that's it. When I have a code block I want to optionally include the filepath for that code block and you might want to include other things like a \"Copy to Clipboard\" button. To do that we need to create our own shortcode!\n\n### Shortcodes\n\nA shortcode is a simple snippet inside a content file that Hugo will render using a predefined template. Within the layouts directory create shortcodes directory and add the following file:\n\n```html\n\u003Cdiv class=\"code-block\">\n\t{{ with .Get \"file\" }}\n\t\u003Cdiv class=\"filepath\">{{.}}\u003C/div>\n\t{{ end }}\n\t\u003Cdiv class=\"code\">{{ .Inner | markdownify }}\u003C/div>\n\u003C/div>\n```\n\nNow in my content markdown files if I want a code block I can use\n```markdown\nThis is a normal paragraph...\n{{\u003C/* code file=\"optional/file/path\" */>}}\n{{\u003C/* highlight markdown */>}}\n// Code goes here\n{{\u003C/* /highlight */>}}\n{{\u003C/* /code */>}}\n```\n\nI can pass in an optional \"file\" parameter and if it exists Hugo will render that div with class \"filepath\" that I can style how I want. The inner code within the shortcode gets processed through the markdown renderer using the `markdownify` function. Because shortcodes can nest within each other, the .Inner content still gets the the built-in Highlight shortcode so my custom shortcode acts as a wrapper extending the native functionality.\nNotice how my shortcode is literally called \"code\" and that's because of how I named the shortcode html file. Name the file whatever you want that specific shortcode to be.\n\nDon't forget to customize how Hugo styles the code syntax by updating your config file.\n\n```toml\n[markup]\n  [markup.highlight]\n    anchorLineNos = false\n    codeFences = true\n    guessSyntax = false\n    hl_Lines = ''\n    lineAnchors = ''\n    lineNoStart = 1\n    lineNos = false\n    lineNumbersInTable = true\n    noClasses = true\n    style = 'dracula'\n    tabWidth = 4\n```\n\nAnd there you have it! A little bit of styling and you can have a custom code block or any other custom markdown element.\n\n### Footer\n\nFor the footer I created another partial with a custom menu in the config for the different social elements.\n\n```html\n\u003Cfooter>\n\t\u003Cdiv class=\"socials\">\n\t\t{{ range .Site.Menus.socials }}\n\t\t\u003Ca\n\t\t\tclass=\"section-link small-thick\"\n\t\t\thref=\"{{.URL}}\"\n\t\t\t{{with\n\t\t\t.Params.targetBlank}}\n\t\t\ttarget=\"_blank\"\n\t\t\t{{end}}\n\t\t>\n\t\t\t{{ with .Params.icon }}\n\t\t\t\u003Cimg class=\"social-icon\" src=\"{{.}}\" />\n\t\t\t{{end}}\n\t\t\u003C/a>\n\t\t{{ end }}\n\t\u003C/div>\n\t\u003Cp>&copy {{ dateFormat \"2006\" now }} {{ .Site.Title }}\u003C/p>\n\u003C/footer>\n```\n\n\n```toml\n[menu]\n[[menu.socials]]\n    identifier = \"github\"\n    name = \"GitHub\"\n    title = \"GitHub\"\n    url = \"https://github.com/olivergilan\"\n    [menu.socials.params]\n        targetBlank = true\n        icon = \"/icons/github.png\"\n\n[[menu.socials]]\n    identifier = \"linkedin\"\n    name = \"LinkedIn\"\n    title = \"LinkedIn\"\n    url = \"https://linkedin.com/in/oliver-gilan/\"\n    [menu.socials.params]\n        targetBlank = true\n        icon = \"/icons/linkedin.png\"\n\n```\n\nIn the above \"socials\" menu, the items have a custom icon parameter that contains the path to the icon for that element within the `static` directory.\n\nThis time I don't want the footer on every page, only on my blog post pages. So instead of adding this to the base template I add it to my single page template for the blog section. If you scroll up to the code block above you'll see I define the \"footer\" block and declare the footer partial in that block. Now it'll be added to every blog post.\n\n### Header Anchors\n\nOne nice feature on a lot of blogs is having anchors for different sections of individual posts. If you look above this paragraph at this section's heading you'll see the \"#\" tag which is clickable and if you look at the URL you'll notice it now contains that header in it. This allows you to link to a specific section of a webpage. Hugo has a feature called [Markdown Render Hooks](https://gohugo.io/getting-started/configuration-markup/#markdown-render-hooks) that makes adding these anchors easy. For a more in-depth explanation of how this works check out [this post](https://pavelkorolev.xyz/blog/2020-10-31-hugo-header-anchors/) by Pavel Korolev.\n\n\n```html\n\u003Ch{{ .Level }} id=\"{{ .Anchor | safeURL }}\">{{ .Text | safeHTML }}\n{{- if and (ge .Level 1) (le .Level 6) }}{{\" \" -}}\n\u003Ca class=\"anchor\" href=\"#{{ .Anchor | safeURL }}\">\n    #\n\u003C/a>\n{{- end -}}\n\u003C/h{{ .Level }}>\n```\n\n## RSS\n\nAdding an RSS feed to the site is really quite simple with Hugo. Hugo has a default RSS template but it doesn't quite fit my needs because I want to only have blog posts on the feed and nothing else. By default Hugo creates a feed for each section of your site but in my case I only want one feed for the root of my site and I only want it to contain pages from the blog section. To do this I followed this [awesome post](https://benjamincongdon.me/blog/2020/01/14/Tips-for-Customizing-Hugo-RSS-Feeds/) by Benjamin Congdon.\n\n## Compiling and Hosting\n\nWhen it comes to compiling and hosting I want it to be as simple as possible. I don't want to spend time in the future messing around with all this infra or manually copying files to servers, etc. Because I'm hosting this whole repository in GitHub I just used [GitHub Actions](https://github.com/features/actions) to build my site. To do that just create the following file:\n\n\n```yaml\nname: github pages\n\non:\n    push:\n        branches:\n            - main # Set a branch to deploy\n    pull_request:\n\njobs:\n    deploy:\n        runs-on: ubuntu-20.04\n        steps:\n            - uses: actions/checkout@v2\n              with:\n                  submodules: true # Fetch Hugo themes (true OR recursive)\n                  fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod\n\n            - name: Setup Hugo\n              uses: peaceiris/actions-hugo@v2\n              with:\n                  hugo-version: \"latest\"\n                  # extended: true\n\n            - name: Build\n              run: hugo --minify\n\n            - name: Deploy\n              uses: peaceiris/actions-gh-pages@v3\n              if: github.ref == 'refs/heads/main'\n              with:\n                  github_token: ${{ secrets.GITHUB_TOKEN }}\n                  publish_dir: ./public\n```\n\nOnce you add this file to your repo and push it to GitHub it automatically creates a workflow that executes the above job. The job runs every time there is a new change pushed to the master branch of the repo. The Job first checks out the latest commits of the master branch, installs Hugo, compiles the site, then pushes the compiled static files to the gh-pages branch of the repository.\n\nThis is great because it means whenever I want to make a change to the site, whether that's changing code or just adding a new blog post, I simply need to push the change to my master branch and it'll automatically rebuild the site and push the new build to the gh-pages branch.\n\nFor hosting I want to keep it simple as well so I'm just hosting my site on [GitHub Pages](https://pages.github.com/). In the settings for my repository I set the gh-pages branch to be the source for the served pages and I add my custom domain so that people can access the site with my custom URL.\n\n## Conclusion\n\nAnd that's it! Now I have a functioning blog that I can add new features to and expand whenever I want. It's incredibly simple and minimal, no themes or bloated JavaScript frameworks (actually no JS at all as of right now), and it fits nicely into my existing workflows.","src/posts/001-how-to-create-a-blog-in-hugo.mdx","94c7eeedf1c120dd",true,"work-life-balance",{"id":23,"data":25,"body":31,"filePath":32,"digest":33,"deferredRender":22},{"title":26,"slug":23,"date_published":27,"description":28,"thumbnail":29,"tags":30},"Is Work-Life Balance Worth It?",["Date","2022-07-27T00:00:00.000Z"],"In the debate of work-life balance versus work-life integration it seems as though balance is winning out over passion as more and more people view life as the hours spent between clocking in and clocking out. Why is this viewpoint dominating and does it lead to a fulfilling life?","The_Blacksmith.jpg",[],"I recently read a [tweet](https://twitter.com/shelbyn_23/status/1549944330646949890?s=20&t=a8NQKrJuA61IW0TGunCV0A) expressing exasperation with the standard 8-9 hour workday and how little time it leaves for life outside of work. Coincidentally the same day I came across this [beautiful essay](https://every.to/p/what-i-miss-about-working-at-stripe) by Brie Wolfson about her nostalgia for her time working at Stripe. What Brie misses most was the long workdays, the stress, the cameraderie, and being part of a group of people giving their all towards achieving a shared mission. These two distinct viewpoints reflect a difference in attitude toward work-life balance that I've seen take shape in \"the discourse\" online and even among friends & family. The former viewpoint believes that work is simply a means to an end for money, purely transactional, and that \"life\" is supposed to be lived outside of work. The latter viewpoint views work as an integral part of one's life and that attemping to bisect the two is not a recipe for a happy life.\n\nIt often feels as though my generation predominantly agrees with the former view of work-life balance while I personally believe that to live a fulfilled life one must seek work-life *integration*. When I see tweets like the one above it makes me wonder if my belief is correct and if it is then why do so many people feel the opposite? Why do so many view work as some punishment or inconvenience that must be endured so that they can live their \"real\" lives after? The mindest of work-life integration can be an ideal that's not available to everyone but most of the individuals in my social circle that try to separate work and life are in white collar jobs with more leverage as employees than most people. It's easy to say people are just more lazy in this day and age but that seems like a cop-out to me and the more I think about this issue the more I feel that _the work-life balance attitude is the natural result of various environmental incentives._\n\n## Caring Doesn't Pay\nMy first instinct regarding this issue is too many people in my generation have seen others get burned (or they themselves got burned) by caring about work too much. Brie talks about late nights full of tears, stress, and joy. She mentions cancelling a vacation after her manager asked because her colleagues were working 15 hour days and she didn't want to abandon them. The opportunity to work with a team of people you highly respect and throwing your all into a shared mission with them as Brie describes is a prospect I'm very drawn to and I firmly believe everyone should experience that at some point in their life. And yet it's probably more common than not that after dedicating your blood, sweat, and tears to a company you still get fucked over. Maybe there's a market downturn and you get laid off because of poor decisions by leadership; maybe the startup simply fails; or maybe it succeeds/ gets acquired and liquidation preferences leave you with little to no reward for your equity. The vast majority of statups are not financially rewarding for anyone other than the founding team so purely from a financial standpoint it can be irrational to dedicate your life to one.\n\nBut startups are unusual in their own right! Even if they aren't completely financially rational there's a ton to be gained through connections, reputation, and skills that you can pick up by dedicating yourself at the right startup. Most people that emphasize work-life balance aren't in that situation and probably work at an enterprise where many of those upsides are less prevalent and there is even less incentive to care about the work. During my time at Microsoft I could have been the most productive engineer in the world and the bottom line for Microsoft wouldn't have changed. Or I could have died and the bottom line for Microsoft wouldn't have changed. When you are so far removed from the result of your labor and the outcomes are so detached from the personal inputs there's very little incentive to find meaning in the work. Marx called this phenomenon alienation, and while a revolution by the working class is probably not an appropriate nor effective solution, it's still a very real result of working for many of these massive corporations. Enterprises also fail to create environments of agency in most cases. Orders come down from \"the top\" with little input from ICs and more often than not opportunities to take \"ownership\" are really just an excuse by a manager to shift more responsibilities downwards without doing the same for the associated upside and rewards.  \n\nThe result is that a vast swath of workers view passion for their job as irrational and even dowrnright risky. As it is now even if you work yourself to the bone and deliver real value to a business there's a good chance you'll be passed over for a promotion due to political reasons or the company will prioritize bringing someone external to fill a role above you instead of hiring internally. It's hard to speak on behalf of other industries on this specific topic but at least in tech it can be far more rational to jump jobs every [2-3 years](https://developerpitstop.com/how-long-do-software-engineers-stay-at-a-job/#:~:text=Around%2050%25%20of%20software%20engineers,developer%20stays%20in%20one%20role.) than it is to stay at one company for an extended period of time. How is someone supposed to foster a deep understanding and affinity for their work if they are incentivized to leave every couple years? How are they supposed to be passionate about a mission if they're treated as expendable?\n\n## Work Has Changed, Work Hasn't Changed\nBeyond poor work environments and bad leadership there's also the fundamental problem that most work is just [bullshit](https://en.wikipedia.org/wiki/Bullshit_Jobs). The world is full of interesting problems and disciplines to master and I'm lucky that I get to work on my craft of software engineering every day. Meanwhile when talking to friends the majority of their day-to-day responsibilities include things like copying rows from an email to an Excel document, shifting images on a PowerPoint slide to be *just* right, or compiling reports with little creative contribution. There's two things that strike me about their descriptions of work:\n1) Most of this work could be automated or at least dramatically minimized\n2) It accomplishes very little of value\n\nWork will feel dull when the nature of the work is dull. This is obvious and yet I'm constantly shocked by how many companies will go through great pain to hire the \"best and brightest\" from the most prestigious universities only to then have them spend their days copying rows from emails into Excel documents. There is an abundance of low hanging fruit for many businesses to reduce toil and unlock the creative productivity of their employees which would make many of these jobs more fulfilling and exciting, not to mention more valuable. If you work as an \"analyst\" in investment banking and your 15 hour days consist of putting meetings on the calendar for your boss you're a lot more likely to feel disdain for your job than if you're given tasks that involve actual analysis, creativity, and even risk-taking. In many ways this is a direct result of poor leadership that doesn't understand how to value the skills of their employees nor how to build systems at scale for reducing toil.  \nSecondly, many of these bullshit jobs do not accomplish much of value which is often the real killer of morale. Many barista jobs can be automated too but they often get to see the direct result of their work by making drinks, becoming familiar with regulars, and directly providing a service many people find valuable. It doesn't surprise me that I more often meet a barista who enjoys their work than I do a junior investment banker. Most white collar jobs have not adapted to the age of information and unlocked the creative productivity most of their employees have ot offer. \n\nThere's also the issue of the workday itself. When productivity was a direct result of time spent on the assembly line a 9-5 workday made sense but when work requires creative or analytical time spent at a desk only marginally results in higher output. There's simply no reason for many white collar information jobs to require employees to sit at a desk for 8 hours a day and yet a shockingly small amount of companies even try to experiment with different working schedules that may better fit their employees' lives. I do think this argument is sometimes taken too far with people claiming that any more than 3 hours a day of creative work is a waste which misses the point that most people-- especially those early in their career-- cannot do 3 hours of productive work without a lot of \"wasted\" time inbetween. There's also the fact that not all work work done in a creative job is creative. As a programmer no matter how productive I can be writing code or debugging a problem there's still a lot of work to be done around planning, coordination, and team building. Brie talks about working 15 hour days which is fine and well when you are at an early stage startup trying to solve an ambitious problem and the mountains to climb seem never-ending. But most companies are not in that situation and making employees commute an hour each way in traffic to sit at a desk for 8 hours to only do 2 hours of productive creative work is not a good strategy to make people passionate about their jobs.\n\n## The Burdens of Adulthood\nBad work environments and boring jobs aren't where the problems end either. It also feels as though we have less time today than we had in the past. I am extremely fortunate to work as a software engineer in tech where employees have more leverage than normal. I can work from home and set my hours in a way most people can't and yet even I often feel overwhelmed keeping up with the responsibilities outside of work e.g. cleaning my apartment regularly, doing my laundry, excercising, buying groceries and cooking for myself, cleaning dishes, etc. Just taking care of the bare necessities often takes up most of my time outside of work and that's not even taking into account time spent with friends, leisure, hobbies, etc. Modern life is so full of [time taxes](https://www.theatlantic.com/politics/archive/2021/07/how-government-learned-waste-your-time-tax/619568/) just for daily survival that sometimes it feels like too much for one person to handle... and it might be.\n\nIn 1960 women were predominantly getting married [around the age of 20](https://www.bgsu.edu/ncfmr/resources/data/family-profiles/hemez-distribution-age-first-marriage-fp-20-09.html#:~:text=In%201960%2C%20men's%20median%20age,FP%2D19%2D06) and men around 22. Today those averages are at [28 and 29](https://www.prb.org/usdata/indicator/marriage-age-women/snapshot/#:~:text=The%20median%20age%20at%20first,across%20states%20and%20local%20areas) years old respectively. It's not an exaggeration to say that people today shoulder the burden of adulthood alone for far longer than they have in the past. Similarly in 1960 [about half](https://www.pewresearch.org/fact-tank/2015/12/30/its-no-longer-a-leave-it-to-beaver-world-for-american-families-but-it-wasnt-back-then-either/#:~:text=As%20more%20mothers%20enter%20the,%2Dat%2Dhome%20dads) of mothers were stay-at-home mom's whereas today that number has dropped below 30%. The cumulative effect is that historically an individual could work 8-9 hours a day but many of the responsibilities of adulthood outside of work were lessened by the contribution of a spouse while today even with a spouse there's a good chance no one is staying home with the time to handle non-work responsibilities.\n\nWhat becomes evidently clear is that when women won their battles for equality and entered the workforce en masse they weren't *getting* jobs they were *switching* jobs. Even just in 2019 if American women were paid minimum wage for the time they put into housework they would have earned [$1.5 trilltion](https://www.nytimes.com/interactive/2020/03/04/opinion/women-unpaid-labor.html), a staggering amount. This is in modern times when the housework performed by women is a fraction of what it used to be. It's not unreasonable to posit that because we did not value the labor of women monetarily and did not count it towards any of the metrics we use to judge the health of the economy we completely missed the fact that there was this massive amount of necessary labor being performed to support fulfilling lives. Of course the answer is not to make women return to these jobs-- the gender of the person performing the housework is irrelevant-- but this work still needs to be done and now more people are shouldering that burden alone for longer.\n\n## What Can Be Done\nSo what can be done? I still believe the opportunity to enjoy one's work and to find meaning in it is critical for a fulfilling life and we should do everything we can to change the incentives. Whether it's on an individual level, company level, industry level, or even government level there's plenty of things we can do to shift the cost-benefit of most of these jobs in a way that makes them more fulfilling and motivating. Not only would that make our society happier on average (which we desperately need) I suspect it would lead to greater productivity gains for the economy as a whole.\n\n#### __Change the costs of showing up__\n- 4 day work weeks, 10-3, variable work hours, etc. There's plenty of room to experiment with different work schedules that better fit people's lives and do not sacrifice on creative/analytical output\n- Build better public transportation and denser cities to make it faster and easier to work in person. Pretty much every city in America besides New York requires a car to live and work but sitting in traffic and commuting for hours automatically makes the cost of showing up for work higher. Remote work has helped in this regard but ultimately young people who are passionate about their jobs will want to work in person even for a couple days a week and to be frank the logistics around working in person are terrible for most of America. \n\n#### __Create a culture of loyalty and respect__\n- Prefer internal promotions over external hires\n- Invest in employee development. If an employee leaves your company at the same level they joined that should be viewed as a failure in most instances. This means real investment in training and education beyond just online seminars or a Pluralsight subscription.\n- Pay more, give better benefits. Pay is a sign of respect and should accurately reflect how valuable an employee is to an organization without that employee needing to employ Machiavellan negotiation tactics\n\n#### __Improve the quality of work itself__\n- Reduce toil with tech automation and give the existing workforce more creative/analytical responsibilities\n- Promote agency with flatter org structures and more ownership. Create opportunities for employees to take risks and benefit more from the wins\n\n#### __Reduce people's overall economic risk__\n- Start offering internships for high school students and invest in on-the-job education. Instead of people entering the workforce at 22 years old with thousands of dollars of debt we should consider the benefits of them joining the workforce out of high school, debt free, especially when most of the skills will be learned on the job regardless of whether they have a degree or not. This needs to be driven by the businesses and there's a whole bunch of caveats to making a dynamic like this work but it's possible. This is a whole other post I will write about in the future but there's a *lot* of room to change peoples economic outlook by changing the structure of the education-to-work pipeline.\n- Make healthcare cheaper and separate from employment. Healthcare is one of the biggest spending categories for people in America. By making it cheaper you automatically make most people richer by some degree and by detaching from employment status you empower employees to more readily bad jobs and either take risks making their own companies or joining companies that they are passionate about.\n- Make housing cheaper. By making housing cheaper across the board you enable people to more readily move and organize themselves physically in localities where they can meet people with interests such as theirs. If we want people to dedicate themselves to shared missions it's important that they can work and live near others with a similar mindset. Just between cheaper housing and healthcare you will give employees a ton of leverage to leave bad jobs and find other people working on missions they find meaningful.\n- Provide better paid parental leave and childcare. Right now the cost of raising a family and doing much of the important housework is simply too high. We need find a way to reward the massive amount of unpaid labor being performed at home. \n\nFor each of these changes there will be caveats and unintended consequences but what we do know is that whatever we're doing right now isn't working. People find meaning in life when they can dedicate themselves to a mission whether that's raising children, becoming a champion of a sport, writing a novel, mastering a craft, etc. While not necessary, most missions people dedicate themselves to are directly economically productive and thus become jobs and that's a good thing because when groups of people work together they can often accomplish far more than what an individual ever could. I view the trend to try and separate work from life as a failure on the part of our society and we should work on all levels to fix the incentives. Empowering people to live a life of meaning means more than just making them happy in a corporate job but there's also little reason why more corporate jobs can't be more [compelling](https://theoatmeal.com/comics/unhappy).","src/posts/002-work-life-balance.mdx","a3107cd45a1af013","internal-knowledge-systems",{"id":34,"data":36,"body":42,"filePath":43,"digest":44,"deferredRender":22},{"title":37,"slug":34,"date_published":38,"description":39,"thumbnail":40,"tags":41},"Internal Knowledge Systems",["Date","2022-10-09T00:00:00.000Z"],"Effective teams consciously engineer how knowledge flows through their organization. For tech teams, building this internal knowledge system requires effective documentation.","Mountain_of_Knowledge.jpg",[],"Whenever a group of people work together there exists between them a flow of information which can ultimately determine how successful that group is at accomplishing a specific mission. Many dysfunctional organizations have broken or inadequate flows of information at their core and make poor decisions because of it. For an organization to succeed at scale it needs to effectively transmit information in multiple dimensions: from its leadership to the individuals at the edges of the organization, from the edges of the org to its leadership, between teams working in tandem, between teams working orthogonally, etc. You can think of an organization of individuals in much the same way as that of a living organism with millions of cells all receiving various signals and pieces of information informing them to act in a certain manner. The organisms that are successful are the ones that get the right signals to specific cells so that they perform the right actions at any given time to benefit that organism. All sorts of information needs to get to the right place at the right time with sufficient accuracy to allow every individual in the organization to make the right decisions at any given point in time. \n\nThe flow of information manifests itself in various ways with the default being tribal knowledge held by individuals. This informal repository of personal knowledge is augmented by internal message boards, company memos, documentation, notes, etc. The vast majority of organizations pay no mind to this dynamic and as a result most information in any given institution is what Samo Burja calls [Intellectual Dark Matter](https://samoburja.com/intellectual-dark-matter/). Successful organizations and functional institutions are aware of their flow of information and take conscious steps to engineer it in a variety of ways. When it comes to startups and tech teams having an explicit formalized internal knowledge system that reduces IDM is crucial for maintaining efficiency and productivity at scale. I am interested in exploring what the ideal system looks like for tech teams in particular and the following is my working theory on what such a system looks like.\n\n## Goals\nThe first step to building an effective internal knowledge system is understanding what the goals are. For different institutions this could mean different things but for my team at Census the goals of creating this system are as follows:\n\n1. __Increase Velocity__  \nIt's almost a clich√© at this point but startups want to move fast. As we scale and add new engineers we want to maintain our productivity and continue to ship high quality code frequently. The faster new members to the team can get set up, grok the codebase, and start contributing the better. Likewise, the faster a team member can look at a new part of the codebase or grasp a new assignment and ship code the more value will be created. \n\n2. __Increase Quality__  \nOftentimes the tradeoff for speed is quality. As we grow we want Census to become _more_ stable and _more_ reliable and _more_ performant all while we add new engineers to the team, create new features, and onboard new customers. To do this while maintaining velocity we need as many engineers as possible to have the relevant information at their fingertips to make informed decisions autonomously.\n\n3. __Reduce Fragility__  \nAs systems and projects become more complex they tend to become more brittle. This is often due to more critical knowledge being known only by a select few individuals who have been there since the beginning and are then relied on when issues arise or changes need to be made. This is an instance of intellectual dark matter and can threaten the long term viability of a project. The sooner this knowledge is formalized and distributed the more pain we can avoid down the line as we scale.\n\n4. __Reduce Mistakes & Errors__  \nAs we scale the goal is to have our usage increase an order of magnitude more than our errors. If you 10x your customer count but only 2x your incidents then your codebase is actually becoming more stable despite an increase in absolute error count. When the project is accurately documented it is easier to spot missing or innacurate details and fix them.\n\n5. __Increase Autonomy__  \nAs more engineers on the team learn and think about the overall state and goals of the project the more they will be empowered to make small but important decisions correctly on their own. This increases the autonomy of the average engineer which increases productivity, increases quality, and creates a more enjoyable developer experience.\n\n## The Effective Internal Knowledge System\nThe term _internal knowledge system_ is fancy and useful when discussing this theoretically but in practicality this is pretty much just a system of documentation. Before I go into how we plan to solve this problem at Census allow me to throw another list at you. When thinking about this problem I've read about and observed many different internal documentation systems and I've seen the problems multiple teams face with them. Below is what I believe to be some key characteristics of an effective system for tech teams.\n\n1. __Declarative__  \nThe documentation should accurately describe the present state and goals of the system it is documenting. The past states of the system should be observable through a versioning mechanism. And above all it should clearly state what the overall goals for the system are so that members of the team are oriented around what changes need to be made to bring the system from its current state to its desired state. \n\n2. __Structured__  \nI used to think it was enough for engineers to just put an effort into writing docs. I now know this to not be sufficient. Documentation needs to be structured in such a way that information has a logical place to live so that other members of the team immediately know where to look to find a given piece of knowledge. \n\n3. __Searchable__  \nDocumentation should be easily searchable. This means that documentation mediums like video or audio tend to do a poor job because it is hard to organize and skim a video for relevant information. You can `ctrl+f` a 10,000 line written document (or 100 10,000 line documents) faster than you can skim a 5 minute video. \n\n4. __Relevant & Versioned__  \nAvoid including everything. The core documentation system should do its best to not drown the signal in endless noise. Ideally when it comes to low level implementation details the code should be self documenting and then just focus on higher level details and the few low level details that really matter. I used to think just documenting everything is the way to go and it might be better to have too many docs than too little but I've come to appreciate knowing when to *not* include something. At the very least there should be a mechanism to easily ignore the cruft and see only the core that matters.\n\n5. __Permissioned__  \nNot everyone should or needs to have access to all the information. This is less relevant at startups but as a company scales the need to partition and segment information becomes crucial. A proper internal knowledge system should make it easy to ensure that only those with proper access can view any given piece of information.\n\n## Implementation\nOkay so how do you actually build an effective internal knowledge system? Well I'm not quite sure but I plan on doing this for Census in the coming months so I'll make sure to write another post explaining how that goes. My working theory so far is as follows: we already have a bunch of documentation but it's scattered and unstructured. Most of it is in Notion but without any organization so the plan is to start there.\n\nI'll begin with an overall directory structure as follows:\n```markdown\n.\n|- Getting Started/\n|- Architecture/\n|--- Infra/\n|--- Module 1/\n|--- ...\n|- Team 1/\n|--- Style Guide\n|--- ...\n|- Team 2/\n|- Team 3/\n|- Ops/\n|--- Planning/\n|----- RFC/\n|----- ...\n|--- Deployments\n|--- Git & Github Workflow\n|--- Logs & Debugging\n|- OnCall/\n|--- Runbook/\n|- Uncategorized/\n```\n\u003Cbr/>\n\nI've intentionally kept out a lot of the subsections for each directory but each top-level directory should have an internal structure as well. You can think of this top level structure as a top-down approach but another approach is to take all your existing documents and group them together as leaf nodes creating gradually bigger groups from the bottom up. I think the latter approach is ultimately the best way to create a good system that fits your specific knowledge but the above structure is a solid generic starting point for most small engineering teams.\n\nMost of it is self-explanatory but to quickly go over it, the `Getting Started` directory should hold all the info for a new member to the team to onboard including things like local environment setup, high level concepts, important tools, git flows, etc. `Architecture` contains information regarding the infrastructure like cloud resources, service diagrams, etc. as well as sections for logical code modules that clearly explain how different parts of the codebase work. Then each team gets its own directory where they can outline team specific style guides, planning sections, common patterns, etc. This works because Census only has 3 engineering teams right now and they all share one repository but these might be unnecessary for your situation. `Ops` holds all the information around... you guessed it, ops! Things like deploying, planning, etc. `OnCall` should have all the information needed for an engineer to successfully manage a week on call. Finally `Uncategorized` is for any docs or info that doesn't immediately fit into one of the existing buckets. This will happen and that's fine; building this system is an iterative process. As the uncategorized information grows we'll create new sections, shift old sections around, and try to reduce the uncategorized queue. \n\nIdeally we'll get to a point where every section and piece of info has a unique number associated with it, different sections have different structured formats to make it easy to write new documents, every piece of information has a specific place to live, and finding any needed piece of information is effortless.\n\nKeep in mind that this won't all happen overnight and these sections will grow and change. Initially it can even be painful to organize the docs because the existing information can feel overwhelming and older members on the team might have muscle memory for where certain information lives even if there's no intuitive reason for it to live there. That muscle memory will be broken and new habits will need to be formed. In the long run it should make life easier though and I'll write a follow-up to examine how this worked for us at Census.","src/posts/004-internal-knowledge-systems.mdx","0344c2c2a9f68b31","prioritizing-efforts",{"id":45,"data":47,"body":53,"filePath":54,"digest":55,"deferredRender":22},{"title":48,"slug":45,"date_published":49,"description":50,"thumbnail":51,"tags":52},"Prioritizing Efforts",["Date","2022-08-26T00:00:00.000Z"],"Working on the right thing is as important as working hard but when a startup is rapidly growing how do you determine where to best focus your efforts?","Strategy.jpg",[],"import Quote from '../components/Quote.astro';\n\nFast, a one-click checkout payments startup was founded in March 2019. In November of that year they raised a $2.5M seed round and then 5 months later they raised a $20M Series A led by Stripe. Their headcount grew rapidly and less than a year after raising their A they raised a monster $102M Series B round. Everything was trending in the right direction and in Februrary 2022 they announced they were looking to double their headcount by the end of the year. 2 Months later the company went bankrupt and shut down. There are many reasons why Fast imploded in such a spectacular fashion and without knowing all the information the best I can do is speculate but I believe their problems stemmed from poor prioritization.\n\nThe most important task for the leadership team of any startup is to effectively prioritize work. Moving fast and being productive isn't enough if it's not going towards solving the right problems and focusing on the wrong problem once or twice could be enough to kill a young company. During the past few years where money was cheap and plentiful there was more room to experiment, pivot, and make mistakes with prioritization but that luxury is over for the foreseeable future. As the funding markets tighten and runways shorten I predict the companies that more effectively prioritize their efforts will win out.\nOn the surface this seems obviously true but in the day-to-day of a startup grind it can be deceptively difficult to know what work is the most important, especially as the company grows and the number of stakeholders-- all with issues most important to _them_-- vie for attention. My CEO at Census gave me the framework for how he deals with the problem of prioritization: __focus on the work that most effectively derisks the grand vision.__\n\nThink of it this way: when starting a company there is inevitably a grand vision for what you want it to become. This vision is what you want the company to look like in 10 years when it's mature and has all the bells and whistles, integrations, market dominance, culture, etc. To get from nothing to that grand vision requires a lot of time and effort and throughout that journey there will be a number of risks that could prevent the vision from ever becoming a reality. Your job as a leader is to discern which risks are greatest at any point in time and focus the efforts of the business on overcoming those risks. As your company grows the amount of risks will generally increase but the severity of any given risk most likely decreases.\n\nFor example, in the beginning when all you have is an idea the biggest risk is that it's just a bad idea. If your idea isn't valuable then it doesn't matter if you do everything else right you will be unsuccessful which is why investors will always ask what sort of market validation you have done. By speaking to potential customers and experts in the field you can overcome this risk by getting an understanding of the market and its needs. But once you overcome that initial risk and you determine there's a need for whatever you want to build then you have another risk: are people willing to pay you for your solution and how much? This is similar to the first step but subtly different in the fact that a lot of people will happily say they need a solution to a given problem and they might even say they're willing to pay for it but when it comes time to fork over money it's a whole different story. Customers happily willing to pay for a product or service is the so-called *Product Market Fit* that every startup wants to achieve and it's the most important risk any new company must overcome initially.\n\nEvery company is different but most startups share some big risks that are worth thinking about:\n- Do people want your product?\n- Will people pay for your product?\n- Can you build the product?\n- Can you manage a growing team?\n- Can you sell to customers?\n- Will you run out of capital?\n- Can you expand the market?\n- Can you capture the market?\n- Can you scale?\n- Can you be profitable?\n\nAs you grow the risks will change and multiply but be less severe individually. Whereas not having PMF can singlehandedly destroy a company later risks such as regulatory risks, culture changes while scaling, technical debt, unit economics, distribution, competitors, etc. are less likely to be the sole downfall of a company. An important distinction is that the _risk_ in question is not necessarily about overall risk to individuals in the company but more about the vision itself. If you're a young but growing company and you get a buyout offer technically the risk to you as an individual would basically be brought to near zero because an exit event like a buyout could result in becoming financially independent and therefore losing personal risk.  Being acquired by the wrong company, however, could mean the original mission is now less likely than ever to materialize. This isn't necessarily a bad thing and the vision for a company can certainly change over time but it's worth keeping in mind when assessing what that real goal is and what efforts should be focused on to best get you there.\n\nSo where do I see people make mistakes with this? I speak to a bunch of young founders and entrepreneurs and quite often they seem to be following a template for building a company: they have an idea, pitch it to investors, give away about 20% of their company to raise an initial seed round, immediately hire a team of engineers and a designer, and then start building. That *might* be the right set of moves to make for your given situation but often times it's really not necessary to do all that. Fundraising is an opportunity to overcome the risk of running out of capital but if you can validate a market, build an MVP, and start generating revenue with little capital then there's not much need to raise money as you're just giving away more equity than necessary. But maybe you don't want to risk your own money when you can risk investor's money and maybe you can't build the MVP on the side while working a full time job so you need some money to pay yourself while you work on a prototype. In that case raise money and eliminate that risk but then there's no need to suddenly hire a whole team. Adding more cooks to the kitchen does *not* make it easier or faster to build a product in the early stages so you should ask yourself: *why am I hiring this person? Is it because I just raised money and feel like this is the \"next step\" or does hiring someone with this skillset genuinely make the odds of success higher than doing something else?* This applies to any area of a business, not just hiring, and it's common to fall into the trap of doing what feels easy. If you're a good at engineering you might think your startup's problems will be solved with cleaner code; if your background is in product management you might think just adding more features or conducting just one more customer interview is always the best path forward; if your background is in operations you might think introducing new processes or increasing headcount is always the best path forward. At any given point in the life of a company one of those strategies might be the optimal one but that analysis should be made irregardless of how comfortable you are in doing that sort of work and focus instead on how much that work will derisk the company.\n\nWhen using this framework a lot of the classic startup advice around moving fast, validating a market, finding PMF, scaling, etc. makes more sense. It also helps to explain, in part, why some companies fail. When Fast announced they were shutting down operations just a little over a year after raising $100M it became clear that leadership had not been appropriately derisking the company. According to [The Information](https://www.theinformation.com/articles/why-stripes-fast-horse-is-losing-the-one-click-checkout-race), Fast's revenue in 2021 was just $600,000 while its burn was $10 million per month! With this context it becomes even more shocking that Fast's CEO and CTO gave an [interview](https://www.businessinsider.com/fast-recruiting-tech-hiring-vicky-xiong-engineering-fintech-payments-2022-2) to Business Insider in February 2022-- just two months before shutting down-- announcing their intention to *double* their headcount by the end of 2022. This was after already doubling their headcount the previous year. I don't have all the information they had so I do not want to judge too harshly from the comfort of my armchair but from where I'm sitting I can't imagine that not having enough engineers was even close to the biggest risk the company faced at that time. In fact the opposite was true: 60% of Fast's operating budget went to payroll making their employees one of their biggest risks instead of the biggest reductions in risk.\n\nAnd then you add-on the expensive corporate retreats, paying The Chainsmokers [$1 million dollars](https://www.npr.org/2022/04/05/1091077398/checkout-startup-fast-is-shutting-down-after-burning-through-investors-money) to perform at a conference, hiring a videographer to follow the CEO around the world to film him skiing, scuba diving, and perform other stunts, all while the engineering team was given a broad array of conflicting tasks [not related to the core mission](https://www.businessinsider.com/fast-startup-employees-domm-holland-overspending-overhiring-chaotic-2022-4). Throwing a sick concert or making the CEO a celebrity influencer did nothing to derisk the mission of Fast and it's telling that so much time and money was put into those efforts instead of things that would have been more effective.\n\n\u003CQuote author=\"Pragmatic Engineer\" link=\"https://newsletter.pragmaticengineer.com/p/the-scoop-fast\">\nOne of the few warning signs engineers noticed is how Fast spent far more on infrastructure than the scale of the operation would have called for. Engineers sometimes brought up suggestions to scale infra down, and save costs - given there was not much revenue generated.\n\u003C/Quote>\n\nI could harp on what I think Fast did wrong (chief among them was their propensity to [overengineer solutions](https://newsletter.pragmaticengineer.com/i/51799618/warning-signs-within-the-company)) but the actual lesson isn't about the specifics of their actions and instead is focused on the fact that their actions did not do much to increase the odds of success. If Fast was a consumer social app then it may have made sense to make the CEO a celebrity or to throw fancy parties to build a brand. Fast wasn't a consumer social app though and their focus on efforts completely unrelated to the performance, user experience, and developer experience led to the shutting down of a company a year after raising $100M.\n\nSo if you're in leadership position of a growing company (at an early stage company _everyone_ is in a leadership position) to best increase the odds of success I recommend identifying the biggest points of risk that threaten the long term vision and then prioritizing your efforts on those areas.","src/posts/003-prioritizing-efforts.mdx","1bf1621768ba8b18","single-threaded-brain",{"id":56,"data":58,"body":64,"filePath":65,"digest":66,"deferredRender":22},{"title":59,"slug":56,"date_published":60,"description":61,"thumbnail":62,"tags":63},"My Brain is Single-Threaded",["Date","2022-11-10T00:00:00.000Z"],"Your brain can only focus on one thing at a time. Multitasking is just an excercise in context switching and the more important a task the costlier it is to switch contexts.","Single_Road.jpg",[],"I used to multitask a lot. My girlfriend in college would enter my room and see me gaming on one monitor, watching NFL Redzone on another, and completing school assignments on my laptop. I've since consciously and aggressively reduced the number of tasks I work on at any given time, especially as those tasks require deeper and more intense focus. This change was a response to a gradual realization that my brain is \"single-threaded\" in nature and any meaningful work requires minimizing costly context switching.\n\nI began really noticing it Junior year of college once I got to higher level maths and programming courses. When completing assignments I often found myself turning off everything including any music playing and working in complete silence, sometimes even with my phone locked away in a drawer if necessary. I was being challenged in a way that required genuine focus without distraction. It's not that I physically couldn't have a football game on in the background it's just if I did I wouldn't have noticed a single thing happening in it and if I did then it meant I had lost my flow state. \n\nIt still wasn't very often when I had assignments that challenged me such as a that so I didn't take much conscious action but then I graduated and joined Microsoft and now Census and it's all different. The scale and complexity of the systems I am working on and the pace at which things change is incredibly rapid compared to school. I'm being pushed so much harder every day than I have the past decade and it's a welcome change. Especially at Census the agency I'm granted and the impact I can have leaves me with a wide open field of extremely creative work and it can only really be done effectively when focusing. \n\nBut what does it mean to be single-threaded? It means that at any given time the processor (your brain) can only make progress on one active task. To work on two tasks at once it needs to switch back and forth. Every time it switches the entire context of what task its working on needs to change. This doesn't matter if the cost for switching contexts is low and for the past decade most of my \"work\" in school has had a low cost. When I would watch football, play games, and do schoolwork it wasn't that I was actually doing all three at once it was simply that the cost of switching my attention rapidly from a game to a tv screen to a worksheet was negligible. In fact if you find that you can switch between activities rapidly without burden it might be a sign that those activities aren't worth doing. Or at least they might not be very *fulfilling.* \n\nI have tried coming up with a good heuristic for what makes a task costly to context switch in and out of but I have been unsuccessful. My best approximation is that the cost to switch contexts increases as the complexity and novelty of the task increases. It has to be sufficiently complex because if it wasn't you wouldn't need to devote your full attention to it but it also needs to be novel. Programming can be extremely complex but because I'm very familiar with it-- it's less novel-- it's easier for me to switch into a programming context. My brain is familiar with  the state of mind required for programming so it's easier to switch from a natural resting state into it. In fact because I program so much the natural resting state of my mind has gotten a lot closer to that of when I'm programming. The times when programming has a high cost to context switch is when I'm analyzing a new system or a new part of the codebase or debugging something and I need to understand all the interactions happening. In other words, when I'm doing something novel. Similarly when writing blog posts such as these it's far more unfamiliar and therefore far more costly for me to switch contexts. It can take hours for me to switch into the right mindset for writing-- it quite literally feels like my neurons are firing in a different direction-- so when I finally get into that flow state if I lose it I'm back to square one. That's a massive cost and it's entirely because writing is unexpectedly complex and it's also not something I do very often. \n\nThere's no real takeaway here, just a development in how I approach work. The more important a task is the more I try to focus only on it. [Solve one problem at a time](https://www.bennadel.com/blog/4352-only-solve-one-new-problem-at-a-time.htm). Get comfortable not jumping around to different tasks even when you hit a dopamine plateau. Get comfortable not looking at your phone in lulls. Learn how to not even think about whether you should look at your phone (that's the hard part). As I've grown more conscious of the single threaded nature of my brain I've realized the need to curate what tasks are running on it more carefully because it's the only way to achieve meaningful deep work that I find fulfilling.","src/posts/005-single-threaded-brain.mdx","50d6587c1c745d49","goals-for-2023",{"id":67,"data":69,"body":75,"filePath":76,"digest":77,"deferredRender":22},{"title":70,"slug":67,"date_published":71,"description":72,"thumbnail":73,"tags":74},"Goals for 2023",["Date","2022-12-11T00:00:00.000Z"],"2023 is coming. The big areas of focus for me in this new year will be career, health, adventure, and mind.",null,[],"New Year's resolutions are mostly corny and not a very good way to achieve the sorts of lifestyle changes that people hope to achieve with them but it is important to set goals and then take time to reflect on your progress towards said goals at a regular frequency. I like to think of my life in terms of chapters or [narrative arcs](https://en.wikipedia.org/wiki/Story_arc) that usually last multiple years and contain different experiences, lessons, and character developments. Thus my goals generally act more as themes for a given arc along with some specific quantifiable milestones that help me track my progress. Once a year is too infrequent to effectively reflect on my progress and update my milestones but the holidays and the turn of the year is nevertheless a good time to take stock of where I am and where I'm headed.\n\nCurrently I'm focusing on the following broad areas of my life.\n- Career\n- Health \n- Adventure\n- Mind\n\nLet's start with my career. I work as an engineer at [Census](https://www.getcensus.com/careers?utm_source=workwitholiver) and I fucking love my job. For the first time since middle school I feel like I'm not only being challenged but the training wheels are off and I get to run full speed. It's really the perfect situation for me. I spend the majority of my time writing new features, fixing and improving our systems, and learning from my founders and colleagues. Everyone I work with has an equally high IQ as well as EQ making it one of the most exciting groups I've ever been a part of and I trust our ability to achieve the mission. Success is not a given here and I wake up every day aware that my actions will have a direct effect on the outcome of the company, an experience that stands in stark contrast to my time at Microsoft. While here I'm meeting some awesome people that I hope to work with in the future even beyond Census and I am gaining the skills to become a far better engineer and founder. It feels like every week I learn something new that will help me down the road when it comes to starting my own company. So this year for my career I want to\n- Get involved with interviewing and hiring\n- Learn about LLMs and how they work because AI might change how my career looks completely\n- The rest of the goals here are redacted ;)\n\nWhen it comes to my health my goals follow from last year. I want to continue healing my gut and putting on the weight I lost during the two years of my illness in 2019-2021. I currently weigh about 145 lbs, up 10 lbs from a year ago, with a height of 5'10 and by next year I want to weigh at least 155 lbs putting me just shy of my 160 lbs body-weight pre-illness. In terms of general fitness I am pivoting from focusing primarily on strength training and instead I want to increase my endurance and stamina as well as my flexibility. Gut health, stamina, and flexibility will be the core foundations upon which I build an unbreakable body. So this year for health I want to\n- Weigh 155 lbs by EOY\n- Run 10 miles at a pace of 8 minutes a mile\n- Be capable of performing a split\n- Perform reps on the ab wheel from a standing position\n\nWhen it comes to adventure I have definitely been disappointed the past few years. COVID robbed two key years of my life and I graduated college a semester early just to have Omicron bar me from traveling throughout Asia as planned. And then I ended up moving to NYC (which was a bit of an adventure) but I grew up around here my whole life. I need to get out of the tri-state area and go see new places, experience different cultures, and meet different people. With COVID gone and my health mostly back to normal I want to put more emphasis on doing fun shit and injecting some chaos into my life before I pick up too many obligations and settle down. My character arc demands it. Having said that my career right now is crucial. I simply cannot be backpacking across Europe or working remotely in Asia while I'm grinding and trying to build something successful at Census. There are other things I can do, though, like\n- Live in San Francisco for a month and work out of Census HQ\n- Travel alone to a country that speaks a foreign language\n- 2-day motorcycle trip across the Moroccan desert\n- Wild card adventure\n\nThe last big area of focus I want to touch on is my mind and more specifically, my communication. This primarily encompasses my writing and this blog (but also on rebuilding the confidence I lost the past three years). I'm happy I started this blog last year and I want to start publishing more often and more consistently. Writing is one of the few things that I simply cannot do while multitasking so to write more consistently I'll have to be more disciplined about dedicating time to step back from everything else that's going on and focus just on writing. This is a net positive. I wish for this blog to be more than just a technical resume-esque website and instead I want it to better reflect my mind and ideas, even the non-technical ones. I want to write about my various interests and what I've learned. I want to worry less about only posting complete thoughts and focus more on just posting what I think is interesting. At the end of the day this blog serves as a public extension of my private journal and I want to increase the surface area of that which I show, NOT because I want to build an audience (this blog literally has zero analytics of any kind and I am not interested in being a \"creator\") but because I think that's what makes the internet interesting. To that end I want to\n- Post at least once a month on this blog\n- Share my writing more publicly\n- Add a blogroll of other independent blogs I am inspired by\n- Write some non-technical posts about topics such as education, my illness, etc.","src/posts/007-goals-for-2023.mdx","7a6d749db3248891","software-crisis",{"id":78,"data":80,"body":85,"filePath":86,"digest":87,"deferredRender":22},{"title":81,"slug":78,"date_published":82,"description":83,"thumbnail":73,"tags":84},"Software Crisis",["Date","2023-01-22T00:00:00.000Z"],"The term software crisis was coined in 1968 to identify the inability of software development to keep up with the rapidly growing usage and requirements of computing. Today the crisis continues with poor software more common than good software and failure more common than success.",[],"import Figure from '../components/Figure.astro';\n\nA couple weeks ago every [flight in the US was grounded](https://fortune.com/2023/01/13/faa-computer-failure-grounded-thousands-flights-caused-2-contractors-introduced-data-errors-notam-system/) due to the meltdown of the FAA's NOTAM  system in the latest large-scale example of the *software crisis.* The term was coined in 1968 to describe the rapidly expanding pace of power and use-cases for computers and the inability of the industry to keep up with the appropriate quality of software. Computers became exponentially cheaper and more powerful and thus the role of software grew but the majority of the software created at the time shared characteristics that defined the crisis: \n- Over budget, behind schedule\n- Frequently never completed\n- Poor performance\n- Difficult to maintain\n- Did not meet the requirements of the end-user\n\nOver the next decades some of the brightest minds in the field set to providing solutions for the crisis and out of those efforts we got a number of new languages, programming paradigms, philosophies, and methodologies. Procedural programming and C brought a paradigm shift in the way programmers reason about and build software. Later Object-Oriented Programming and languages such as Java did the same. Methodologies like waterfall, spiral, rapid, incremental, continuous integration, etc. started popping up all with the aim of taming the complexity and solving the crisis-- or at least a part of it. Then in February 2001 the Agile Manifesto was released and took the industry by storm. Today every software team from the smallest startups to the largest enterprises proudly wave the flag of the Agile development process.\n\nAnd today, 2 decades after the birth of Agile and with further developments such as BDD, TDD, DDD, and every other acronym you can think of, the characteristics of software that marked the crisis are as prevalent as ever. NOTAM melted down because a contractor introduced incorrect data; because the system *let* him introduce that data. Over a million organizations use Microsoft Teams, a basic chat app that constantly crashes, consumes memory, and straight up fails to work on many machines. Twitch, a streaming platform with 31 million users, takes upwards of 10 seconds to render on my 6 year old MacBook. Companies (and the [NSA](https://techbeacon.com/security/nsaarmys-inscom-leaks-top-secrets-aws-bucket-look-ma-no-password)) routinely [expose customer data](https://www.securityweek.com/aws-s3-buckets-exposed-millions-facebook-records#:~:text=The%20company's%20researchers%20identified%20an,%2C%20likes%2C%20and%20Facebook%20IDs.) by forgetting to add authentication to their public AWS S3 buckets. Outdated software keeps people in [prison](https://kjzz.org/content/1660988/whistleblowers-software-bug-keeping-hundreds-inmates-arizona-prisons-beyond-release) when legally they should be free. Browsers have a never-ending appetite for RAM and now desktop apps built on those browser engines have adopted a similar palate. New front-end projects using the most popular frameworks are saddled with dependencies for dependencies for dependencies each one increasing the [surface area](https://www.bleepingcomputer.com/news/security/dev-corrupts-npm-libs-colors-and-faker-breaking-thousands-of-apps/) for attack. Peek into the average enterprise codebase and you'll find hundreds of lines of boilerplate code, unnecessary abstractions-- factories and providers and complex inheritance schemes-- along with dependency injection and a variety of other patterns complicating code so that a useless unit test becomes a little more sane to write. Kubernetes and microservices designed to decouple independent pieces of software now add latency, orchestration complexity, and interface coupling across multiple runtimes and software teams. Large-scale government software systems routinely experience [outages](https://news.ycombinator.com/item?id=34440228), [data leakage](https://krebsonsecurity.com/2022/02/report-missouri-governors-office-responsible-for-teacher-data-leak/), and [exploitation](https://www.cnn.com/2022/05/18/politics/software-bug-warning-vmware/index.html) and the default state for new government software projects is [failure](https://www.standishgroup.com/sample_research_files/Haze4.pdf). The crisis is ongoing.\n\nThe Standish Group conducts a study every year on the state of software development in the industry and publishes a [Chaos Report](https://www.standishgroup.com/sample_research_files/CHAOSReport2015-Final.pdf) with its findings going back to 1994. Agile dominates the industry as the primary methodology employed in most software projects yet the success rates are still dismally low. \n\n\u003CFigure src=\"/images/software_project_success_table.png\" alt=\"Software Project Outcomes Table\" caption=\"Software project outcomes by project size\" />\n\nRead the [full 2015 report](https://www.standishgroup.com/sample_research_files/CHAOSReport2015-Final.pdf) for definitions on project size and resolution status. When the project size is small success rates are high and only a few projects fail. As projects increase in size the success rates drop with a 41% drop just from a small to a moderately sized project.  We built solutions to the problems software development faced in the 1900s but those solutions were outpaced by the requirements of software as it ate the world. The outcomes in the Chaos Report read like an O(n\u003Csup>2\u003C/sup>) algorithm and our efforts to solve the crisis are being dwarfed by the exponential growth in importance and scale of software. \n\nIn retrospect OOP is mostly a bad idea for software at scale (that's for another time) and it's unsurprising that Agile didn't overcome that to solve the crisis. The [original manifesto](https://agilemanifesto.org/) is only 12 principles and 68 words. There's too much room for interpretation and not enough specifics on how it should be applied and used in various software development scenarios. In a sense dedicating effort to solving the crisis mirrors the problem most teams face with tech debt: you don't need perfect software to be successful. You can build the most technically sound application but it won't generate any revenue if it doesn't actually solve a problem and add value to customers. Inversely you can build wildly successful products with horrific code because the bar is so low and people will use something imperfect if it solves their problem over something perfect that doesn't. The startup graveyard is littered with technically sound products that lost because the technically unsound products actually shipped.\n\nThe problem is made worse by the concentration of software engineering talent. As software eats the world its importance in every industry from agriculture to manufacturing to defense to logistics to government elections and beyond is growing but the most talented software engineers are found in the companies focusing exclusively in the world of bits and predominantly in the big tech companies. It makes sense for engineers to aim for those companies: regardless of the pay, lifestyle, and status, (all of which are significant by the way) those big companies were once small companies pushing the boundaries of technology and revolutionizing the world with new search engines, operating systems, social graphs, etc. Now a top engineer going to work for Google will utilize their talents far less than if they modernized the software used in global shipping instead. Startups push the needle on this problem of talent concentration but they do little to address the hundreds of legacy companies and industries that affect our everyday lives and need software talent. There may not even *be* enough software talent to address the needs of all those companies and any solution to the software crisis will have to address that.\n\nProgress is being made. Firebase, Supabase, and Pocketbase bring backends and databases to the world of front-end devs and full-stack frameworks like NextJS, SvelteKit, Remix, etc make it easy to build and manage an application of decent scale with just a couple engineers. User-friendly cloud platforms like Heroku, Digital Ocean, Render, Fly.io, and others have removed the deployment complexities of small projects so teams can focus more on the product and less on the infrastructure. The tools to build software at a small scale are better than ever catalyzing an explosion in the number of individuals and small teams building profitable products. These improvements, however, are confined to building small-scale, highly focused, software-only products focused on solving specific tasks and have not affected the outcomes of software at scale. The scale and requirements of the software needed in enterprise and nation-scale systems is a whole different beast and gains in small-scale software development haven't translated over. \n\nIf 90% of bridges built collapsed before they were finished the world would look very different than it does today yet 91% of medium sized software projects fail and our industry treats this as normal. Just as competent engineering teams should dedicate time to address technical debt so too should our industry re-acknowledge the ongoing crisis and dedicate efforts to solving it. We need solutions that allow for consistent success in developing good software at scale in our most important industries. That might start by creating an industry-wide definition for what *good* software even means. I have no big answers but I have conviction that this problem of software development can be solved. There won't be a silver bullet that can address software creation in every scenario but the majority of software systems can surely be classified into a handful of categories with best practices and methodologies for each. Likely those methodologies that work best for each scenario already exist and what's required is the synthesis of these ideas into frameworks for management, engineering, and design along with the subsequent education and adoption by the industry at large.","src/posts/009-software-crisis.mdx","e49567087d8bf9bb","where-no-code-fails",{"id":88,"data":90,"body":96,"filePath":97,"digest":98,"deferredRender":22},{"title":91,"slug":88,"date_published":92,"description":93,"thumbnail":94,"tags":95},"Where No-Code Fails",["Date","2022-12-22T00:00:00.000Z"],"No-Code tools like Webflow, Bubble, Adalo, etc. are all the rage these days. Despite this I believe they all have a fundamental problem to overcome: if they are simple enough for non-engineers to use they aren't powerful enough but if they are powerful enough they become too complex and a real engineer will most likely just use code instead.","nocode.jpg",[],"I read [this](https://github.com/getlago/lago/wiki/Post-mortem-of-our-1st-YC-startup:-a-Reverse-ETL) postmortem today from a YC company that pivoted from their first idea as a no-code reverse-ETL tool. The post was interesting to me for a couple of reasons:\n\n1) My current company [Census](https://getcensus.com) is in the same space trying to solve the same problem they  pivoted away from\n2) The problem they ran into that ultimately led to their pivot is a problem I believe exists more generally for a number of companies specifically in the no-code space. \n\nRegarding (1) Census actually ran into the same wall they hit but we have a very exciting solution that we are actively shipping and we're confident this will turn into one of our greatest strength as a product. I'd like to write a post about that but for now I want to focus on (2) and it's how I see this problem affecting no-code tools that exist today. The problem is this: no-code tools are sufficiently complex that non-engineers are unwilling or incapable of effectively using them while engineers are unwilling to use them because they don't actually make our lives significantly easier where it matters.\n\nNo-code isn't a new concept with products like Wordpress, Squarespace, Wix, Shopify, etc. pioneering the space in different ways. Historically, though, these tools focused on static sites or domain specific problems such as e-commerce. Recently there's been a crop of new VC-funded tools like [Webflow](https://webflow.com/), [Bubble](https://bubble.io/), [Thunkable](https://thunkable.com/), [Adalo](https://www.adalo.com/), and many more that aim to allow for the creation of general web and mobile apps with much more complex lifecycles and abilities. They're interesting and they show promise but I believe they operate in an uncanny valley-esque situation where they don't actually solve the hard part about building apps making them too difficult for most non-engineers and not useful for existing engineers leading to their TAM being quite small.\n\nI first noticed this problem with tools designed to simplify the building of tech in high school. Both of my parents own small businesses and I have watched them on more than one occasion struggle to build websites through Squarespace and Wix. It didn't matter that those tools were barely more than templates with customizable sections-- not even flexible enough to be called drag-and-drop-- it was still a challenge for them. After spending hours on a site they'd end up with dark font on dark backgrounds, overflowing paragraphs and images, misaligned buttons, etc. I consider both my parents to be smarter than average yet they are certainly not technical and those no-code tools to build simple static pages were still not easy enough. I'm not sure either of them would stand a chance with Bubble or Webflow which indicates to me that neither would at least half the population. Beyond just writing the code there are patterns and concepts around building a functional site that they didn't understand at the time which meant their ability to use these no-code tools effectively was limited. In the end they both had someone else build the sites for them. \n\nSince then both my parents have become more tech-literate and they've actually become quite capable at times especially when using things like Canva and Wix so I do not think these tools were failures-- their success financially is well established-- it's just that at the end of the day they are used to build simple products. Creating an average web app with the features and capabilities expected by users today is an order of magnitude more complex than creating a static site with Wix. It may be that in time individuals like my parents will learn the concepts around building web apps and be able to use a no-code tool like Bubble effectively but I'm not convinced if for no other reason than because most people have no idea how to model data.\n\nFundamentally when you take away all the implementation details my job as a software engineer is to design a system to solve a specific problem under certain constraints. This amounts pretty much entirely to:\n1) Defining the shape and transformations of the data model\n\t- What data is required versus optional?\n\t- What do inputs and outputs look like?\n\t- How does the data transform throughout its lifecycle? \n\t- What relationships exist within the data model?\n2) Defining the characteristics of the system to allow for the necessary data model within our constraints\n\t- What security is necessary?\n\t- What availability and uptime is required?\n\t- What performance is expected?\n\t- What failure modes are acceptable?\n\t- What should costs be?\n\nThe de-facto way to do the above tasks today is to write code, usually lots of it, which is complex and error-prone and yet it's flexible and expressive and has had decades of smart people creating new languages and libraries and tools to help perform those tasks as easily as possible. I haven't used a no-code tool that measurably improved my ability to perform any of the above tasks and they often make it harder. Often there's no clear data modeling part of the tool at all; if there is then you're probably limited on what types you can use or define. How the data is transformed and manipulated is not easily defined. Properties of the end-system like security and performance and errors are almost always non-existent. Performance and availability are usually just straight up functions of cost for what plan you're using on a given tool and lack granularity.\n\nThe end result is that the difficult part about building full-fledged applications-- the reasons why software engineers get paid so much-- isn't any easier which means it's still a massive barrier to entry for someone who isn't used to doing that sort of engineering. And for someone who is used to doing that sort of engineering it's not a great value prop because that person probably already knows how to code and doesn't find that to be their primary roadblock. To them the no-code tool becomes just another framework or language they need to learn to implement the system they're envisioning and it's less expressive and more proprietary with less skill-transfer than what they're used to.\n\nNo-code isn't destined to fail forever, though. There is certainly a type of person who is smart enough to model these systems and yet doesn't know how to code or who does know how to code but doesn't like to/isn't very good who will find great value in these tools. I just think that's probably a smaller market than most people realize and the success of these tools hinges upon expanding that slice of people. They can do that by trying to attract more non-programmers and teaching them the requisite knowledge around building systems (hard!), or attracting existing engineers by making their tools powerful enough to model systems as robustly as regular code (also hard!). It's this second possibility that excites me, though, especially with things like GPT. As mentioned, writing code is slow, error prone, complex, and hard to maintain. It's a *distraction.* I can envision a future where software engineering is quite literally just defining the properties of the system and a mix of AI and program synthesis does the work of actually implementing it. Lastly, I think for existing engineers no-code holds an interesting possibility in the front-end space. If I could design an entire front-end in a visual builder such as Figma but also have the tooling to seamlessly hook it up to my backend, manage state properly, handle data fetching, etc. then I think that has a chance to be wildly successful but nothing I've tried really nails this yet. \n\nNo-code has a future but I do not think it looks like the current rendition of what we're seeing. At a certain level writing actual code isn't the hard part around building apps and these tools need to lean more into empowering engineers to model their systems effectively while being interoperable. In the end I suspect the winners of this space will be much more low-code than no-code.","src/posts/008-where-nocode-fails.mdx","40ee907d0119ac8e","i-was-wrong",{"id":99,"data":101,"body":107,"filePath":108,"digest":109,"deferredRender":22},{"title":102,"slug":99,"date_published":103,"description":104,"thumbnail":105,"tags":106},"I Was Wrong",["Date","2022-12-04T00:00:00.000Z"],"Notes on the rise of AI and large language models.","d2_neural_net.png",[],"I'm pretty proud of the fact that last year around October I pulled out of my crypto positions and largely switched my stance regarding the technology. For months at every party and get-together with other tech folks I was the only one in the room voicing my skepticism about the industry. I have been vindicated for the time being but the victory is sour because as I was excitedly exploring crypto to its natural conclusion I was neglecting and horribly mistaken about an adjacent industry: AI. When AI started to build hype around 2012 with things like IBM's Watson and then Google Deepmind it was very exciting. I did Google's machine learning course and learned the concepts behind those networks but came away unimpressed. It felt like powerful curve fitting with some very narrow applications but it certainly wasn't anywhere close to general intelligence. Nevertheless the hype grew and startup after startup popped up with \"AI\" in the name promising magical results. Most of these startups weren't even attempting to use neural networks to solve their problems-- a fact that more than one founder has openly admitted to me-- and the hype didn't seem to be leading anywhere. \n\nThat doesn't mean there weren't cool results; there certainly were but they were mostly academic or they seemed to be indicative of Moore's law and how far computing had come as opposed to some fundamentally new type of software. AI became a buzzword and anyone using it was either talking about social media recommendation engines, self driving, or straight up bullshitting. Sometimes all 3.\n\nSo I lost interest. It seemed like unjustified hype and then it seemed to plateau for a number of years and every time someone brought up the idea of AI to me I dismissed it and its potential impact. Candidates like Andrew Yang ran on a platform of increasing automation and how AI would replace jobs and I simply didn't buy it. I still don't fully buy it, for what it's worth, but I now see a viable path to mass automation (whether this is catastrophic for workers or instead creates more abundance than humanity has ever seen is yet to be seen). Whenever it was brought up it was in the context of AGI or solving self driving, two problems that weren't even remotely close to being solved but in dismissing those usecases I completely missed the slow and steady progress taking place in the field. Then things began rapidly and consistently changing with the release of GPT-3.  \n\n### GPT & The Rise of LLMs\nGPT-3 was released in June of 2020 and it was obviously different than any other \"AI\" I had seen. It's capability to respond to a variety of prompts and the quality of the responses was clearly on a different level even though it was still limited. It did fail for certain topics and was happy to spout impressive-sounding babble that didn't actually mean anything and any attempt to have an ongoing conversation would quickly break down. Still, it forced me to step back and ask: is this going to change the world? My response at the time was no because of GPT-3's obvious limitations and my implicit assumption that we were in for another decade-long plateau in the power of these models. \n\nThen DALL¬∑E was released at the start of 2021 and a year later DALL¬∑E 2 and I was blown away by it's ability to understand certain concepts and synthesize images based off that. It was the first time I began to wonder if maybe there was some fundamental understanding of concepts happening in these models. But I thought to myself: this is impressive but is it practical? How expensive is it to train such a model? How accessible is this tech really? But then Midjourney and Stable Diffusion followed quickly after which blew that notion away. Now ChatGPT-- which is basically just the GPT-3 model with some filters and context tracking-- has displayed a level of intelligence and understanding that I never thought I'd see from a machine in my lifetime. And to top it all off, GPT-4 is rumored to be almost ready and is expected to be as a big a leap from GPT-2 to GPT-3. It's safe to say my implicit assumption of a plateau in AI tech was wrong and things seem to instead be speeding up. \n\nAdmittedly at the time of writing I don't actually know how these models work at all. Back in the machine learning craze about 8 years ago I did some Google machine learning courses and learned the concepts around those systems. From what I've heard basically everything from back then is outdated and these systems operate under completely different principles. It's very possible we're not even scratching the surface of what these new models are capable of and this may just be the beginning of exponential growth in capability for LLMs. Such a thought is truly frightening.\n\nIt's worth mentioning that I *still* don't believe these models are conscious, whatever consciousness even is, but this brings me to my second mistake. I didn't believe we were headed to general intelligence in the sense that we could create a computer that thinks like a human but that's sort of missing the forest for the trees. If GPT becomes 10x more powerful than it is today it doesn't really matter if it's \"conscious\" or not because it'll still be capable enough to perform a bunch of human functions and significantly affect the structure of society as we know it. In fact the whole question of consciousness has started to feel ancillary and while I have my theories around where consciousness comes from and how it can possibly be created in a machine it all feels largely irrelevant right now. It seems to be the case that consciousness is not a prerequisite for intelligence and instead the opposite is probably true. \n\n### Emergence of AI & Crypto\nAs an aside, I find it amusing that we are seeing this emergence of AI in parallel with the emergence of crypto. Both technologies started with niche groups of highly technical individuals building new technology to solve a problem. During the last crypto cycle, though, we saw it really grab hold with \"finance bros\" and entrepreneur types; the type of person who likes the bling and flashiness of a place like Miami and envisions a future where they are the founder of the next big consumer social startup. This isn't a knock against anyone of such description but the result was that everyone I knew in crypto fell into two buckets: extracting as much wealth as possible through financial market mechanisms like arbitration (or outright scams if they werent technical) or they were desperately trying to build the big usecase for crypto. Social apps, gaming, emerging market loans, ads, etc. Especially near the end it felt like everyone had an idea on how to make crypto useful in the real world and everyone wanted to claim that throne. \n\nIn contrast, the AI space still feels overwhelmingly technical. It's as though the entrepreneur-lifestyle type of person who 6 years ago would have started a company with AI in the name just to attract investors has since pivoted to crypto and they haven't yet pivoted back. Maybe they're burnt out from going all in on an industry that doesn't seem like it'll pan out, maybe higher interest rates prevents this behavior, or maybe they just haven't caught on yet to whats been happening with with these new models but everyone I know who's interested in AI is interested in building the models themselves not in end-user applications. As a result I think there's a lot of alpha to be had right now in building the actual customer-facing tools powered by the models instead. We will absolutely see a massive crop of AI startups in the immediate future but for now the low hanging fruit is all still there. \n\n### Pitfalls of AI Startups\nI do think there are some pitfalls to watch out for if you plan on creating a product built around AI. The first is with the models themselves. GPT is incredibly impressive yet obviously limited and prone to just making stuff up or spitting out senseless babble. It would be a challenge to trust its output with anything critical but also using an automated system to sanitize or correct the output is very difficult because it's generally completely unstructured. \n\nSecondly, and the biggest risk in my opinion, is the platform risk of relying on a company like OpenAI. We just saw how a company as big as Facebook could be brought to its knees because of the decision by executives at Apple. Building on top of GPT would represent an even bigger platform risk than that and absolutely needs to factor in to any business decision and it's something that should scare the shit out of any startups trying to use OpenAI's tools. The way around this is to only use open source models like Stable Diffusion and Midjourney-- but there's no guarantee there will be any comparable open source models for something like GPT-4 and later models-- or to just accept the risk and dedicate a significant amount of revenue and resources to building your own models right from the start. I'm willing to bet we'll see a *lot* of AI companies that end up being successful going that route. If you can start with GPT and build a valuable product and start generating revenue you can then use that revenue to build in-house models that let you deleverage the platform risk. That's easier said than done, though. It remains to be seen how easy building such models will be. It's possible that once it's demonstrated that such a model can be built it then becomes easy to reproduce and that most of the cost is in the initial research and experimentation. \n\nThere's a third less obvious risk but it's that the space might simply be moving too fast to reliably build a customer-facing product. Maybe GPT-4 comes out and you immediately start building a product powered by it. A year later you've shipped the first version and acquire some customers but then another year later GPT-5 comes out and completely commoditizes your abilities. Would you be able to simply upgrade models? Are they plug-and-play? It's probably not so straightforward which means that building right now introduces a risk of becoming outdated very quickly. This is a pretty unique risk but one that should be considered. \n\n### Evaluating Potential AI Startups Ideas\nOne of the interesting phenomenons I've noticed with GPT and other LLMs is they are extremely impressive and yet it is very difficult to envision just how these models can be or might be used. The obvious low hanging fruit is there: AI profile pictures and picture book illustrations with DALLE, musical lyrics, poetry, different flavors of chatbots with GPT, etc. Those are certainly valid usecases yet none of them are venture-scale and I've had trouble of thinking about what can be done that *is* venture-scale. I've been using the following framework to evaluate what sort of products and businesses would work well with a GPT-like model:\n\n**Domain w/ Clear Boundaries**\nAvoid completely open ended domains like \"browsing the internet.\" This just feels like a problem space that is too vast to reliably and consistently engineer these models to handle properly. If you are going to build an AI product to browse the internet instead have it focus only on a select number of websites and with a set number of actions. A digital assistant could reliably navigate to Google Calendar and manage a schedule. Then again, if it's too simple of a domain then you *probably* don't even need an LLM and would see better results with just plain ol' software. Going back to the previous example, once you've captured user intent it's trivial to use Google Calendar's API to just automate someone's calendar without any AI involved. \n\n**Pick Your Edge Cases Wisely**\nAny domain that is simple enough to not have any edge cases might be too simple to justify using something like GPT. Therefore you probably want to pick a domain with some type of long tail of edge cases but you should evaluate these cases very carefully and pick the problems where the edge cases aren't critical. This is why I don't like self driving as a problem space. There's a seemingly infinite number of edge cases and getting it wrong on any of them can lead to catastrophic outcomes. Similar with something like a therapy chatbot. You only need it to mess up once and it creates dramatic harm. \n\n**Reduce Scarcity**\nOne funny observation about GPT, DALL-E, Stable Diffusion, etc. is that so far they've really only reduced the scarcity of things that are alread post-scarcity. Sure making digital art more accessible reduces its scarcity but it's not like there was a drought of good artists. Similarly generating 1 paragraph blurbs isn't exactly reducing the scarcity of anything. Even at its best generating song lyrics or poems etc. isn't dramatically reducing the scarcity of whatever its generating. It's not as though you can't be successful making music using GPT and you can probably even make a GPT-based product designed to help musicians but it doesn't feel like a very defensible position and it also won't change the world. Of course, changing the world is overrated and not everything has to be venture-scale but for the sake of this excercise it's worth keeping in mind.\n\nSo the real question going forward is: can this product effectively reduce the scarcity of something with extreme value? And can it do that by effectively navigating a clearly defined domain consistently enough with much greater efficiency than human counterparts? And when it messes up are those mistakes easy to spot and correct preferrably in an automated fashion? It's definitely difficult to think about problems that fit all those criteria but they exist simply because of P != NP. That is, we currently have tons of humans doing jobs that are really tedious and manual and very automatable with AI and otherwise. Actually doing the work takes NP time but checking that the solution for the work is correct can happen a lot faster. So even if your product requires human oversight it can still potentially provide massive efficiency gains. Hint: I think paralegals and investment banking analysts fit this criteria perfectly and you could probably create a GPT-based product to have one individual do the work of 20 in these fields. \n\nI will not personally be pursuing any ideas around GPT right now but one of my big goals this year is to better understand the tech behind these large language models. Currently my stance is that there's probably a 30% chance that these models end up being a more impactful invention than the iPhone and the internet combined. There's still a massive chance they turn out to be impressive and fun and even useful but not revolutionary and yet... 30% is quite a big chance to upend the world.","src/posts/006-i-was-wrong.mdx","2ab5ba40d74136f5","just-start",{"id":110,"data":112,"body":117,"filePath":118,"digest":119,"deferredRender":22},{"title":113,"slug":110,"date_published":114,"description":115,"thumbnail":73,"tags":116},"Just Start",["Date","2023-03-13T00:00:00.000Z"],"It doesn't take much to become better than average at anything in life. The most important step is the first. Just show up and start and the rest will follow.",[],"It's not hard to be better than average at just about anything. You just have to show up and try. It may seem trivial or tautolically true but starting is the most reliable way to achieve whatever you want and just by doing so you separate yourself from the average person. If you have a goal then planning matters but it matters less than momentum because a rock solid plan with no momentum leaves you in the same place but action and adjustment will move you closer to where you want to go even if your plan is incomplete. In fact, the odds of you succeeding double or triple the moment you start doing something regardless of a plan because momentum compounds. [Past wins lead to future wins](https://en.wikipedia.org/wiki/Winner_and_loser_effects) so small wins become big wins and taking that first step can lead to outcomes wilder than you ever imagined. I've made the mistake of not starting soon enough more times than I can count in my life-- and I see people around me make it all the time-- so this seemingly obvious truth is not well internalized even by me. \n\nFailure to start stems from two broad patterns I've observed. The first is paralysis in the face of conflicting advice which happens all the time in just about every industry or field. Take an individual who is trying to lose weight and now think about all the conflicting studies, scientists, fitness experts, and influencers who have strong opinions on the best way to achieve this goal. The internet has democratized access to experts and valuable information more than ever before but in the situations where you need to be an expert to discern which expert is correct you are not far off from being completely uninformed. When this happens it's common for to get in the mindset that you just one more opinion, to read one more study and then it'll all be clear when the opposite is true. When faced with conflicting theories the best method is to start falsifying and gathering feedback through action. There are endless proposed methods online for sustainably losing weight but none of them involve sitting around looking at more proposed methods. Act. This happens with everything whether it's business, excercise, cooking, music, language, etc. The act of doing will expose truths and inaccuracies about the field itself and paths to mastery will become apparent that were impossible to see before starting. \n\nThe second and more pernicious pattern is overestimating the complexity needed to get started. Take the same individual trying to lose weight. Over months they listen to podcasts with doctors explaining how to optimize fat loss and maximize muscle growth; they watch fitness influencers for how to best execute lifts in the gym to hit different muscle groups; they create elaborate meal plans with defined macros and targets. Meanwhile they could have started by just cutting out all junk food and doing a light workout every day and it would get them 80% of the way to where they want to go. Experts are so often working at the edge of knowledge for a given field trying to find gains and novel results where no one has before meanwhile a beginner in any endeavor would see results from simpler actions. When a professional athlete talks about optimizing their workout or a musician talks about the humidity of the air or a chef talks about the techniques to perfect a delicate sauce they are actually talking about the last .1% of performance possible. If you are at the beginning of your journey you almost never need to worry about those optimizations and you will never reach the point where those optimizations matter so quickly that you do not have time to see it coming and adjust. In other words, the [80/20 rule](https://en.wikipedia.org/wiki/Pareto_principle) applies to just about anything in life and when you are starting out you get to benefit from the low-hanging actions that get you 80% of the way. This, too, feels like an effect of the internet: we have such access to masters in their field that we often forget we don't need to be as skilled as Gordon Ramsey too cook a healthy and tasty meal or as athletic as Lebron James to be in shape. We just need to start.\n\nIn a sense this is a rephrasing of the common startup adage \"just ship.\" With startups the importance of shipping is obvious and accepted yet I've met so many first time founders making the mistake of not shipping. It almost always comes with a lofty goal to reshape society or disrupt an industry with massive incumbents and leads to weeks writing business plans, refining pitch decks, creating wireframes and mockups, and endless theorycrafting about the idea. The goal is to launch with a product superior to the incumbents in every way; to come out the gate with such an obviously better product that society and the world has no choice but to reorganize itself around it. This startup loses every time to the one without a 50-page business plan, without a refined pitch deck, without wireframes, but with a founder that identified the one differentiator to build a simple vertical slice on and got some customers onboarded. \n\nIn life, as in startups, the person who starts despite imperfection and iterates will always outperform the one who plans meticulously but never puts their plans into motion. The founder in motion will get customers and feedback early allowing them to provide value they didn't even think about beforehand while the founder that only plans will never learn about the untapped opportunities provided by a customer's needs. The individual in motion will learn what works and what doesn't and adjust their tactics as they go while the individual that only plans will miss obvious pitfalls because the problem space for just about anything is so vast you cannot account for everything. The founder in motion will find others who want to join their mission as employees and investors while the founder that only plans will find people who only want to talk and theorycraft. The individual in motion will find communities and mentors that will help them along their journey while the individual that just plans will often plan alone. The founder and individual in motion will experience the effects of compounding results while the ones who just plan will delay the power of compounding longer and longer. The ones in motion will reach their goals while the ones who plan will constantly find new edge cases and new reasons to delay starting.\n\nPlanning has a place and a strategist will outmaneuver and outperform brute force but plans only matter when put in motion. So whenever you're beginning something new focus on the motion first. Focus on the basics. Take the first step. Build the momentum. Then plan once you are on your way. \n\nJust start.","src/posts/010-just-start.mdx","1ca7ba6841489f47","believing-is-the-difference",{"id":120,"data":122,"body":128,"filePath":129,"digest":130,"deferredRender":22},{"title":123,"slug":120,"date_published":124,"description":125,"thumbnail":126,"tags":127},"Believing is the Difference",["Date","2023-03-26T00:00:00.000Z"],"The world can feel like a rational and deterministic place completely indifferent to your emotions but that's not always the case. When it comes to competition, learning something new, achieving something ambitious, or even changing who you are your belief can be the difference between winning and losing.","hand_holding_apple.png",[],"I have a joke that goes something along the lines of \"my character flaw is genuinely believing I could do \\[insert highly improbable feat\\]\". For example I truly believe that should the need arise I could land a commercial 747 airline with no training. Except the joke isn't that I think I can land a giant commercial aircraft with no training or expertise it's that I am pointing out the belief as a flaw when in reality it has probably been among my greatest strengths historically. The act of believing in your ability to do something increases the odds of your success in doing said thing. I don't quite know why that is the case but I'd like to share a few moments in my own life that highlight this phenomenon and provide some clues as to why believing can be the difference between succeeding and failing.\n\nEarly into my high school days I became fascinated with programming. I had been playing around with the basics of html and css at that point but I wanted to build bigger and better things than static sites. I started by learning Java but even before I got to anything interesting I needed to learn how to think like a programmer and that proved far more difficult than I anticipated. The simplest problems on [Project Euler](https://projecteuler.net/about) were too difficult for me and I couldn't wrap my head around solutions that were completely obvious because I couldn't logically figure out how to apply loops and conditionals in the correct manner for the given problem. \n\nFor 3 months every day after school I'd go home, open up one of these basic problems and then try to solve it for 30 minutes before giving up and studying the solution to try and reverse engineer the correct thought processes required. Then one day, sitting in math class absent-mindedly thinking about one of these problems, it clicked. I quite literally felt the neurons in my brain firing in a whole new pattern and programming has felt like a native ability ever since. \n\nLooking back on it, a more sane individual would have stopped trying in the face of seemingly zero progress far earlier than I did. Three months of banging your head against a wall at the *very beginning* of a new skill is not a recipe for a new career path but I kept going only because I knew my older brother was already studying CS in college and if he could figure it out then so could I. The reason I'm a programmer today is because I believed (quite stubbornly) that I could be even in the face of overwhelming evidence to the contrary. That seemingly irrational belief became my reality.\n\nAnother profound instance happened in my second semester of college while studying Calculus II. I had taken a bit of calculus my senior year of high school but it mostly encompassed Calculus I and the little Calculus II we did cover I found incomprehensible. Meanwhile at Rutgers University our Calculus II course is notoriously difficult with a high failure rate and it was common practice for students to take it over the summer at an easier community college then transfer the credits just to avoid taking it at Rutgers. \n\nSo there I am, having heard all the rumors, breezing through the course along with a growing apprehension waiting for the other shoe to drop when we start the chapter on Sequences & Series. For the first time that semester I cannot make heads or tails of the material and all the fears and apprehensions crash down in what I thought was the dreaded fate of all Calculus II students. For 2 days I frantically try to see the patterns---to understand the problems and their solutions---in my weekly assignments. Then on a Thursday night at 11pm with one hour before my weekly assignment deadline and on the verge of a breakdown it all changed when I asked myself a question: what if I was really good at this? What if Sequences & Series were actually really easy to understand? What would such a world look like and how would the me in that world solve these problems? When I looked back at my paper I was staring at a different language---one I could comprehend and understand with ease. The patterns composed easily before me and I began to look at Sequences & Series---and later all of Calculus II---from a different perspective.\n\nIt feels clich√© to write these words. These are the type of corny feel-good dramatizations about confidence and the power of belief usually intended for a target audience of 10 and under but I've truly experienced these moments and they weren't the only time. Sitting in my dorm and grasping Sequences just minutes after not understanding any of it was the most extreme manifestation of this phenomenon I've ever experienced but it's happened so many times to varying degrees that I cannot discount its existence. Over short time periods like this one and longer ones over months and years, in academic subjects and athletic endeavors, in side projects and personal goals, this phenomenon of belief altering my performance continues to come up. \n\nThroughout my life I would claim my defining differentiator from my peers is my ability to learn new things rapidly and with ease and I believe my confidence in my ability to do so plays a large role in that. The more confident you are the less stressed you will be and the less stress you experience the more elastic your brain will be and the more elastic your brain is the faster you will learn. Whether or not that is the actual mechanism at work is irrelevant to me, however. I've never doubted my ability to learn something and then found it easy but every time I internalize a confidence in myself for a coming task I accomplish it with a high probability of ease and these experiences over time has cemented this as fact to me. Whether I'm under pressure (trying to land a 747 with no experience), in a totally new domain, trying to achieve something ambitious, or all of the above quickly acquiring and learning new skills is essential and believing in your ability to do that accelerates the process.\n\nThere's an unfortunate caveat I've learned which is that this doesn't work without internalized belief. There are times when I consciously tell myself something but I do not believe it in my gut; I do not believe it *unconsiously.* In those cases conscious reinforcement hasn't been enough. This means it can be hard to put into practice the process of belief and benefit from the subsequent boost in performance which can be needed the most when you're at your lowest. When you are beaten down and worn out---when it feels like the world is against you and the walls of depression are closing in---you can find yourself without the conscious power to override the defeat within your own soul. I have yet to find a reliable and deterministic method for turning conscious belief into internalized belief but I've compiled two broad heuristics that can be useful.\n\nThe first is to start with a question. When your gut says \"I can't do this\" no amount of gaslighting by your prefrontal cortex will convince it. If you instead pose simple questions you have a chance: \"what if I *could* do this? What would a world where I can do this look like?\" \n\nWe become the stories we tell ourselves about ourselves and by asking questions you give permission to the deepest parts of your soul to acknowledge its current beliefs yet also to imagine alternate narratives about itself. These narratives over time can become desires and then beliefs and then realities. When I was at my lowest point as a teenager and debating whether I should even continue the dance of life the turnaround all started with a question. By giving myself permission to imagine a better future even if that felt impossible in the moment I was able to craft a new roadmap for myself and change my reality. This does not happen always but it happens enough to make this a usable strategy. Start with a hypothetical and see where it takes you.\n\nThe second strategy is to start with small wins. Jordan Peterson has a now famous recommendation to start the long journey of self improvement by cleaning your room. It's great advice. Your brain is a prediction machine and it learns via reinforcement over millions of unconscious and conscious predictions about the future and then subsequent interactions with reality. When you start with a small win it subtly strengthens the connections in your brain that say *I can do this* and in time it can give you the conditioning required to believe in yourself even when tackling far greater tasks than you can imagine. I have such a strong confidence in my own ability to learn new things not because I wake up and tell myself every morning that I can do it but because my brain has hundreds of thousands of experiences to draw upon where I was able to learn something new stretching all the way back to when I first learned something as basic as talking. The [winner effect](https://en.wikipedia.org/wiki/Winner_and_loser_effects#:~:text=Testosterone%20is%20another%20compound%20whose,losing%20team's%20testosterone%20goes%20down.) is real and it's because the body operates on these subconscious internalizations more than we realize so small wins become big wins and similarly small wins become new beliefs and those beliefs lead to better performance. \n\nI find myself in an increasingly rationalist world that attempts to quantify everything. At a societal level this obviously has advantages but I find myself increasingly trying to surround myself with individuals that go beyond rationalism. I want to be friends with, work with, and invest in individuals who say *I know the odds but I will win anyway* because I think those people are more compelling *and* more likely to win. To put it simply: when two individuals with equal ability compete head-to-head the one who believes in themself will have an advantage over the one who doesn't. If you want to achieve great things, be a great partner, a great competitor, a great founder, etc. you need some level of delusion. You need some level of blind faith in your ability to achieve what you desire because it is this blind faith that will keep you going longer than the rational individual in the face of seemingly insurmountable odds. It is this blind faith that will keep you relaxed and adaptable in the presence of pressure. It is this blind faith that will be the difference between success and everything else.","src/posts/011-believing-is-the-difference.mdx","019c361ab21829ef","thinking-short-and-long",{"id":131,"data":133,"body":139,"filePath":140,"digest":141,"deferredRender":22},{"title":134,"slug":131,"date_published":135,"description":136,"thumbnail":137,"tags":138},"Thinking Short and Long",["Date","2023-05-06T00:00:00.000Z"],"Thinking short and long is the act of focusing on the day-to-day tasks required to move yourself forward while also zooming out and effectively strategizing against a longer term vision. When building a company you will need to do both effectively but in the trough of sorrow you will need to do both at the same time all while the pressure and problems you face seem to multiply endlessly.","telescope_eye.png",[],"I often hear founders and investors talking about the need to think short and long---to zoom in on the daily details and to zoom out on the big picture strategy---as key skills for a founder. I think it's great advice if not a little obvious but the way these skills come into play changes over the lifetime of a company in a way I didn't fully appreciate before. \n\nIn the beginning of a new company you will have a guiding vision but by far the most amount of your time will be spent laying the bricks of your foundation every single day. It may seem on the outside that you are immersed in the big picture vision because that is what you will discuss whenever you talk to investors, customers, or family but the majority of your time will be focused on the daily grind. At such an early stage there is little need to zoom out and analyze the big picture compared to how often you need to be zoomed in and executing relentlessly. Navigating a ship doesn't matter much if you don't have a ship!\n\nOn the other side as you are approaching an exit it becomes far more important to spend time zoomed out, analyzing the bigger picture, and strategizing effectively. Solving day-to-day problems will be less of your concern and you will need to be capable of seeing the bigger dangers and opportunities. Hedging risks against economic black swan events, capitalizing on new opportunities, and managing the growth of your business all require a clear vision of the future beyond the daily work that needs to be done. You will need to think long to navigate your ship through uncharted waters.\n\nThese skillsets and their value seemed obvious to me for the longest time but recently I've come to realize there is a third distinct skill that you don't get for free just by being good at the other two. That is not just thinking short and thinking long but to do *both at the same time*. This is so difficult that it separates itself as a skillset from the other two individually and is one of the defining hardships in the [Trough of Sorrow](https://andrewchen.com/after-the-techcrunch-bump-life-in-the-trough-of-sorrow/). \n\nAfter you've attained product-market-fit but before you are on the path to an exit you will spend the majority of your startup's lifetime in the trough of sorrow facing a seemingly endless road of hardships and struggles. As you scale the tricks and shortcuts that got you here---and you *will* have tricks and shortcuts otherwise you wouldn't be here---will begin to slow you down. Your abstractions and data models will show their limitations, your bugs and ops load will increase, your morale will decrease, and your velocity will slow. Your ship will begin to spring leaks. You will have to dedicate a significant amount of your focus day-to-day fixing those leaks while at the same time the challenges of scale will require more deliberate long-term thinking. \n\nOn paper the margin for error may be bigger than in the past but the opportunity cost of a wrong move will be higher than ever before. Incumbents will begin to treat you as a real threat and deploy resources---sometimes more than you have---to destroying you while new competitors that are still young and agile will pop up around you. Big ships turn slowly and in such an environment you are only afforded so many wrong turns before you're left in the dust. A month or two pursuing the wrong approach early on may not be a problem because you can pivot in a day but that agility will rapidly disappear as you scale. A random walk approach to solving your problems will not be a sufficient strategy for this phase because your growth turns your local maximas into tech debt, your tech debt amplifies the leakiness of your foundational model, and the weaker the foundational model the slower you become, the more firefighting needs to be done, and the worse your position becomes relative to competitors.\n\nThis is the time to escape your local maximas. Plans will need to be made on the scale of months but executed on the scale of days. The nature of escaping local maximas means your plans might not show meaningful returns on investment for longer than ever before making it hard to guage the effectiveness of new strategies. You will need confidence to stick to new initiatives for long enough while also having the humility to understand that any given course of action could be wrong. Full rewrites of your codebase will become attractive options just to get back to the feeling of high velocity but this is a trap in all but a few instances. \n\nThe hardest part about engineering isn't building the initial system it's changing it in motion. Part of thinking short and long is recognizing what you have here and now and where you need to be long term and then executing on a plan to reduce the delta. This is difficult in a way that academic program design and brute-force programming usually fails to capture. Refactoring often leads to bugs and you'll be suffering with enough of those. Sometimes it's not clear that refactoring in a specific way will help and sometimes it feels *very* clear but there aren't definable metrics. It's very tough to convince people that things should be done a different way if you cannot point to immediate quantifiable ROI on the work required to change the system. If you're the founder or in a position of leadership you may think that you don't have to convince anyone but there's always stakeholders beyond yourself and at this stage of your company's life you may find yourself with more stakeholders than you realize.\n\nWorking at a company during this period can be brutal for non-founders as well. Foundational employees are likely to leave at this stage and take with them critical institutional knowledge while increased ops loads and longer timelines for progress will lead to burnout amongst the employees that remain. You are most likely to burn out at this stage too. The headcount of the company will grow and change leading to internal politics that need to be managed for the first time in the company's history. Lines of ownership will be drawn, formal processes will be implemented, and accountability will be quantified. In many ways the fun part of an early startup will rapidly vanish but the abundance of a large established corporation will not exist yet leading to the combination of boring cog-in-the-machine work environment without the margin of safety to go along with it.\n\nYou may become increasingly frustrated with your own ability to get things done. Your time context switching between daily tasks and big picture planning will prevent you from doing either one as well as you'd like. To properly strategize long term you need uninterrupted time to understand and map out the landscape ahead. To properly move the needle on high impact daily tasks you need uninterrupted moments of flow. But your time will be interrupted. Your calendar will fill up and your responsibilities will multiply and you will find yourself without the time to work on the high impact daily work you're used to doing and you will be frustrated at your own lack of focus at seeing the bigger picture. This feeling of deteriorating excellence due to having one foot in both worlds will seemingly come at a time when the issues your product and company face become more apparent than ever and the solutions needed more obvious. This decreased effectiveness combined with a growing list of problems leads to the sensation of slog and it will stretch out before you like a road that disappears across the horizon. \n\nThe worst part about this stage is you might do everything right and still lose but that's just the nature of things. There's no way to know until you try. If you're an employee at a company in this stage more will be asked of you than perhaps you signed up for but there will also be incredible room to grow. Simply showing up every day and executing relentlessly can be the difference between success and failure. If people feel they can rely on you to do what you say you will do that eases the load off everyone that you work with. Dependency means \n\nI have no advice to give about how to get through this period of time not because I don't have ideas on what would help but because I don't have the experience to know if they're right. It would be disengenuous. All I can do at this point in my career is observe and learn and hopefully in 10 years I can definitively write about the strategies that make this period of a company's life easier to get through. What I do know is that the skillset required to get through this period is distinctly different than what is required before and after it. You will need to think short and you will need to think long and you will need to do both every day all the time. I do know a good team that you trust is critical---I don't see how you can possibly survive without that---and you will need to pace yourself. Now more than ever the game becomes a marathon not a sprint. The only way out is through.","src/posts/012-thinking-short-and-long.mdx","c1ae56c65ff1679b","6-questions",{"id":142,"data":144,"body":150,"filePath":151,"digest":152,"deferredRender":22},{"title":145,"slug":142,"date_published":146,"description":147,"thumbnail":148,"tags":149},"6 Questions",["Date","2023-05-29T00:00:00.000Z"],"Fenyman had a concept of 12 questions which he contemplated for much of his professional career, constantly adding new facts and insights to each category over time. This allowed him to progress along many axes at once over long time periods until the accumulation of understanding in any given question reached the point where others considered it a breakthrough. Here are the 6 questions I'm thinking about these days.","fenyman.png",[],"Feynman had this concept of 12 important questions and every new idea or thought he came across throughout his life he'd try to contextualize within one of those questions. The idea is to build this ongoing thread of new insights for each question and continue to pull each thread over long time periods until revelations would emerge. I do not have 12 questions but I do have 6 that I find interesting and hope we as a civilization answer in my lifetime.\n\n### 1. Education at Scale\nSo many problems in the world can be boiled down to issues around education. Our solution as a society seems to be the establishment of state-run (and privately run) schools that all look and act uniformly in their approach to solving this problem. Their yearly schedules are similar, kids are grouped by age, the subjects are pretty much the same, the extracurriculars are similar, the daily class breakdowns follow similar patterns, the yearly progression is similar, and the end goal is the same: college. In America the school system happens primarily at the local level with influence from the states and the federal government so it's common to see variation in syllabi, resources, wealth, etc. across different schools but the directional approach to the overall problem of educating the people remains the same. Even privately-run schools look almost identical to public schools in all but their prestige and wealth. \n\nIt can be difficult to measure the efficacy of different school reforms but we know that what we have right now is not working. The average US adult reads at a 7th grade level and American students routinely score worse than international counterparts on standardized tests. Our educational elite seem committed to the idea that the problem is funding and more schooling = more education but we routinely see this is [not the case.](https://ny.chalkbeat.org/2022/8/26/23319844/new-york-school-spending-test-scores-disconnect) Most education policy makers view education as a function of locking students in a room for 8 hours a day and fiddling with the right knobs to make them come out the other side smarter but this is not how learning works. You can force a child to sit in a chair and you can even force them to read a book, reciting the words out loud to be absolutely certain, but that simply does not mean they are learning the lesson we want future citizens to be learning.\n\nOur kids are isolated from the world from ages 6 to 18 every weekday for 10 months out of the year, forced to sit in sterile environments, often learning the same subject --- like a foreign language --- for years and still graduate with no proficiency in it. Worse yet the basics of reading and writing have proficiency rates that are abysmally low and after 12 years of schooling the average American is unqualified for the work force, has very little formal reasoning and logic skills, and has not interacted with the world in a meaningful manner at all. Any school reform that shows a sign of promise quickly sees their benefits disappear when rolled out at scale (I cannot find a source for this now but this is famously a phenomenon that the Gates Foundation has struggled to overcome). Why is that?\n\nSo much can be written about the education problem and potential fixes but I'll leave it here for now. Education is still plagued by [Bloom's 2-sigma problem](https://web.mit.edu/5.95/readings/bloom-two-sigma.pdf), our schooling institutions seem to be sliding in the [wrong direction](https://www.sfchronicle.com/sf/article/S-F-school-district-pledges-to-have-academic-17312844.php#:~:text=Recent%20results%20reveal%20that%2058,of%20Latino%20students%20are%20proficient.) even in our richest cities, and worst of all despite all our resources and advancements in technology we have not seen a boom in educational outcomes. Why aren't we [producing more world-changing geniuses](https://erikhoel.substack.com/p/why-we-stopped-making-einsteins) than ever before? What does it take to solve the education problem for a society at our scale? If we are to solve our society's challenges in the next century we better figure this one out.\n\n### 2. Software at Scale\nWe have an ongoing [software crisis](https://olivergilan.com/blog/software-crisis/). The short of it is most software projects fail. And as a project increases in size and importance the odds of it failing goes up. The [CHAOS reports](https://www.standishgroup.com/sample_research_files/CHAOSReport2015-Final.pdf) published by the Standish Group paint a bleak picture with software project success rates past and present. Despite methodologies like Agile and all the developer tooling and product management knowledge that's been accumulated since the '60s we've seen only marginal progress in consistently building software successfully. The important thing to note here is that we can build software at scale in the sense that we have the compute and knowledge to build large systems but we cannot build software at scale in the sense that many organizations can competently build software.\n\nThis is an increasingly important problem and has been since it was identified in the NATO Software Engineering Conference in 1968. Software is eating the world and it's playing an increasingly important role in our lives. It's critical for our banking, transportation, national security, healthcare, etc. We need to figure out how to competently build software for all aspects of our lives even when it's being built by semi-competent organizations in the government. This is the problem I am most focused on right now given my career and understanding of the domain so if I can solve one of the big issues on this list it's most likely to be this one. I do think there are promising solutions here and I think a lot of them exist already they just haven't been synthesized into a single philosophy and framework for software development so that the average developer and product team can just follow some simple guidelines and arrive at good software. I am confident this can be solved in my lifetime.\n\n### 3. The Immune System\nAutoimmune disorders are [on the rise](https://www.autoimmuneinstitute.org/articles/about-autoimmune/autoimmunity-on-the-rise/#:~:text=The%20best%20guess%20that%20current,2%2C3%2C4%5D.) and it feels like every day I'm talking to someone with new allergies they didn't have growing up. The immune system is so crucial to understanding and controlling human health and our medical system simply does not understand it nearly well enough. Most autoimmune disorders are misdiagnosed and most do not have great treatment options. We need a Manhattan Project for mapping out, understanding, and controlling the immune system. From what we know it seems to be somewhat programmable. Could we ever arrive at an understanding well enough that allows us to quite literally program/debug our personal immune systems like we do with code? This could be the biggest seismic shift in human health after sanitary water and antibiotics.\n\nHow does the immune system relate to other systems in our body like our gut biome and our skin? How does it relate to mental health and the brain? How does food, exercise, and sunlight affect it? Can it be harnessed to fight cancers, Alzheimer's, and other classes of illnesses? Our immune system is dynamic and vital to understanding our health and wellbeing.\n\n### 4. Community\nIt feels like community is deteriorating across America. Kids spend less time playing with friends, adults spend less time with friends and family, and rates of depression & suicide are increasing. In our cities and towns people know their neighbors less and less and we are becoming more insular, spending [more time alone as we age](https://www.visualcapitalist.com/who-americans-spend-their-time-with/).\n\nOn top of that we are seeing weird trends around gender and vitality. Fertility rates are plummeting leaving us with aging populations and a dearth of young kids to inject life and hope into our communities. We are also seeing growing divides between the genders and there seems to be a massive disconnect between expectation and reality in dating for both the men and women I speak to in my life. At least in the coastal liberal cities it seems that taking an adversarial approach to dating is the predominant strategy and it doesn't seem to be working well for us as a society. \n\nAll the technology in the world won't save us if we hate each other because of our politics, gender, or lifestyle. We need to figure out how to bring back a sense of community to our country as we grow while protecting the liberties of individuals and the diversity of lifestyles that a free nation should expect. This is not a problem that digital technology can solve. It will require social technology and smart leaders.\n\n### 5. Food at Scale\nHeart disease is the [leading cause of death](https://www.cdc.gov/heartdisease/facts.htm#:~:text=Heart%20disease%20is%20the%20leading,groups%20in%20the%20United%20States.&text=One%20person%20dies%20every%2033,United%20States%20from%20cardiovascular%20disease.) in the US. Obesity rates and the amount we spend on healthcare are skyrocketing and it's undeniably related to the food we eat. This even relates to so many of the autoimmune problems and the rise of allergies we are seeing. It sure *seems* like our food is poisoning us but the extent is unclear. The interesting thing to me is what incentives are leading us down this path. Is it just as simple as garbage food tasting good and hijacking our brain's reward mechanisms to become addicting? Is this demand-induced? Why is it with all our wealth and all our fertile farmland we cannot seem to grow really healthy food at scale for cheap? \n\nThis problem can be broken down into a couple categories but the two big ones are: what even *is* a healthy diet and what would it take to feed the entire nation such a diet? How could we build farms that can grow the right food in the necessary quantities for cheap while being environmentally sustainable? Avoiding soil erosion, excess fertilizers, animal cruelty, resource consumption, and all the other problems our farming industry is currently plagued with is important on its own but to do that *and* to feed everyone the right food for cheap seems incredibly important. It can be tempting to view this purely as an engineering problem but it's far more than that. Understanding what a healthy diet looks like for different groups of people with different ancestry and diet restrictions is an unsettled science. On top of that even arriving at an answer does not take into account the immense political and economic efforts that would be involved to reform our farming industry to grow the foods it actually should. The very health and vitality of our nation could rest on figuring this out.\n\n### 6. The Nature of Consciousness\nWhat is consciousness? Why does it seem like some matter has this property while other forms of matter do not? Where does it come from? Does it rely on organic matter or can silicon be conscious? This is a fascinating question that gets to the heart of what it means to be human and it could become increasingly important as AI becomes more and more powerful. It may seem academic --- and it's certainly easy to smoke a joint and sit in an armchair talking about the nature of consciousness mannnnnn --- but in reality understanding human consciousness could unlock an understanding of the universe, human behavior, psychology, and mental health. The nature of consciousness (along with the origin of life) are the two big unsettled questions in biological science in my opinion. \n\n___\n\nThese are just some of the questions I find interesting but I'm also young and I expect I'll find quite a few more as my life goes on. Some of these are big and I have no expectation of finding an answer to them myself although I do hope we figure them out as a civilization within my lifetime.","src/posts/013-6-questions.mdx","15d530ca3e0dd9b6","living-with-buggy-hardware",{"id":153,"data":155,"body":161,"filePath":162,"digest":163,"deferredRender":22},{"title":156,"slug":153,"date_published":157,"description":158,"thumbnail":159,"tags":160},"Living With Buggy Hardware",["Date","2023-08-10T00:00:00.000Z"],"Over the past 3 years I fought for my life against a failing body. Now I'm trying to live with the weakened state I find myself in.","the_body.png",[],"On the morning of August 2019, a few weeks before my 21st birthday and my Junior year of college, I experienced the most intense pain in my stomach I've ever felt. It occurred while stuck in traffic during my one-hour commute to the offices of Prudential in Newark. The pain was sharp and deep in my abdomen and it had me doubled over, debating if I should pull to the side of the road. The pain dissipated a few minutes before arriving at work and sitting in the parking garage I took some deep breaths and questioned what just happened. After a few minutes of no pain I concluded that nothing serious was wrong so I continued on with my day. \n\nOver the two years following that moment I experienced the hardest period of my life. I experienced greater physical and psychological pain than ever before, I lost my strength and watched my body wither away, endured hopelessness and disillusionment in the heart of the American healthcare system, and experienced extreme anxiety and depression. All of this happened as I took the hardest classes of my college career, graduated at the height of COVID, and burned out at my first full-time job. The experience altered the way I see myself and the world. It made me rethink my own mortality and my relationships with those around me. It broke my body and wore down my mind. That I am here today is part luck, part resilience, and a lot of discipline yet I am still a fraction of what I once was. I‚Äôve held off on writing about this period in my life because in my mind it‚Äôs still not over yet but so many people close to me do not know what I have been through and cannot fully understand me today without this context. That this period of my life will ever fully close is unclear so I‚Äôve decided to write about it before I forget what I experienced myself. \n\n## The Descent\n\nLooking back on it I am not sure that the event in the car was the beginning of my problems (or even related to them at all) but it stands out to me as the moment when my digestive tract began to not behave as it should. The thing is, random acute pains are not fundamentally abnormal nor concerning and do not always indicate something is seriously wrong. Up to that point I'd been a remarkably healthy individual and very in-tune with my bodily functions. I was lean with a body weight of 155-160lbs at 5'11, very active, and grew up eating organic whole foods cooked by my parents. Even throughout college I'd cook most of my meals and spent a majority of what little money I had on high quality groceries. I drank alcohol little compared to the average college kid, avoided unhealthy sleeping habits, and worked out regularly. Doctors would occasionally express amazement at just how healthy most of my indicators appeared on the results of my physical checkups. For most of my life I'd gotten random sharp pains in my chest or experienced stomach pangs or would wake up with a sore muscle/tendon randomly and as far as I can tell this is just a normal part of the human experience. The pain in my stomach that day far exceeded anything I'd randomly really felt before but it completely went away after 30 minutes and later that night when my stool was loose I assumed the entire event was just a form of food poisoning. \n\nOver the next few days my stool continued to degrade in quality (it feels weird to comment on that mostly because I meet many people who do not have a clear concept of a \"healthy\" bowel movement but your stool is probably the most reliable indicator for the overall health of your digestive tract and internal systems as a whole). I've always had extremely healthy bowel movement with the exceptions only being times I was sick and they never lasted more than a week so when it was two weeks later and my stool was still not healthy it definitely set off alarm bells. I brought it up to my GP but after some tests none of my other indicators expressed any issues and I was otherwise having no problems with my health so it was once again dismissed. I had the beginning of a new semester to deal with as well as continuing my internship so I was happy to hear there was nothing to worry about and move on.\n\nThe puking began 3 weeks later during the first couple days of my Junior year. I hadn't thought about that initial incident in the car for a few weeks at that point but while attending a baseball game with two friends I had a single drink and felt sick the rest of the night. The next morning I awoke and rushed to the toilet where I promptly vomited. Kneeling there gripping the toilet seat I thought about that incident in the car and if it was related to what had just occurred. *\"Maybe just no hard liquor for a while\"* I thought to myself. That night I attended the first party for the semester that my fraternity was throwing but I didn't even make it to the next morning and vomited after two beers. All my friends laughed it off as me having drank too much but at that moment, with my stomach burning like fire, I became seriously concerned for the first time. During that entire first week of the semester I tried different amounts of foods and alcohols until by the end of the week having a single sip of a beer was enough to make me vomit and my stomach was regularly burning intensely.\n\nSo I cut it out. I stopped drinking entirely in an attempt to ease the issue. I sat down and thought about what could possibly be happening and concluded that I might have a stomach ulcer that was being aggravated by alcohol. Over the next few weeks I didn't touch alcohol at all but my symptoms continued. I'd routinely go to sleep with my stomach burning in pain and I could feel my appetite slowly decreasing all the while the hardest semester of my college career was getting into full swing. After two weeks of this I booked an appointment with a nearby GI doctor and explained my symptoms. He promptly diagnosed it as a stomach ulcer and prescribed Pantoprazole to reduce my stomach acid so that I could heal. \n\nI optimistically took the medication over the next month and a half but nothing improved. The pain would come and go in seemingly random waves. My stomach would feel as if it was burning from the inside, my skin felt extremely sensitive to the touch, and I began to experience bouts of nausea. At the time I was working out 5 days a week and on a cold Tuesday after class I remember walking home from a particularly hard core-focused workout and immediately feeling the pain wash over me. From that point on every time I worked out my core I would experience the burning pain. I immediately began to reduce the intensity of my workouts which helped for a little. Then I had to avoid core workouts entirely which avoided direct stress on my stomach but as the weeks went on I found myself modifying my workouts more and more. The problem with the core is that most any athletic endeavor or exercise uses it. I had to drop my weight down so that I could isolate my muscles more without the need to brace my core but in the end it wasn't enough. \n\nI went back to the doctor and explained things were worsening including the inability to workout. I asked about the possibility of herniation but he dismissed my concerns and informed me that the medication takes time and that I should try it for another two to three months. And so I did. At the time I was in the best shape of my life at a lean 160lbs. I was lifting far more than my bodyweight in most compound lifts, hitting PR's regularly, and had a lot of energy as a young man. The 3 months after that second doctor's meeting I experienced a rapid decline in all those areas. My appetite dwindled fast, even the smallest workouts would leave me in pain the rest of the day, my energy to even try to workout quickly evaporated, and my stomach became so sensitive I began to experience insomnia. Over those 3 months I lost 30 pounds and became a shell of myself at 130lbs. All the work I had done over the past four years to gain weight and muscle was wiped out.\n\nI couldn't quite comprehend what I was experiencing over that time period. I was watching my body whither away and my mind was in a state of panic, denial, and frustration. I would go to fraternity events and hang out with other friends but it became tiring to constantly decline alcohol. In the end I didn't even have the energy to try to socialize and I stopped going. I quit my internship (that I had continued to work at during the school year) because I could not handle the energy required for school and work. The little energy I had went towards maintaining my grades and my relationship with my girlfriend at the time. My fear and desperation was growing but I held on to this stubborn belief that I would wake up the next day and recover and I wanted to make sure that when that recovery happened I wouldn't have sabotaged my schooling and future. School was the priority for me and so I invested my little energy into that and by the time I was done with classes and assignments I had nothing left. My life consisted of class, homework, sleeping, and distracting myself from the new reality I found myself in. \n\nI tried explaining what I was experiencing to my parents but it did not feel as though they understood. My mother urged me to go to the doctor again and my father gave me the sort of holistic advice such as ‚Äúworkout more‚Äù and ‚Äúmake sure to only eat good food‚Äù that I just didn't want to hear. I _had been_ exercising. I *was* eating good food. What little money I had from my internship was going to school, rent, and groceries and I was eating organic whole foods that I was cooking myself. I became resentful that all my friends around me could live such easy lifestyles with shitty diets, poor sleep habits, and drug abuse and yet they were all thriving and I was the one suffering. At the 5 month mark I went to sleep every night wondering if I was headed towards a young death. Scenarios and possibilities flashed through my mind and fear became a constant in my life. The only one who seemed to sympathize was my girlfriend at the time mostly because she saw the decline up-close every day. She watched as the guy she first met slowly began to fall apart and her standing by me during that time is one of the most important reasons I didn't completely lose myself.\n\n## Searching for a Solution\n\nAt the 6 month mark I had settled into school and also realized that if prioritizing school meant dying then it wasn't worth it. I can't fully remember the order of events but I set my mind on figuring out what was happening to me. I no longer believed it was a stomach ulcer and I realized I would need a more comprehensive medical journey to figure out what was going wrong. I began by meeting with a GP and from there I embarked down a road involving multiple doctors from GPs to GIs to Radiologists to try and figure out what was wrong. Over the next 6 months I conducted ultrasounds, CT scans, SIBO breath tests, blood tests, urine tests, an endoscopy, colonoscopy, etc. I was tested for cancers, Crohn's, Celiac's, and every other potential fatal disease. \n\nWith each test my hopes of finding the cause of my problems would rise and with each test the results came back negative and with each negative test my frustration and anger grew. I was in the most pain I've ever experienced, my old life was gone and I was barely holding on. Fatigue was a constant, pain was a constant, I couldn't seem to retain water and I was continuously dehydrated. I had no energy and barely any strength left yet all I heard from doctors was my systems look normal and fine and that in everything they could see I was a healthy individual. I could not believe at the time how my body would be considered healthy by any serious medical system. It was even suggested to me once to explore the possibility of a psychosomatic approach to my problems but that did not bear fruit. This was not a problem of the mind. \n\nAll this happened over months as I struggled to fit in doctors visits between classes and on weekends. I ended up getting second and third opinions trying desperately to figure out what these doctors were missing. That no one could point to an obvious root cause began to drive me mad.\n\n## The War In My Mind\n\n7 months after that initial pain in the car my symptoms seemed to level off. I wasn't doing well but I also wasn't getting worse. I had reached a steady state of suffering but the relief from that was short lived: death almost became a preferable outcome to the prospect of living the rest of my life in this state and as my body seemed to pause its deterioration my mind began to crumble. \n\nHow could I possibly achieve my hopes and dreams of building a family and a business and a community when I could barely stay awake for 10 hours a day and had no energy or strength to do anything beyond sit at my computer and do some schoolwork? How could I possibly lift up my kids and be the dad I want to be when even the slightest physical exertion had me doubled over in pain? How could I ever ask a woman to sign up for a life with me in such a state? It felt as though I had stuck my head in a microwave and every second new thoughts and scenarios would pop in and out and bombard my mind with terrible ideas. \n\nOver the course of my life I was always able to call on my body when I needed to. I was such an active kid that would constantly play outside, climb trees, go for runs and bike rides. Whether I wanted to play a sport or learn how to surf or scuba dive; whether I wanted to dance or play I could do it all. I had definitely always been more cerebral than physical but my body was always there when I wanted it and it always did what I asked of it. I was proud of my mind-body connection and I attribute a lot of my early psychological confidence to the dependability my body provided me. To watch that all disappear over the course of a couple months destroyed my mind in ways that are hard to fully appreciate.\n\nFor the first time in my life my body and health felt out of my control and with them, my destiny. My dreams felt out of reach and the future felt like a long dark corridor with no sign of light at the end of it all. I had always been someone to face things directly and one of the defining attributes I hold highly about myself is high executive functioning. I was used to staring at uncomfortable and hard work that needs to be done and doing it regardless of how I felt. I was used to changing who I was and growing when necessary. Depression in high school had made me acutely aware of my own psyche and I was comfortable with the dark corners of my mind but that was suddenly an irrelevant skill: my body was failing and no amount of mental resolve was stopping it. I slept as much as possible not just because I was tired but because being awake had little benefit. I began to resort more and more to the escapism of video games and movies. I gave up on discipline and executive functioning --- it made little difference anyway --- and did whatever I could to procrastinate and distract myself from reality.\n\nThese actions led to me despising myself. When I looked in the mirror the man that looked back was not myself. I felt locked in the prison of my broken body and my resentment at others grew in ways I am embarrassed to admit. Watching friends and influencers make progress in the gym made me jealous and listening to thought leaders talk about waking up early and solving all your problems by grinding harder infuriated me to no end. *To have a body that can wake up at all is a blessing that is out of our control* I would think to myself. Even watching other students go for a jog would cloud my mind with thoughts of how unlucky I had become. I am not religious but I spent many nights wondering why the universe was doing this to me, why God was punishing me. I would spend hours racking my memories for things I had done so wrong in my life that I deserved this outcome. In the end fatalism seemed to be the only answer: I was simply an unlucky roll of the dice in a cruel and unrelenting universe.\n\nLiterature and history is full of humans suffering in dignity but that is not how I would describe my experience. At the very least the inner turmoil in my mind stripped me of any sort of self respect or dignity. I grew impatient and hard to be around. I became increasingly quick to anger and my frustration at the doctors who couldn't help me, the world that didn't seem to care, and the body that yielded no clues to what was going wrong continued to mount. My life and future was falling apart around me but the rest of the world kept moving as usual. Until it didn't.\n\n## The Year the Earth Stood Still\n\nCOVID came to America in early 2020 and my school shut down in-person classes at the beginning of March, 8 months after my symptoms began. When the world stopped because of that virus a big part of me was relieved. The end of social activities relieved me of the burden of turning down invites and making excuses for why I wouldn't attend yet another party or gathering. Remote classes meant I could attend school from the comfort of my home and save the energy I would have otherwise spent on commuting to class. The lack of public activities meant I could avoid the stress of trying to hide my pain and sickness from others. I was suffering just like before but now at least I didn't feel as though the rest of the world was moving on without me. \n\nTurns out that was a naive reaction to the pandemic as the little social interaction I *did* have before disappeared and I felt more isolated and alone than ever. Being stuck inside so much and doing my classes all on Zoom turned out to be terrible and the last two semesters of my schooling was a joke. I increasingly began to fight burnout from being inside staring at a computer screen so much. On top of that seeing a doctor became impossible for at least 6 months and so did chances of figuring out what my problem was. The world was in stasis and now so was I but my state was suffering.\n\nAs the world found a new normal with COVID and lockdowns I found my own normal with my condition. Those days felt like limbo. My context window of consciousness collapsed and I just lived moment to moment. Despite what the Buddhists may say it did not feel like enlightenment. I planned for no tomorrow, couldn't remember what I'd eaten for breakfast the day before and simply drifted on. I was not in hell, just purgatory. I finished my Junior year then my first Senior semester and graduated early and joined Microsoft. I knew I was going to have the credits to graduate early and for years I had planned to take that time after graduating early to travel. Had I even been healthy enough to travel COVID made that impossible so I pushed up my start date and began working.\n\nA little over a year and a half after my problems began the world began to open up again and I was able to make appointments with doctors again. Over the next 3 months I repeated the process of testing and waiting and testing and waiting. I became sick of explaining my symptoms and the timeline of everything to new doctors. After a period of unsuccessful doctor visits a family friend recommended a GI near me and so I met with her and we concluded that with all the tests I'd done in the past there was not much else left to explore. She ran a few tests again to rule out false negatives and tested for a few more problems but after a month of that she sat across from me and informed that she couldn't do anything else. She'd tested for everything she could and it was still unclear what was happening to me. The best she could offer was IBS medication to potentially ease the symptoms. **I don't know why but when I heard that she could do no more to help me it changed everything.**\n\n## Priority #1\n\nUp to that point I had been outsourcing my health to the professionals. Between school, internships, and then my first job at Microsoft I had so much on my plate it felt like the logical choice to offload the task of researching and fixing my health to the people who specialized on that one task. Unfortunately personal health is probably the starkest example of the [Principle-Agent problem](https://en.wikipedia.org/wiki/Principal%E2%80%93agent_problem) which states that an agent with authority to act on a specific goal for a principle may not always have the same motivations and incentives to achieve that goal. When it comes to your health you will always have more incentive and desire to make yourself healthy than a doctor ever will and so taking your health into your own hands is always necessary, even if you consult with doctors. The most cynical interpretation of this dynamic is that doctors might even be incentivized to _not_ make you fully healthy because they get paid the more they see you but I think this view is generally overblown (although it is *very* present in the American system). Regardless from that point on, my health became my own priority #1.\n\nWhen I heard that the doctors were out of ideas to diagnose and help me it felt like permission to take control of the problem myself. I felt the feeling of agency I had forgotten. I realized I didn't care if I had to leave my job or sacrifice on any number of other things in life I was going to make my health my number one priority and I was going to spend all my time and energy on fixing whatever the fuck was going wrong with my body. And so I set to work.\n\nI could complete most of my work for Microsoft with just a couple hours of work a day and instead of going above and beyond like I had been I simply dedicated the rest of that time to fixing my health. I made it a full-time job. The first thing I learned is that my experience is not uncommon: stomach problems are on the rise in the US and its a phenomenon GI's are aware of and actively trying to figure out. There are national conferences where every year more and more doctors are talking to each other with stories of patients experiencing symptoms just like mine with inconclusive causes. These issues seem to specifically be tied to increased allergies, with gluten being a primary culprit even in the absence of Celiac's. It‚Äôs not clear why it's happening but leading theories suggest high FODMAP diets leading to partial digestion of food, malabsorption of nutrients, breakdown of the gut lining, and certain food particles crossing the stomach-blood barrier and triggering an immune response. \n\nTwo separate doctors had told me confidently that gluten and other foods were not the problem and I had believed them. A colonoscopy, endoscopy, and multiple blood tests ruled out gluten as a source of my problem but at this point I was ready to try anything so I cut out _all_ FODMAPs. Growing up with a family that cooks and having already been cooking most of my meals at that point it was easy for me to experiment with my diet like that.\n\nI immediately noticed the difference. The first day without FODMAPs I had the best sleep I had in two years and by the second day the burning sensation had been reduced by 20%. It's hard to explain the emotions I felt as a result of all of that. Shock, hope, dismay, and excitement filled my entire soul that week. I couldn't believe that after suffering for so long I may have found a solution and that my problems may be near their end. I was afraid to believe but I also wanted to accelerate the process. Every day I ate this restricted diet I gradually got better: my pain began to recede, my bloating decreased, and I could feel my energy returning. With each day my stomach burned a little less and it felt as though a weight crushing me from all sides was being released. Finally I could see a light at the end of the dark tunnel. And yet there I was thirty pounds lighter than I used to be, skinny, weak, and a shell of my former self. So I set about recovering the rest of my body. \n\nI started off with pushups in my living room and then I went for short jogs in the park a few blocks from my house. I would stop by the pull-up bars in the park and simply try as many as I could. I could barely do three. With my pushups I could barely do 10. It was scary to see my body in such a weak state although unsurprising considering the weight I'd lost and the inactivity I'd experienced over the past two years. It certainly wasn't the first time I'd had to grow strong in the gym so I was used to this sort of progression and I invited the opportunity to overcome an obstacle that I could exercise my agency over. Each day I was able to do another pushup and another pull-up and run a little further. Each day gave me a little more motivation to keep pushing and keep fighting. I was thanking God every day for the chance to overcome the challenge of physical workouts instead of the challenges I'd been overcoming the past two years. Unfortunately I quickly ran into the limitations of my new diet: I wasn't getting enough calories. Funny thing about cutting out many foods is that you end up with not a lot of things to eat. And I was not eating enough.\n\nNow that I had a better idea of what to eat I needed to figure out how to eat that in sufficient quantities. My progress and improvement seemed to plateau as I struggled to get enough calories day to day. The psychological strain on me at that time during that plateau was unbearable. What if I slipped back into the pain I had just endured for two years? What if this was just a temporary respite? Maybe my diet wasn't the issue? Was this recovery just a random coincidence with my diet change? My pain was at around 50% it's original intensity at that point and the thought of slipping back kept me up at night. \n\nI didn't end up slipping back into pain and I continued to improve but the pain lingered for longer and my improvement slowed after that first month. Even today I am only about 60-70% of where I once was and I still sometimes experience occasional burning in my stomach.\n\n## Burning Out and Working With Pain\n\nWhen I graduated in the middle of COVID I pushed my start date up and immediately began working at Microsoft. I couldn't travel like I had originally planned and I was too weak and sick to do anything materially enjoyable at home so I figured I might as well start earning money. That ended up being a poor decision in retrospect. \n\nIn another attempt to escape my new reality I threw myself into work with no break after school. I plunged headfirst into the job and did everything I could to learn and grow. I taught myself as many new skills as I could around infrastructure, DevOps, feature development, and anything else that was thrown my way --- and a lot was thrown my way. I worked long hours and I _did_ learn a lot and grow as an engineer but it was all just a distraction from the daily pain I was experiencing. Eventually it wasn‚Äôt even a good escape. \n\nIt was an incredibly dysfunctional job with too much red tape and no reward for individual achievement and after 12 months of grinding without any healthy outlets like exercise or friendships I burnt myself out. My struggles over the previous two years and the bleakness of my future caught up to me. I was beaten down and exhausted. I trundled along for another 6 months before quitting and getting another job at Census. \n\nThis time I took a month off before starting my new role and traveled to Israel to relax and decompress. It was a great reset and when I got back I made it an explicit point to start a lot slower at Census. I was already improving quite well when I joined and I made sure to take advantage of my newfound health to live a more rounded life. At 5pm my laptop was closed and I focused on my wellbeing: cooking, going to the gym, going on runs or long walks, meeting friends, etc. This enforcement of boundaries between work and the rest of my life actually let me relax and improve much more efficiently and happily during the time I was working and it‚Äôs part of the reason my skills grew so rapidly early on at Census. \n\nAs my responsibilities grew at Census, however, I became more invested and my tasks became less clearly defined. I relished at the chance to take on bigger problems but working at the higher levels of abstraction also meant it was much harder for me to gauge how long a given task would take and suddenly I found myself working longer and longer. I would think to myself *just one more hour and I'll have this working* but three hours later I would be down an even deeper rabbit hole. When I would finally close the computer it was already late in the evening and I hadn't eaten dinner or worked out. I wasn't taking care of my base needs and that led to losing weight and stress and early signs of burnout.\n\nI've since tried to pare down how much time I'm spending in front of the screen but that hasn't really worked. Anyone who's experienced burnout knows that just reducing load doesn't always fix the problem once your mind is conditioned to feel stress and frustration on your daily tasks. It feels like all the accumulated burnout from COVID, school, and Microsoft are returning and I'm constantly trying my best to keep it at bay but even taking time off doesn't work. It's extremely frustrating because to be successful like I want to be sometimes you *have* to grind, especially when you're young and learning. I am not a perfectly efficient engineer and the only way to learn the things I need to learn is to grind but I cannot grind because if I neglect my base needs even for a day or two then I lose energy, I get brain fog, my sleep suffers, and I burnout. This is my constant struggle.\n\n## Moving Forward\n\nIf we fast forward to today --- around a year and a half after my recovery began --- I've been able to reintroduce most foods except gluten and I've regained 15 pounds of my old muscle. I'm feeling much better and I couldn't be more grateful and happy for my second lease on life and everything I've learned from the experience around nutrition and health but I'd be lying if I said things were perfect. I'm still underweight --- ideally I'd be at 155lbs instead of the 143lbs I'm at now --- and I still suffer from anxiety and stress around the whole incident. I still don't know what actually caused this problem and it's hard to shake the feeling that at any day I can wake up and lose the ability to eat a whole new food group and I'm already down dairy and gluten. My pickings are becoming increasingly slim and the consequences on my life are not trivial. Eating out is a constant problem and I never cease to feel like a burden to friends when picking restaurants. The corollary is I need to cook most of my meals which means a large majority of my free time is spent cooking food, cleaning dishes, cooking more, cleaning more, cooking more, cleaning more. Over and over and over and over. Meal prep and a dishwasher has made that part of my life more bearable but it's a literal constant drag on productivity. \n\nActivities that used to be fun escapes like going for a day trip to the beach or a two day hike now inspire anxiety around getting enough calories. The odds I'll find enough food to sustain me for such trips is low which means either I eat something I am allergic to and suffer for it or I get hungry in the afternoon and become a cranky person that is not fun to be around. I'm constantly trying to bring meal prepped food but even that's not easy because I can't just whip up a quick high-calorie sandwich or something equally portable because I cannot eat bread.\n\nI've learned how to expand my diet within the constraints I have but I *still* do not consistently get enough calories. I am almost always running at a near caloric deficit and that can be tiring in ways that are hard to describe. It's common for me to lose up to 5 pounds when traveling or on vacation for a week because I simply do not have my kitchen and groceries to implement my normal system of food. It still feels like I'm constantly playing catch-up and I have very little margin to let loose and live my life like I'd want to. I spend not just too much time but also cognitive energy making sure my body gets the fuel it needs to survive. Just to avoid the hell I experienced two years ago. \n\nThe psychological scars of the experience are still very fresh in my mind and I think that's going to be the last part of this whole ordeal that stays with me. I used to have an [undying confidence](/believing-is-the-difference/)  in myself and a self esteem that let me attack the challenges of life but that's mostly gone now. I have anxiety and bouts of fear and self-doubt frequently. My body sometimes looks alien to me and I find it much harder to take pride in myself and how I look. I don't trust my body to not fall apart on me when I need it most which makes me less willing to take risks or seize opportunities. Maybe this is just a signature of growing older but I no longer trust nature to spare me and I feel that I can die at any moment. I feel fragile in so many ways whereas in the past I always prided myself in being more resilient than my environment ever demanded. Now I am constantly facing feelings of inadequacy in the face of life's challenges but even worse, life's opportunities. \n\nIn October I will be moving away from my home in the northeast to go live and work in San Francisco. It has been a dream of mine to move west to Silicon Valley since I was young but now all I can think about is how I can build a routine to get the groceries I need and the tools to cook them and the time to make it all happen consistently. Even getting to this point where I feel I have the ability to move across the country to a new environment without falling apart is a huge step for me psychologically. I feel ashamed to tell people it's taken me so long to move because I'm worried about getting enough food. The blank stares on their faces always scream: *this is America isn't it? We have food here too.* But it's never so simple. I will have to build a whole new routine around getting high quality groceries and becoming acquainted with a kitchen and rhythm of daily life to make the food I need to eat consistently. Even a single day with less calories than I'm used to can mean dropping weight and feeling fatigued the next day.\n\nThere's not much of a moral to this whole story it's simply time I wrote it all down and there's still so much I left out. I have discovered so much about nutrition and my body. I have become increasingly prone to burnout and frustration. I have become disillusioned with the American medical system. I have spent two years staring into the abyss and I do not know how to capture all that in writing just yet. I have dreams of building my own company and achieving great things but now all those dreams come with this challenge attached. I still think it's possible to achieve what I want and I still stubbornly believe it's possible to regain all my former strength and resilience. Perhaps I will write another post more focused on the technicals of what I've discovered around nutrition but the high level of it all is this seems to be an autoimmune problem. If there's any part of the body that resembles software and is programmable it's probably the immune system and so I have hope. If my immune system can flip a switch and become allergic to these food groups out of nowhere then surely I can find a way to flip that switch back off and that is something I will do even if it takes me years.\n\nHell, maybe I'll even make this mission a business. It would certainly be nice to work on this full-time and I increasingly speak to people who are suffering from similar issues and would love a solution. I was blessed to be raised by parents who cooked almost every night and understand the value of good healthy food so when the time came I 1) made the connection between my problems and my diet and 2) had the tools to cook for myself to solve my problems. I'm constantly amazed by how many people suffer from so many issues and never realize that if they stopped stuffing their face with every variety of garbage many of their symptoms would be alleviated. Otherwise intelligent people continually fail to see the connection between what they put in their bodies and how they feel both physically and mentally. In America there seems to be a prevailing view that our minds are abstract separate entities when in reality our minds are the results of physical cells just like every other part of our body. We talk about the mind versus the body but these are systems that are intertwined and what you eat can most certainly affect how you think. Of course, my knowledge is admittedly far from complete in this domain and without any formal credentials I do not know how I would build a sustainable business for this just yet or what that business model would even look like. The hardest challenge for these things is most people simply aren't willing to help themselves. Anything short of a pill that can be prescribed is most likely doomed to fail due to lack of adherence. Most people aren‚Äôt willing to sacrifice half of what I have had to sacrifice just to recover to this point and I will need to sacrifice even more if I want to get to where I want to be. \n\nSo for now I will focus on myself. With the food I can eat I will regain my weight and strength. This time in addition to just strength I will focus on mobility and balance as well. I will focus on rebuilding my gut and reprogramming my immune system and flipping whatever switches need to be flipped to make my body behave normally again. As I prepare to move to a whole new environment with new challenges and opportunities I am excited for what is to come. I will build an iron body with more strength and resilience than I‚Äôve ever had and with that body I will seize the opportunities life throws my way.","src/posts/014-living-with-buggy-hardware.mdx","d249ffd3038a0802","is-tech-losing-its-leverage",{"id":164,"data":166,"body":172,"filePath":173,"digest":174,"deferredRender":22},{"title":167,"slug":164,"date_published":168,"description":169,"thumbnail":170,"tags":171},"Is Tech Losing Its Leverage?",["Date","2023-09-25T00:00:00.000Z"],"Software used to be the highest leverage differentiator between tech companies and the rest. I'm not so sure that's the case anymore.","tech_leverage.png",[],"**I was interested in business before I was interested in tech but when I fell in love with computers and taught myself how to code in high school it seemed like an obvious marriage between my skillset and interests.** At the time it felt as though tech was the highest leverage skill one could have when building or operating a business and it made sense that the darling companies of the day were all high growth tech giants like Google, Facebook, and before them Microsoft. These companies stood above most others because of the clear advantages and leverage that tech provided them. \n\nThe biggest advantage for software companies was zero marginal cost for increasing inventory. Consider a traditional automobile company that spends $10m to build 1,000 cars. If they successfully sell all those units they can only create another 1,000 cars if they spend another $10m and that's not to mention the time and cost to get assembly lines and manufacturing in place as well as the risk of recalls and other manufacturing defects that might eat into the profits. This is different from software companies where once the product is built the marginal cost of producing 1 copy of it versus 10 billion copies is simply the cost of creating a new CD. Once the consumer internet became fast enough and companies moved off of CDs in favor of downloading software the marginal cost actually reached zero. Microsoft might have spent $1 billion to build Windows (random estimate) but the cost to them for selling 100m copies of it versus 500m was the same. This allowed tech to scale far better than traditional business models. Sure, car companies might see savings from economies of scale but that's negligible compared to the scalability of software. \n\nYou might think the tradeoff for such scalability is higher upfront costs but upfront capex was almost always lower for tech than physical products and the margins much higher. It felt like every other billion dollar tech company was started by a couple friends in a garage or hobbyists and tinkerers plugging away at their code. There was not such a need for credentials or permission from investors and bankers just to get the funds needed to *try* a new venture. You could even build and distribute your software anonymously which opened the playing field to many people who were traditionally excluded from many avenues of business due to age, race, or sexuality. \n\nSoftware didn't just have better scalability and capex but also better logistics. You didn't have to spend time talking to suppliers, getting factories set up, dealing with regulators and governments, etc. You could just start building. And if you were good at building and you built something useful then you could create products that were used by millions with just a few people. And even once it was it built changing it or upgrading it was far faster and easier than traditional products where you needed to update factory processes and deal with the whole cycle around that. Software engineers could move massive building blocks with a few strokes of the keyboard and make sweeping changes to mature products faster than ever before.\n\n**The leverage provided by software that was once the obvious differentiator between tech companies and the rest is no longer so apparent to me these days.** Whether it was interning at Fortune-50 \"legacy\" companies, working at Microsoft, or hearing stories from friends at their tech startups the power of software to deliver business outcomes seems to be diminishing rapidly. Entire teams of engineers are employed to maintain simple features and new features are implemented at a snails pace. Adding new endpoints to an api gateway to enable a new product line at Microsoft was a multi-quarter endeavor. Changing simple UI components, fixing a deploy pipeline, adding a new api endpoint, fixing a bug and many other small tasks take weeks instead of minutes, even at tech companies an order of magnitude smaller than Microsoft. I personally have experienced this frustration countless times across every job I've had and every friend who works in tech has recounted similar frustrations even at some of the highest growth startups that are supposed to be agile and lean.\n\nThe experience I'm generally describing is work that Google calls [toil](https://sre.google/sre-book/eliminating-toil/) : fighting with the tooling, debugging dev environment problems, fixing CI/test flakiness, and everything else that isn't easily automatable but also isn't novel work nor related to the core value prop that the software is trying to provide. It sometimes feels like upwards of 70% of an average engineer's job is just toil these days except at a select few startups and I believe it's why so many companies slow their innovation and feature improvements to a crawl. Why do Notion, Airtable, the social medias, GitHub, Zapier, etc. all basically feel like the same products they were 3-4 years ago? Maybe this is what happens at scale: your core value prop is baked in and there's not much reason to rock the boat but perhaps I'm naive in doubting that many of these tech unicorns can justify their valuations in their current states. Airtable and Notion are two big examples here because they are solid products but in the enterprise space which they both [seem to be committing their focus on](https://www.airtable.com/newsroom/company/airtable-new-direction) they are competing with giants like Microsoft and Google. I don't see how a smooth but narrow product like they currently have can outcompete Office. And just because you have a solid core product offering doesn't mean you should take your foot off the gas in expanding its capabilities. Notion should want powerful spreadsheets embeddable in its documents and it should want notion pages that can become presentation slides and yet they don't seem to be able to build these features and even if they were to, say, buy Airtable is anyone confident they could actually integrate the two products in a way that's synergistic? Maybe I'm wrong to conclude that the reasons they *haven't* done these things is because of all the time they're wasting on toil and other tech debt but for whatever reason the challenge must feel too big for them and when you spend the majority of your time working on toil then it *is* too big.\n\n**My instincts tell me that as an industry we have taken two steps forward and four steps back in many regards.** For starters, you can throw away the zero marginal cost of inventory. Not because you can't distribute your product freely anymore but because it's quite rare for a company to actually do so. Instead the dominant business model is to distribute a license to use the product which is running on hardware in the cloud owned by the seller. This means that to increase units sold i.e. increase the active users you need more compute and the seller is paying for that compute. The cost to Figma for selling its product to 1,000 users is *not* the same as selling its product to 1 million users. Software as a Service has changed the scalability equations for software companies.\n\nSaaS comes with many benefits and there's a reason why it's become the dominant business model but it does mean that many companies have switched from product companies to quite literally service companies. How many of those benefits are actually software related versus business related? Investors and boards like recurring revenue because it's predictable and can be planned around. It also means you can potentially earn more lifetime revenue for a single customer even if the product doesn't change much. Whereas in the past you'd need to provide a new version of the product that is good enough to convince an existing user to upgrade, with SaaS they will continue to pay as long as they need their problem solved. Renting is more profitable than selling. But does it make it easier to build and distribute software? \n\nThe second problem that SaaS introduces is that products are never finished. In theory this is good: products should keep getting better over time but in practice this means that products are actually just sold before they are ready. This is not just a side-effect but an encouraged practice for startups and if you're a founder or investor this is great! It lowers the upfront capex requirements for building software products even more and gives you an opportunity to pivot earlier if you do not have product-market fit. The downside is you become beholden to paying users before you are ready. This can distort the incentives of product teams and companies as a whole which leads to feature-bloat and tech debt that is carried throughout the lifetime of the company. It's essentially a greedy algorithm for company building which disincentivizes proper software methodologies and patterns. Advocates for this playbook will correctly argue that code is not the product its just a means to an end but how many medium-size and growth startups are drowning under the weight of their tech debt? Would many tech unicorns be growing faster today without that early tech debt? Maybe scale is to blame here and there's no avoiding the slowdown that comes with success but I'm doubtful that explains everything. Is the ship-fast-at-all-costs model of company building a local maxima?\n\nIf we ignore the change in business models around software I feel that the adoption of agile methodology in many instances has hurt rather than helped productivity for the same reasons. Anecdotally speaking the enterprise organizations I've worked for that touted their agile work environment have used it as an excuse for shitty planning and irresponsible creation of tech debt. Of course, leadership will never actually allocate the time to pay down that debt but they love to listen to the troops so be sure to point out the cracks in the system during your next retro. If you're enterprising enough as an IC they'll encourage you to fix those issues on your own time (you won't have the resources to make the required cross-cutting changes ofc). I've even experienced the discouragement of *any* planning or technical specifications because it \"wasn't agile.\" You combine this with micro-services and you're guaranteed to reduce the pace of development by an order of magnitude and make the defining contributions of smart engineers the reordering of some buttons and the deployment of one or two new functions during their 3 year tenure at your company. This development style leads to a weird situation where so much engineering time is spent on random minutiae of these giant systems while at the same time the end-product feels so disorganized and unpolished. The rough edges show everywhere and the product improves at a snails pace because no individual or team is capable of moving large enough building blocks across the codebase. \n\nSpecifically relating to the tech we use to build I believe the unification around the web as the dominant runtime set us back in many ways. We had gotten pretty good at creating rich experiences using native apps and moving to the web nullified a lot of that tech tree. We became constrained by static hyper-text documents and over the past decade we've been reinventing all the tooling required to build those rich app experiences in the browser. The web also made us lose so much of the offline capabilities we used to build applications around. Maybe this helps for DRM and deploying updates but it means that any sufficiently powerful app needs to run on a server hosted by the company that built it and storage that used to come from a user's disk now needs to be paid for in \"the cloud\" and the surface area for security vulnerabilities becomes a non-trivial problem. It did allow us to unify around Javascript (although unification is a strong word) and avoid cross-compatibility problems of different operating systems but I'm not convinced that's a worthy tradeoff for what we have now. We are still hamstrung by supporting different browsers and mobile platforms while our best Javascript frameworks are only starting to catch up to some of the capabilities that we had a decade ago and the economic scalability of a software product is now worse than before.\n\nI strongly believe moving to the web also changed the way dependencies are used in software development to focus on APIs instead of libraries. APIs are rarely conformant to a spec like OpenAPI and are difficult to customize when necessary. How much time is wasted because your startup's subscriptions are handled in Stripe and your auth is handled in Auth0 and your secrets are managed in Doppler and half your application is spread across random AWS services so now a simple change to rename or add a payment tier to your offering is accompanied by the rewiring of all these disparate pieces tied into different places in the codebase. And if, God-forbid, you want to make a change or add something that is slightly out of the scope of what these services might provide you'll have to hack around their API interfaces instead of just modifying or forking a library. \n\n**It's not clear to me if this loss of leverage is even a real phenomenon or if I'm naively misremembering what once was.** I wasn't working professionally back before the dominance of web development and Javascript frameworks and everything else that has now become the standard. It's also not lost on me how requirements and expectations of tech and its applications today have grown immensely even from 15 years ago. Security, redundancy, usability, speed of development, support expectations, feature-sets, etc have all become much more complex and harder to fully implement. The demands from customers and the problems that tech is being asked to solve  continue to grow and it's possible the change in productivity I am describing is a result of that. \n\nAfter all, the cloud is ridiculously complex but it almost certainly lowers the barrier to entry by removing the need to manage physical servers in a fledgeling company. And for all the complexity of SaaS it does theoretically make software more profitable. Unifying around the web simplifies target runtime environments that need to be supported, deployments and updates can happen on the schedule that best suits the developer, and has lowered the barrier to entry even further by making Javascript a somewhat universal language. \n\nThese were necessary advances in the tech landscape because it means that many more people can build software to supply the exploding need of it. And maybe I have it completely backwards: tech has more leverage than ever because there's almost no such thing as a tech vs non-tech company if you look at it through the lens of using software in daily operations. Every company uses software to solve some problem and an increasing number of companies need engineers to build custom software even \"legacy\" brick and mortar companies like Starbucks and Dominoes. Maybe a bunch of the inefficiencies and problems I see today with software is a result of this influx of inexperienced and often young cohort of engineers in the workforce and the fact that these legacy companies can build software at all should be considered a raving success. It's obvious that a lot of the progress in the industry has been necessary and beneficial and maybe my disillusionment is the result of seeing how the sausage is made so to speak. I don't think that's the full picture here, though.\n\nAs I write this I realize I'm just describing the [Software Crisis](https://olivergilan.com/blog/software-crisis/) and maybe that's why I'm so frustrated by these experiences. It feels like every new language, framework, cloud provider, and random dev tool is claiming to change the way we develop and provide the solution to this development problem we find ourselves mired in but none seem to deliver on this promise. Not only does it feel like this problem is worse than before it feels like it's getting progressively worse. Surely as an industry we should be able to figure out why it often feels like making even small changes to codebases to add a feature or solve an underlying problem comes with so much baggage and effort for such little gain. As engineers we are failing to use tech to drive solutions for a business when we cannot implement necessary changes to products in an appropriate timeframe. Projects fail and companies die because of this failing. \n\n**I do not have a clear idea of what the solution looks like because it's not clear to me if there is a single cause to this problem of increasing toil.** We can start by creating better tooling to handle all the common problems that every SaaS product faces: pricing/account tiers, emails, common models like workspaces, organizations, users, etc, a variety of auth methods, trials, user invites, auditing, admin panels, OpenAPI-conformant endpoints, etc. There are some products in this space such as [Ship SaaS](https://shipsaas.com/), [Go SaaS](https://saasstartupkit.com/) and [SaaS Starter Kit](https://www.saasstarterkit.com/)  as well as others, but none of these sorts of solutions seem to be mature and well thought out enough to really solve these problems at scale. Another thing we can do is create new frameworks that handle many of these problems far better than they do today. Rails is the best web framework I've ever used and does basically everything right but it simply relies on too much magic with untyped Ruby and meta-programming. Combine that with Ruby's Object-Oriented design and the intense coupling to the DB with ActiveRecord and most Rails projects become incomprehensible at scale (I find this unfortunate because Rails is awesome and Ruby is far more beautiful than Javascript). At the risk of introducing yet another JS framework into the world it would be nice to see a Rails-esque framework written in Typescript with first-class support for reactive frontends and built-in standard library for solving most of the common problems web apps need to solve. \n\nEither way I do think this problem is solvable because many startups seemed to have avoided it. From the outside companies like Stripe (a few years ago), Replit, Linear, Tailscale, Ramp, Clickup and some others seem to innovate at a breakneck pace. It's hard to know if that's because they've actually solved a lot of the complexity and toil internally or if they just brute-forced this pace of delivery but from the outside they are releasing features at a pace that most companies simply aren't. It'll also be interesting to see how the culture of these companies changes over time as they grow and scale and if most of their shipping velocity is behind them. Can any of their lessons and philosophies be systematized and scaled to larger organizations? To more organizations? Oftentimes these companies are successful because they have a unique composition of 10x engineers that drive the core growth in the early years when the team is small but that's not a scalable strategy. As the need for software grows we need methodologies and tools that allow even 1x engineers writing software for your local DMV to ship quality consistently. \n\nThese days when I talk to my friends outside of tech I'm consistently surprised by how much better many of those opportunities appear to be. A friend working for a boxed wine startup that's only been around for 6 months is seeing higher growth and revenue than many startups I know that have raised tens of millions --- hundreds of millions even --- of dollars. And between AWS and all the other SaaS subscriptions modern tech teams use the margins on the boxed wine is far superior! Maybe the low hanging fruit in the enterprise software space is simply gone or maybe the requirements and expectations have outgrown our abilities. For one reason or another it feels like tech has lost its leverage.","src/posts/015-is-tech-losing-its-leverage.mdx","3ccbcd7bfa02ed43","i-moved-to-sf",{"id":175,"data":177,"body":183,"filePath":184,"digest":185,"deferredRender":22},{"title":178,"slug":175,"date_published":179,"description":180,"thumbnail":181,"tags":182},"I Moved to San Francisco",["Date","2023-10-01T00:00:00.000Z"],"It's time for a new era in my life. I'm now in the arena.","sf.jpeg",[],"Today I woke up at 3:30am, hopped in an Uber, and headed to JFK where I flew to my new home in San Francisco. This is the first time in my 25 years of life that I will not be living within an hour of my parents in the suburbs of NYC. I've traveled alone including a backpacking trip to Costa Rica, a month of working remotely in Brazil, and other fun trips here and there but never have I lived permanently in a whole new part of the world like this. \n\nThe word *permanently* is certainly doing a lot of work here. There's nothing necessarily permanent about this because a lot can change overnight and there's no real commitment for me to stay here if I don't want to. But I did not come here with the intention of going back tomorrow. Nor next week or month. So why did I come here?\n\nWell Census, the company I work for, is headquartered here but we have an office in NYC as well and it's not like I'm being forced by them to move. We also have a fully remote-friendly culture so I could theoretically have moved to any city as long as the timezones weren't obscene. So Census isn't the whole story. This city has more to offer than just that.\n\nFor starters, I needed to get out of New York. I was born in NYC, raised in it's suburbs, went to college in New Jersey, and then moved to Manhattan after graduating. I love New York and I love the chaos and dynamism and opportunity. I love the stories of the people there and I'm captured by the personality and history of its buildings, streets, and neighborhoods. I firmly believe it's one of, if not the, best city in the world. \n\nAnd yet everything about it is familiar. The weather and how it changes with the seasons, the shortening and lengthening of the days, the rhythm of the city over the hours, days, weeks, and months. The way the light bounces off the buildings, the manic drivers, the debauchery, the class. All of it is familiar and right now as I move on from my [long illness](https://olivergilan.com/blog/living-with-buggy-hardware/) and the world moves on from COVID I do not want familiar. I want new settings, new people, new challenges. I want to go out and see things I haven't seen before and inject a bit of entropy into my life as most young people should. Being alone so far from everything I know isn't a bug it's a feature of this move. \n\nSo why SF? There's a number of reasons but ultimately it *just makes sense*. At least for now. When I was young I always wanted to go out West, my job is headquartered here, I have a couple friends in this city from college and from work so I'm not starting completely from scratch, and if I execute on my dreams to start my own company any time soon then SF is a great place to be for that. I'll also be close to so many other awesome parts of America although I will be further from Europe which is a bummer. The opportunity for me to grow and improve on many dimensions exists in SF and that's ultimately what I'm excited for. \n\nI will have to go out of my way to meet new people and make new friends (if you're located in SF reach out to me!) and I'll have to build new routines. I'll be working in-person far more than I previously have which will be the first time in my professional career (apart from my first internship at Prudential) where that is really the case. I'll also be living with roommates for the first time since my Sophomore year of college pretty much. All of that means I'll have to put concerted effort into carving out high-quality personal time where I can be alone with my own thoughts as well. I'll also have the opportunity to take advantage of the natural beauty and abundant nature within a short distance of the city and relearn my old hobbies around sailing and surfing as well as some new ones. I'm starting with a blank slate here and I'll be presented with opportunities I would have missed in New York due to my entrenched patterns and behaviors. \n\nThe signs for my destiny point to SF in this moment but that can change and I will keep an open mind with all things. I want to give this city a fair shot and to me that means a minimum of 6 months but potentially even a year or more of living here. Life is unpredictable, however, and I may soon find myself moving yet again but even if I do I do not think I'll be going back to New York. The gravity of that city is powerful and I *already* have attractive opportunities there that would incentivize me to move back but I'm intentionally turning away from those for now. This is the time for me to explore the rest of the world beyond the New York metropolitan area and I'm going to take advantage of that. I'm going to seize the opportunities this city brings my way and my mantra for the next indefinite amount of months can be summarized with the following:\n\n\u003Cimg src=\"/images/give_me_stronger_battles.jpeg\" width=\"500\" />","src/posts/016-moving-to-sf.mdx","7f2490c8f710ed3e","changing-of-the-seasons",{"id":186,"data":188,"body":194,"filePath":195,"digest":196,"deferredRender":22},{"title":189,"slug":186,"date_published":190,"description":191,"thumbnail":192,"tags":193},"Changing of the Seasons",["Date","2023-09-27T00:00:00.000Z"],"Winter brings with it hard times and dark days but I am remembering what it means to find beauty in every season and what type of life allows me to do that.","fall_watercolor.jpeg",[],"I used to look upon the short, dark winter days of New York with dismay. The biting wind and dry air cuts through many layers of clothing and attacks any piece of exposed skin. The sky is dark when you wake up and dark when you leave the office. If it's not dark you're lucky to see the sun instead of a diffuse gray blanket of weak light. You're lucky if you feel direct sunlight on your skin twice a month. That's what I disliked the most about it all. The whole period of winter was depressing for me primarily because the sun is so far away. \n\nI really internalized the idea today that I no longer feel this way. Instead I am welcoming the changing of the seasons and as I do I remember that I didn't always fear the winter. When I was young I was excited for the new seasons and the changes they would bring. It felt as though every season lasted just long enough and the next one had a whole new way of life to shake up what had just become routine. Each season brought with it its own character and traditions and behaviors and mindsets. \n\nWinter was for working hard; for bearing down and focusing. All the plans set during the turning of the year and the goals set in the previous year were to be executed on and chased. It was a time to grow physically stronger. It was a time for nature and society to throw its hurdles at me and for me to overcome them. I grew physically older in the winters.\n\nSpring would roll around just as my body's battery was running low and all that was dormant sprang to life again. The flowers would bloom, the trees would bring color back to a grayscale landscape, and animals would return and one of those animals would be me. Spring brought with it an air of hope and good spirits. It would feel as if my own consciousness would bloom along with the flowers and my battery drained from winter was recharged.\n\nSummer followed shortly after with its freedom and time. In Summer I could move slower. I was unburdened by obligations of school and society so I could pause and take stock of what was around me. I would appreciate where I was and what I was doing and I could take that time to explore my curiosities and examine new sides of myself. It was a time where I grew mentally and emotionally.\n\nFall brought relief from the hot summer days and a time to connect with family both past and present. Cold dew-filled mornings served as a reminder that winter was coming and the easy times were ending but the holidays preparations for it easy. Dinners with family and friends brought me close to the people I love and the traditions of the holidays brought me close to my ancestors who went through those same traditions. Stories around the fireplace taught me the history of my parents and their parents. The shortening of the days and the falling of leaves was a stark reminder that nothing is permanent and that what matters is the ones we love and the the person we become. \n\nAnd now the seasons *still* represent all of that I am simply the one who forgot. As I got older and my family became far more fragmented I forgot the annual traditions. As I started to work my summers became less free and I took less time to pause and slow down. As I began to experience serious illness and injury for the first time I forgot what it was like to have absolute faith in my body to carry me through the hard times. But none of my earlier understanding of the world came for free I just didn't see all the work that went into crafting my environment. My parents put great effort into organizing large holiday gatherings and the natural schedule of school as well as family vacations provided natural moments for me to slow down and embrace my freedom. As I grow older I'm becoming more aware that such events are important to me for a quality life and that I must no longer rely solely on my parents to provide them. Instead the onus has fallen on myself and my siblings to bring our family together. It falls on me to carve out time for myself in the summers and to focus on my health and goals in the winter. The changing seasons reflect a world that is dynamic and alive and now it falls on me to live the type of life that reflects that. I believe I am finally beginning to do that.","src/posts/017-changing-of-the-seasons.mdx","9b1346ce449f9958","what-the-nfl-taught-me-about-business",{"id":197,"data":199,"body":204,"filePath":205,"digest":206,"deferredRender":22},{"title":200,"slug":197,"date_published":201,"description":202,"thumbnail":73,"tags":203},"What the NFL Taught Me About Business",["Date","2023-11-15T00:00:00.000Z"],"The NFL acts as a microcosm for business and can teach us lessons about building successful organizations from small startups to large companies. Understanding these lessons will shape the choices and effectiveness of both leadership and ICs and can radically alter the outcomes of a business.",[],"import Quote from '../components/Quote.astro';\n\nEach year 224 collegiate football players are drafted into the NFL across seven rounds. After the draft is over teams will sign undrafted players as free agents and currently the league is comprised of about 30% undrafted players with [15 of them](https://www.profootballhof.com/news/2005/01/news-undrafted-hofers/) having been inducted into the Hall of Fame. Of the 224 players that are drafted only about the first 10 are expected to be impactful enough to change the direction of a franchise. The first 32-64 players are expected to be good enough to play meaningful snaps (a unit of play) during their first two seasons. The rest are basically a tossup for if they even play a snap in the NFL and how their careers turn out. I can take 3 useful lessons from the NFL Draft that apply to business and life in general:\n\n1. Talent is not evenly distributed\n2. Talent is hard to measure\n3. True outliers are scarce\n\nIve learned these lessons and others from watching and loving the NFL but over the years I've begun to understand how they apply to other areas of life. So how does the NFL apply to business and startups? What can we learn just from the nature of the Draft and the composition of the league? Let's start with those three lessons of the draft.\n## Understanding Talent\n#### Lesson 1: Talent Isn't Evenly Distributed\nIn the world of programming there's the concept of a 10x programmer which is someone who is 10 times more productive than the average programmer. This idea gets a lot of [pushback](https://payne.org/blog/the-myth-of-the-myth-of-the-10x-programmer/) in engineering circles with many claiming such a person doesn't exist or isn't even *possible* but we can see in the NFL and in every other skilled endeavor that talent clearly isn't evenly distributed. What's so remarkable about the Draft is the stark divide even amongst the best of the best. The average college football player is easily 10x more athletic than a normal person and yet the ones drafted are 10x better than the average college player and then even amongst the pros at the top of their game the divide between them and a Top 10 Draft pick can be 10x or more. A player like [Nick Bosa](https://www.pro-football-reference.com/players/B/BosaNi00.htm) drafted 2nd in 2019 has recorded 15x as many sacks and 5x as many tackles as [L.J. Collier](https://www.pro-football-reference.com/players/C/CollLJ00.htm) --- another player drafted in the same position on the same year but 27 picks later. If Collier is a 10x football player (and being drafted in the first round means he is) then Bosa is a 100x player. The 10x programmer is absolutely real and so is the [100x programmer](https://twitter.com/dhh/status/1718347850361589947) we just don't have good stats to measure what that means.\n\n#### Lesson 2: Talent Is Hard To Measure\nTalent is easy to identify and hard to measure. For the best of the best talent can jump off the page at a young age and it's often easy to see if someone has potential but it can be a lot harder to determine how *much* potential someone might have. That 30% of the NFL is made up of undrafted players and that year after year we see undrafted or late Draft picks break out as stars shows just how difficult it is to evaluate talent. Tom Brady was the 199th pick in his draft and went on to become the best football player of all time. In business and especially programming the domain is so varied and the intangibles required by practitioners so great I would argue it's a lot harder to accurately measure talent than it is in the NFL. The average hiring process for companies is probably better than random but I'm not sure it's by that much. If you‚Äôre lucky enough to have a 10x engineer walk into your hiring pipeline it *might* be obvious that they're great but what about disambiguating everyone else? The candidates that might be a 1.5x or 2x engineer or 0.8x engineer? Good luck figuring that out. It's easy to want to hire the best but chances are you don't know who they are. \n\n#### Lesson 3: Greatness is Rare\nA great player can change the outcomes of games and even seasons. Great quarterbacks can change the outcomes of franchises. When Nick Bosa is injured or not playing the defense of the San Francisco 49ers is noticeably worse and when a star quarterback like Aaron Rodgers tears his achilles tendon it usually means the end of the season for the team. These players dominate the game but they are *rare* and we are lucky if we get one or two new ones each year. It's generally expected that the first 10 players in the Draft are the only ones with even the potential to be so good. Anyone who‚Äôs been responsible for hiring engineers at a company will have the same stories about the quality of their candidates: piles of candidates that struggle to code at all or cannot partake in even a modicum of social collaboration. Forget 10x engineers, finding someone even a little above average can be an extreme challenge. So ask yourself: why would a truly 10x engineer want to work for you? Why would they dedicate their time and efforts to your mission? The vast majority of companies ‚Äî even with a ton of growth potential and value for the world ‚Äî are not sexy or interesting. Payroll for construction isn‚Äôt captivating in the same way a space company might be even if its arguably more beneficial for the average person. So do not be surprised if you don‚Äôt get any 10x candidates especially when your ability to compensate them with competitive equity goes down after each successive hire. **10x engineers exist you just can‚Äôt hire them.**\n## How to Win Without the Best\nIf the NFL is any indication you don‚Äôt need a team of entirely A+ players to win. One of my favorite teams in the NFL was the New England Patriots with Tom Brady and for two decades they would enter the season with a team chock-full of B players and dominate the league. Over 20 years that team won six Super Bowls, nine AFC titles, and 17 division titles. They also had 19 consecutive winning seasons and nine straight AFC Championship appearances making them the most prolific team in football history. If they were a startup they would have been beyond a unicorn and one of the most successful companies of all time. So how did they do it? How did they routinely face teams with more talent and come out on top again and again?\n\nIt all comes down to building a great system. The Patriots faced many young, talented teams but such teams often had big personalities, big egos, and relied on their star players to execute in order to win. The Patriots on the other hand relied on a *system* that they had crafted and perfected over the years and this system enabled them to plug-in different players into different positions from game to game and season to season. The effect of this was resilience in the face of injuries, consistency across seasons with massive changes to the roster, and accumulated process knowledge. Cedric Chin at [Commoncog](https://commoncog.com/) notes that such systems can be extremely effective in business although often at the [expense of the enjoyment of its participants](https://commoncog.com/deming-paradox-operational-rigour/). Similarly the Patriots were known to be a grueling team to work for but the results were undeniable. When you have a competent system B and C players can produce at the level of A and B players --- and A players can become stars.\n\nBut \"build a great system\" isn't much more actionable than \"hire the best people\" so how do you actually execute on that? There's 3 characteristics/lessons of the Patriots system that I think apply well to business.\n\n#### Lesson 4: Do Your Job\nOne of the defining mottos of the Patriots and why they were so successful was the *Do Your Job* mentality. When teams rely on star power and raw talent it places pressures on individuals to overextend themselves and try to do too much. The Patriots made sure individuals knew their sole responsibility at any given time and then pushed them to focus just on that. If you do your part and the man beside you does his then the overall picture will come into focus. Just as in business one man cannot do it all but if you can focus on just one task then your teammates can learn to trust you to get your job done which allows them to focus just on theirs and then the whole team begins performing optimally. Peter Thiel takes this to the extreme by making sure everyone he manages only focuses on one thing:\n\n\u003CQuote author=\"Peter Thiel\" source=\"Zero to One: Notes on Start Ups, or How to Build the Future\" link=\"https://www.goodreads.com/work/quotes/25332940\">\nThe best thing I did as a manager at PayPal was to make every person in the company responsible for doing just one thing. Every employee's one thing was unique, and everyone knew I would evaluate him only on that one thing.\n\u003C/Quote>\n\nBy focusing on one thing you free people from the cognitive overhead of figuring out what to work on, you enable them to hyper-specialize and become one of the best at what they do, it becomes easier to evaluate their performance, and ambiguity around responsibility is reduced. Single responsibility allows B players to contribute meaningfully to a project often without slowing those around them and sometimes even performing at or above the level that a competitor's A player is performing because said competitor's attention is divided amongst multiple tasks.\n\n#### Lesson 5: Outwork Your Competition\nThe Patriots were known as a grueling team to play for and churn was high. Often-times veteran players would choose to play for the team for a year or two and take less money than they otherwise could get because the promise of greatness made it worth it. Win or lose, the Patriots consistently worked harder than most other teams in the NFL. Business is no different. Intelligent people often underestimate how sheer grinding can overcome differences in ability and talent. This is doubly true for people early in their career. It's remarkably obvious how much room I have to grow as an engineer whenever I work with a true 10x engineer and yet I can hold my own against these more experienced counterparts because I will simply put in more hours. I have less responsibility and more time and I can use that time to overcome the inefficiencies of inexperience. So if your team isn't all A+ players and you still want to win you should be prepared to work harder than everyone else and if your team *is* all A+ players and you don't want someone else to eat your lunch you should also work harder than everyone else. Working hard won't guarantee success but it does certainly feel like a prerequisite both in football and business.\n\n#### Lesson 6: Sweat the Details\nWhen everyone focuses on a single responsibility and everyone is working harder than the competition it unlocks a third characteristic of successful systems --- one that showed up again and again across the Patriot's dynasty: sweating the details. There is no better example of this than the [defining moment](https://www.youtube.com/watch?v=U7rPIg7ZNQ8) of SuperBowl 49 and the [practice leading up to that moment](https://youtu.be/_aaYTbaOCDY?si=V9Q127wPjK0a4NQf&t=2129). The Patriots were the most detail-oriented team in the NFL year after year and sometimes in a game of inches that isn't enough to win but after two decades those inches begin to stack up and you're left with a track record that blows everyone out of the water. This matters in business. The best products and the best companies are those where the details are cared for. This can only happen when people feel empowered over their small domain --- another thing that you get with the single-responsibility principle --- and when there's a culture of excellence. You must be dedicated to the craft and willing to invest time and energy to fix the little things even if they don't immediately translate to a metric improving. \n\nSweating the details is probably one of the rarest elements of businesses today and I can almost guarantee that any company at scale is *not* doing this which makes it one of the best ways for a startup to compete with incumbents. Over the lifetime of a company sweating the details will lead to loyal customers, a superior product, and superior execution. At the limit the details can even be a moat. Apple won not because its devices had better technical specs than those of competitors --- in many cases they were worse --- but because they offered fully polished experiences. My favorite app to use today is [Linear](https://linear.app/) (who's crushing it by the way) and it's not because they offer anything fundamentally unique compared to its competitors. On paper it has basically no differentiators and yet they sweat the details: the keyboard shortcuts for every action, the responsiveness of the UI, intelligent placement of elements in the design, etc. all combine to provide an experience that its competitors do not. \n## How to Build Your Team\nIf your system allows for singular responsibility, contains people working harder than your competitors, and encourages attention to detail then it'll be a winning system. This does not mean however that you can win with just anyone. My problem with the advice \"just hire the best\" isn't that it's untrue it's just not very actionable. A good system lets you win with less than the best but you still need to compose your team properly. So if you still need good people and the above is all true about talent being scarce then how do you actually build your team? Once again there are a couple principles from the NFL and the Patriots dynasty that I believe applies well to business.\n\n#### Lesson 7: Embrace Superstars\nOften times strategists and leaders fall in love with a system and then they make the critical mistake of thinking they can win with anyone. This can lead to the conscious or unconscious exclusion of superstars from the team because superstars are often destabilizing in nature due to their overwhelming presence and talent. A good system should take this into account and create an environment where superstars can thrive. Randy Moss was one of the best wide receivers of his generation with a [penchant for trouble](https://bleacherreport.com/articles/1500178-randy-moss-character-issues-prevent-him-from-being-the-best-reciever-ever) and a disregard for authority. By all accounts he was not a great fit for the rigid and strict Patriots team but during his tenure on the team from 2007-2010 his effect was undeniable. What was normally a good team became an unfair team and his first year there the Patriots won every single game of the season and is widely considered to be one of the best teams to ever play in a single season. \n\nWhenever you come across a Randy Moss --- a 10x player among 10x players --- you hire them and you find a way for them to be valuable. System believers often adhere to the rules a little too much and expect the same adherence from their superstars that they expect from everyone else. \"If I let you do X then I'll have to let everyone else do X\" is a common refrain that is simply wrong. Real superstars aren't the same as everyone else and if you need to bend the rules to keep them happy then bend the rules. Embrace superstars, remove anything that stops them from making an impact, and then let them do their thing.\n\n#### Lesson 8: Leaders Are Irreplaceable\nThis rule is not one I always understood but it became undeniable after the Patriots dynasty ended. It didn't end because they lost all their defensive players or all their receivers or all their linemen --- they've faced and overcome all those hurdles --- but because one player left: Tom Brady. When Brady left after a personal rift between himself and the coach, Bill Belichick, the dynasty was over. It turns out that the rigorous and efficient *Patriot Way* doesn't work after losing just a single key leader and today the team is a shell of its former self. A similar dynasty in the NBA is the San Antonio Spurs under head coach Gregg Popovich and star player Tim Duncan. For a decade they dominated the league with a strong system and focus on teamwork but it all sort of fell apart the moment Duncan retired. Similarly we see incredible businesses with a total understanding of their market and a bright path forward suddenly stagnate and collapse when a star CEO or executive leaves. All these instances have led me to understand that systems are valuable but capable leaders are irreplaceable. **The leaders *are* the system.** \n\nIf anything this lesson should help reconcile what I said before with traditional startup advice. It *is* genuinely so important to hire A players early on in the life of a company because the people you hire early will grow into leadership roles and thus they will dictate what the system looks like in your company. In a traditional B2B SaaS basically everyone should be an A player at the Series A. By Series B you can probably introduce a couple of capable B players that demonstrate an ability to learn and grow and then by Series C you will have to probably introduce around 20% B players but you can probably avoid C players. These numbers are meant to be more directionally relevant as opposed to exact descriptions. The overall truth is that the average caliber of employee will *have* to go down as your team size increases but by the time you get to Series C you should have a strong cultural system driven by great leaders that allow those lower performers to bat above their weight. \n\nI should briefly note that leadership can be explicit or implicit. Early employees will always influence the culture and system in place even if not formally promoted into leadership positions. Just the deep knowledge of a system can be enough to make an IC a leader and there are very interesting human dynamics that will inevitably form around implicit hierarchies such as these. Do not assume that you can just hire an IC early on with little impact to the overall culture of the company.\n\n#### Lesson 9: Help People Grow\nIf you want B and C players to perform better than they otherwise could and if you want your early employees to grow into the competent leadership your company will need then your system and culture will *need* to help people grow. The Patriots didn't just draft and sign the best players they focused on players that could learn and then they taught them how to succeed. Year after year they had one of the best offensive line units in the league and it was mostly due to coaching. Their Offensive Line coach, [Dante Scarnecchia](https://en.wikipedia.org/wiki/Dante_Scarnecchia), grew up around football and coached on the Patriots for 34 years! He was extremely experienced not just about football but also about teaching and the results of his coaching showed up on the field every year. \n\nIt's undeniable that great coaches and teachers in any field can make an incredible difference in the performance of their students and business is no different. The single-responsibility principal makes it easy to keep people in a box performing the same work that they've mastered over and over but talented people in such positions will grow bored and leave. If someone is capable of mastering a given domain there's a good chance they can master the next, harder, domain as well. You should identify people's strengths and their propensity to learn and grow and then do your best to keep giving them new challenges and responsibilities at a rate that lines up with their zone of proximal development. This rate will be different for everyone but successfully understanding and taking advantage of this as a boss is probably the best way to keep smart employees engaged on the mission while growing their abilities. \n\nCompanies that rely on college and university to do the teaching for their future employees will be at a sore disadvantage to the company that hires people with talent and ambition and then follows up by giving them the tools and mentorship required to make them succeed. As a leader you should absolutely be focusing on your company's onboarding process, your company's knowledge distribution process, your employees' rate of growth, and anything else that can dictate or explain how a given employee may grow over time. If you're an ambitious young person chase great leadership over maximizing salary early in your career. Great leadership that can make you great is rare and consequently if you're one of those great leaders that can significantly increase the abilities of others then that's one of your best assets for competing against FAANG companies offering higher salaries than you can afford.\n\nSo in the end a system and culture that helps people grow will attract more ambitious and intelligent young people, turn its early participants into the capable leaders needed as the company grows, and help B and C players perform above their level. \n\n___\n\nAs a fan of the NFL I am constantly reminded of these lessons and others throughout the year and I cannot help but notice them occur in other aspects of life. The NFL acts as a microcosm for business and can teach us lessons about building successful organizations from small startups to large companies. Understanding these lessons will shape the choices and effectiveness of both leadership and ICs and can radically alter the outcomes of a business. As third parties these choices will affect us as we are all dependent on organizations, whether private companies or government agencies, to work competently and create goods and services that improve our lives.\n\nThese principles apply to all the institutions around us and they are quite effective at understanding why some businesses are more successful than others, why some governments are more effective than others, etc. At the end of the day if you want to accomplish great things with others you will be working on the same substrate of human behavior and the dynamics that will make your group successful are the same principles that make sports teams, businesses, governments, etc. successful. As I interact with such institutions more and more I will have to update my understanding of these principles so that I can use them effectively in my own endeavors.","src/posts/018-what-the-nfl-taught-me-about-business.mdx","2b486f1aeddfd7b9","goals-for-2024",{"id":207,"data":209,"body":214,"filePath":215,"digest":216,"deferredRender":22},{"title":210,"slug":207,"date_published":211,"description":212,"thumbnail":73,"tags":213},"Goals for 2024",["Date","2023-12-09T00:00:00.000Z"],"Taking stock of my progress.",[],"A year ago I [wrote down my goals](/goals-for-2023/) that I hoped to accomplish during 2023 and now is the right time to take stock on what happened this year, how I did against those stated goals, and what I'm looking forward to in this coming year.\n\nI categorized my various goals into career, health, adventure, and mind. When it comes to my career I redacted most of the goals but the few I wrote down I did not achieve. I did not get super into LLMs and I can't really bring myself to get excited about the AI hype-train. I simultaneously did not take part in interviewing at all but I do think my work had a sizable impact and I'm proud of what I accomplished here. There is still a lot more to do but I believe I made the most of the opportunities I was given and delivered on the promises I made.\n\nJumping to my goals around adventure I definitely fulfilled those:\n- Live in San Francisco for a month and work out of Census HQ\n- Travel alone to a country that speaks a foreign language\n- 2-day motorcycle trip across the Moroccan desert\n- Wild card adventure\n\nI traveled alone to Brazil last Christmas and stayed there for all of January, living for a bit in Porto Alegre and then in Rio, where I made friends, learned Portuguese, and worked remotely. That was fun and rewarding and it helped me regain some of the confidence in myself that I'd lost. I did not do the 2-day motorcycle trip but I did move to SF in October and now I'm living here and working out of the Census office and it's been great so far. I've been meeting new people, making new friends, bought a motorcycle, and overall been really enjoying living in a new city for the first time in my life. I also traveled to Portugal with some college friends in the Summer and traveled around the entire country from Lisbon to Albufeira to Porto. We befriended a couple Dutch travelers, a Ukrainian refugee, and some Portuguese locals to make for an exciting experience. I'm more than satisfied with the adventures I've partaken in this year. \n\nMy goals around my mind focused on my communication and more specifically:\n- Post at least once a month on this blog\n- Share my writing more publicly\n- Add a blogroll of other independent blogs I am inspired by\n- Write some non-technical posts about topics such as education, my illness, etc. \n\nI did not post once a month but I'm happy with how much I've written. I released 10 posts this year and I have at least one more (maybe two) to come before the end of the year. Ultimately the quantity is less important than the quality with writing and I do believe the quality of my writing is improving while also engaging with more interesting topics. I wrote more non-technical posts such as my experiences [developing then living with an autoimmune problem](/living-with-buggy-hardware/), my [move to SF](/i-moved-to-sf/), my growing appreciation for the [changing seasons](/changing-of-the-seasons/) (something I don't really get in SF), and why [believing can be the difference](/believing-is-the-difference/) between succeeding and failing. I also wrote some more technical posts about career and tech including the [Software Crisis](/software-crisis/), the [6 questions](/6-questions/) that I regularly think about and would love to see answered/solved in my lifetime, the importance of [thinking short and long](/thinking-short-and-long/), and what the [NFL taught me about business](/what-the-nfl-taught-me-about-business/).\n\nI did not really share my writing more publicly and I'm still quite embarassed when I learn that people I know in real life read my blog but more people in my life have definitely been reading it and I've even gained some job opportunities from this blog in the past year. I've also expanded the site to include a blogroll as well as a reading list of books I find valuable and I hope to continue expanding it to include more things beyond just blog posts/essays.\n\nSo for all of those above goals I'm pretty happy with their outcomes but my greatest frustrations and failures surround my goals for my health:\n- Weigh 155 lbs by EOY\n- Run 10 miles at a pace of 8 minutes a mile\n- Be capable of performing a split\n- Perform reps on the ab wheel from a standing position\n\nThe only somewhat success I had here was around running. Near the end of this Spring I canceled my gym membership and just began running and doing calisthenics and it was a phenomenal decision. Leaving the office at 5pm and having the beautiful summer New York weather did not inspire strong workouts indoors under fluorescent lights so instead I spent that time running and exercising outside which gave me an opportunity to start running seriously. Up to that point I'd run 6 miles once in my life and my average run was around 2 to 3 miles. A couple months later on September 11 I ran 10 miles for the first time in my life with an average pace of 8:41/mi. Over the next two weeks I ran 10 miles two more times at paces of 8:54/mi and 9:04/mi. Then last month I ran 11 miles at 8:48/mi. My aerobic endurance is higher than its ever been and I can comfortably run 4 miles on my worst days when I've had shitty sleep, no food, and feeling weak. At this point my average run is about 5-6 miles and I'm working on improving my speed. At the start of this month I ran 5 miles at 7:58/mi. I am happy with my progress towards this goal but I could have gone even further. Recently I've started lifting again 2 days a week and I can immediately notice that slowing me down and making it harder to push the distances but it's worth it as the weather becomes colder again. I have no desire to push the distance beyond 10 miles in any material way mostly because 1) it takes a long time and it's hard to regularly find multiple hours to dedicate just to a single run and 2) aerobic endurance is just one component of my overall fitness and I don't want to maximize that at the expense of everything else. In my opinion you see dramatically diminishing returns to increasing distance beyond 10 miles. So for now I'm focusing on keeping my average run length at around 6 miles with occasional 10 milers and pushing the speed.\n\nApart from that I failed at all my other health goals. I didn't even work on doing a split and performing a rep from the ab wheel in a standing position so those were failures but the worst failure is around my bodyweight. I do not currently weight 155lbs and I instead weigh 145lbs --- the same weight as when I started the year. I did gain weight this year reaching 149lbs on two different occasions but proceeded to lose the weight every time due to traveling, moving, and other general stressors. I'm now unhappily plateaued at the same weight as when I started and I consider this an utter failure. Ironically enough the part of the year I saw the most success in gaining weight were the summer months when I was running consistently and doing calisthenics. \n\nThe biggest bottleneck around my weight as well as my general happiness and ability to achieve the rest of my goals is the allergies to dairy and gluten that I developed three years ago. These allergies are highly problematic because they severely limit my access to otherwise healthy calories and nutrients that my body could use (basically all the calories and nutrition from most salads come from their cheese components). High quality dairies and glutens contain critical nutrients for overall health and are often far healthier than modern alternatives like fake butters and other processed foods that are chock full of vegetable oils. Currently if I eat these foods, however, I will experience severe inflammation, bloating, a weakened immune system, and excess fatigue. The inflammation in my gut will prevent efficient metabolization of the other foods I eat and will make my various tendons and joints more susceptible to injuries while exercising. My energy levels will drop, the pain will cause brain fog, and ultimately I will find myself sleeping for longer periods so I can recover. I [wrote](/living-with-buggy-hardware/) about my experience when these allergies first developed and how physically and mentally painful and exhausting it was to constantly have my body attacking itself due to gluten. I was in constant pain, lost a ton of weight, and became a shell of myself. I simply cannot go back to that. \n\nIt is because of these restrictions that my diet is actually the most important piece of all my goals. The allergies force me to spend a lot of cognitive and physical energy maintaining this part of my routine and the consequences of failing here disrupts every other area of my life. Because of these restrictions I cook basically all of my meals which simply adds up to a lot of *time.* Buying groceries, preparing, cooking, then cleaning, then repeating that 3 times every day can quickly accumulate to many hours each week. At least once or twice a day I have to context switch from whatever I'm doing to think about what groceries I have and what I need to buy, what meals I can make with the supplies I have, what the timing will be for when I'm home and can start cooking, etc. Then I have to spend the time actually cooking and cleaning and I have to do this every... single... day. It's mentally and physically draining and it takes up far too much time that I could spend working towards my other goals. And most frustratingly is that none of this work compounds. Every single day my caloric situation resets to zero and I have to start the whole process of getting enough calories from scratch. It's a persistent and daily tax on my productivity.\n\nThese dietary allergies also make it almost impossible to rely on getting an easy bite to eat when out and about. While it may not be the healthiest option if you find yourself out late with friends or at the office it's normally trivial to grab a slice of pizza or a burger. Sure maybe you eat unhealthily for one meal but then you can still sleep at night and have the energy to recover and exercise and get back on your routine the next day. If I find myself in that situation I can either eat a food that will act like poison, go hungry and have a tough time sleeping, or wait until I'm home and make some food quickly which may disrupt my sleep schedule but at least I get the nutrients I need (if I happen to have any ingredients in my fridge). Basically in every case I lose weight or mess up my routine because the inflammation of eating gluten destroys my appetite and not eating means I don't get the calories I need and not getting enough sleep means I have to skip a workout the next morning. I constantly have anxiety around being spontaneous and social because of worries around finding food and it forces me to play it safe and reduce my surface area of luck more than I'd like. **Reducing this dietary burden is one of the highest leverage problems I can solve to free up my time and enable me to achieve my health, career, and personal goals.**\n\nMeal prep can help reduce this burden but it's not without its problems. For starters I cannot travel with a week's worth of meal prep so any time I want to go on a week-long trip I'm either confined to getting a place with a proper kitchen (hotels never do and AirBnB's are hit-or-miss) and buying a bunch of groceries or operating on a caloric deficit for the week. That's partially why it's so important for me to gain weight: if I weighed 155-160 lbs with 3-4% *more* body fat than I have now then I could more easily handle those weeks of traveling on a caloric deficit. As it stands now I have basically no buffer room with my body weight. Secondly, meal prepping isn't easy! I still need to spend a bunch of time figuring out *what* to make and then buying groceries and doing the bulk cooking. I should be able to do this but it takes discipline so that I do not miss the day I'm supposed to do the cooking. It also lends itself to eating the same thing every day which is not the worst thing --- better to eat the same healthy foods every day than varied unhealthy foods --- but eating an unvaried diet can make you more susceptible to developing food allergies and I suspect that's at least partially the cause of me developing allergies to dairy and gluten. If I lose another food group it's over for my ass. But these roadblocks are surmountable. I need to figure out what a somewhat varied meal plan is that I can make in bulk at the start of the week and just pull from that throughout the week. I'll still have to spend time reheating and cleaning for every meal but in a pinch I can rely on a microwave and eat right out of the tupperware. It's definitely an improvement over cooking every meal from scratch and I've had a lot of success with it in the past I just haven't developed a proper routine for it since moving to SF.\n\nThere's another solution besides meal prepping and that's simply to cure my allergies altogether. When it comes to my goals for 2024 this is the only one that really matters to me. **By the end of 2024 I must be able to eat gluten and dairy again without any adverse reactions.** I need to dedicate serious time to figuring out how to make that happen and I'm willing to forego a lot to accomplish such a feat. I firmly believe curing these allergies is possible and I have the inklings of a plan for how to do it but I need to sit down and make the plan concrete. It's gotten to the point where I feel significantly hindered in my other pursuits because of these dietary problems and I'm willing to make a big sacrifice to get back to where I am. I'll give up my net worth, my job, and all my other goals for the year if it means I can get back to a fully healthy and functioning body. As long as I have my health I can get back to where I am with ease. I have some other goals besides this but they're all secondary.\n\nYou can sum up my goals for 2024 as:\n- Cure my dietary allergies\n- Run 10 miles @ 8:00/mi\n- Weigh 155 lbs by EOY\n- Find a wife","src/posts/019-goals-for-2024.mdx","9cc14ab676c3f49f","kidney-crisis",{"id":217,"data":219,"body":225,"filePath":226,"digest":227,"deferredRender":22},{"title":220,"slug":217,"date_published":221,"description":222,"thumbnail":223,"tags":224},"Kidney Crisis",["Date","2024-02-04T00:00:00.000Z"],"Nearly a million people in the US suffer from total kidney failure yet only 20,000 kidneys are available for transplant each year. The kidney crisis is only getting worse and needs a revolution to solve it.","silicon_kidney.png",[],"In the time it takes you to read this post at least one person will have died waiting for a kidney transplant. Kidney disease is the 10th biggest killer in the US and is estimated to rise to the 4th or 5th biggest by 2040. About 1 in 7 people suffer from some form of kidney disease and over 800,000 Americans are living with total kidney failure also known as end-stage renal disease (ESRD). For many of these patients death is the most likely outcome but that may change in the next 10 years. \n\nI was born with one kidney but I was not aware of the implications of that until recently when I had a health scare two years ago. I had always just assumed kidney disease was a solved problem with transplants and dialysis but what I've learned that's far from the case. In this post I want to share some of the issues and exciting new developments I've learned about over the past year and a half. \n\n## Causes of Kidney Failure\n\nThe most common cause of kidney failure is diabetes which accounts for nearly half of the new cases in the U.S. Nephron cells in the kidney responsible for filtering blood are damaged when exposed to repeated high blood sugar and high blood pressure so it should not come as a surprise that kidney disease is on the rise at the same time that obesity and diabetes [is exploding](https://www.cdc.gov/diabetes/data/statistics-report/index.html) in the US. Unless [semaglutide](https://www.drugs.com/semaglutide.html#:~:text=Semaglutide%20is%20the%20active%20ingredient,in%20type%20two%20diabetes%20patients.) reveals itself to be safe over long periods of time, becomes cheaply and widely available, *and* proves effective at preventing diabetes then we can expect this trend of kidney failure to continue. **As of 2020, kidney disease is the fastest-growing noncommunicable disease in the U.S.** \n\nKidney failure doesn't happen overnight and it's estimated most individuals suffering with partial kidney failure are not even aware of it and many people never realize they are experiencing total kidney failure and die from lack of treatment. Kidney health is assessed by measuring the total [glomerular filtration rate (GFR)](https://www.kidney.org/kidneydisease/siemens_hcp_gfr#:~:text=GFR%20(glomerular%20filtration%20rate)%20is,of%20CKD%20in%20an%20individual.) which just amounts to the total amount (ml) of blood your kidneys are filtering per minute. The stage of kidney disease a patient is experiencing depends on their GFR with a value below 90 indicating the beginning of kidney disease, a value below 30 indicating severe reduction in capability of the kidneys, and a value below 15 indicating a patient is experiencing ESRD with a requirement for dialysis. These numbers can vary depending on age, sex, and body size. \n\nGFR is usually measured with a complex procedure using blood plasma or monitoring urinary clearance over an entire day so doctors generally do not measure it directly and instead estimate it using a person's creatinine and cystatin C level in combination with factors such as age, race, and gender. This estimate usually shows up on routine blood exams performed at an annual checkup with a PCP under the label eGFR. Being aware of this value over time is important to understand if you should make lifestyle changes early on to prevent kidney disease from progressing.\n\n## Treatment\n\nI was born with one kidney but never gave it much thought because I, like many people, went my whole life assuming kidney failure wasn't a big deal anymore. I thought the advent of kidney transplants meant that if necessary I could simply get another kidney if mine failed and the odds that I would be compatible with a family member willing to donate one is --- or at least was in my estimation --- high. This turns out not to be as great of a solution as I first thought. \n\nThe transplant solution in which the kidney of a living or decreased donor is matched with a patient and then surgically implanted into their body is the best solution we currently have for people experiencing kidney failure. Only a minority of lucky patients will benefit from it though. **There were only 26 thousand kidney transplants performed in 2022 and of the 130,000 new patients diagnosed with ESRD that year only a little more than 3,000 of them received a transplant.** The rest went on dialysis. \n\nIf you're lucky enough to get a transplant you will need to take immunosuppressant drugs for the rest of your life. Just like any organ transplant the body is immediately aware that the tissue of the new organ originated from outside itself and will begin to attack it with the immune system unless suppressed. These drugs are costly and need to be taken every single day for the rest of your life. Your immune system will be compromised from these drugs making you a patient and at-risk for events like COVID for the rest of your life. \n\nThe real kicker? **Kidney transplants don't last forever.** Even with the immunosuppressants the [half-life for a transplanted kidney is 11 years and only 7](https://pubmed.ncbi.nlm.nih.gov/33346917/#:~:text=Median%20survival%20for%20deceased%20donor%20transplants%20increased,11.7%20years%20in%20the%20most%20recent%20era.) when from a deceased donor. There is also a chance of your body suddenly rejecting the kidney far sooner even with the help of drugs. This is usually not seen as an issue because most patients experiencing total kidney failure are older but as kidney disease begins affecting people at younger ages it will become more common to get a transplant and then end up back at square one when the transplant expires. \n\nIf you are not fortunate enough to get a transplant you are put on the waitlist and your only other option in the meantime is dialysis. Hemodialysis is generally performed in a clinic 3 to 4 times a week in sessions of 4 to 5 hours and involves incrementally removing all the blood from the body, running it through a series of semipermeable tubes surrounded by a dialysis liquid which separates the toxins from the blood through the principle of diffusion. \n\nDialysis works in the sense that it can keep you alive (barely) but chances are you will not be able to live a normal life while relying on it. Nearly half of patients who reach ESRD and receive hemodialysis are under the age of 65 (working age) and [71% of them](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3082405/) are unemployed despite being employed prior to dialysis. If you can maintain employment and a normal routine during treatment then it may not be for long. **Of all the patients receiving hemodialysis [68% of them die in the first 5 years](https://www.renalfellow.org/2018/09/19/what-are-survival-rates-for-dialysis-patients/).** The survival rate of patients on long-term dialysis has even been shown to be shorter than many cancers. The supposed solution to kidney failure that I'd heard about my whole life is less of a solution and more of a bandaid on a gaping wound. You do not want to find yourself in a position where dialysis is necessary to survive because odds are, you won't. \n\nThere is a newer form of dialysis called peritoneal dialysis which uses a similar concept to hemodialysis but is much easier to perform. It involves pumping dialysate into the abdominal cavity and relying on osmosis to pull toxins from the blood into the dialysate before draining it. This can usually be performed by the patient themselves at home or on the go which allows for more continuous treatment of the blood. Because the blood is filtered more often the survival rate is higher than hemodialysis but only a little (52% over 5 years). \n\n## Revolutions in Waiting\n\nThe most surprising part of my reading and talking to people in the field over the past year and a half was learning just how few resources are available to solve this problem. Since 1987 the standard treatment for kidney failure has remained largely the same we've simply increased the scale at which that treatment is available. Kidney disease was considered a solved problem with the widespread availability of dialysis and nephrology became viewed as a boring field of medicine as a result. Most of the nephrology training programs in the US could not fill all their vacant spots in 2018 and the MDs matching in nephrology [declined by 12%](https://asndataanalytics.github.io/AY-2019-Match/). The vast majority of funding and attention goes towards flashier parts of the body such as the brain and heart. Only in recent years has the government realized the shortcomings of dialysis and committed to spending more on better solutions. As a result many private startups and labs have begun experimenting with next generation treatments.\n\nThere are three main branches of progress in the space: better dialysis, growing/harvesting real kidneys, and building an artificial kidney. \n\n### Better Dialysis\nThe better dialysis branch of progress is centered on just that: creating better methods for performing dialysis. This generally boils down to making it easier for a patient to perform dialysis on themselves so that they can do it more regularly, or even constantly, with less chance of error. There is some progress in this area with promising results of [small dialysis machines worn like a backpack](https://pubmed.ncbi.nlm.nih.gov/27398407/) as well as small bedside machines that can be used while sleeping. In the end, though, many of these solutions fail to pass final FDA approval and generally do not receive enough funding to reach mass market. The reliance on dialysate also imposes a challenge on miniaturization as it is a consumable liquid that needs to be constantly replaced as it is used.\n\nIt would be great to see progress in this branch reach the mass markets but I'm skeptical that this approach can deliver significantly better outcomes than it already does.\n\n### Growing Kidneys\nA much more fascinating branch of progress is in growing kidneys themselves. While dialysis focuses on treating the problem that arises with kidney failure growing kidneys aims to solve the transplant supply bottleneck because transplanted kidneys have much better mortality outcomes than dialysis. \n\nOne way to grow kidneys is to let nature do it for us and then just harvest them which is what researchers have been trying to do with pigs and it's shown some promise. Researchers at NYU and the University of Alabama have both successfully [transplanted genetically modified pig kidneys](https://nyulangone.org/news/pig-kidney-xenotransplantation-performing-optimally-after-32-days-human-body) into humans while maintaining functionality. All of these transplants have taken place in brain-dead patients but the latest experiment has shown the kidney to be functional for 32 days after transplant. The genetic modification is necessary to prevent immediate rejection by the host body but otherwise it seems that pig kidneys are close enough in function and throughput to act in place of failed human ones. This could dramatically increase the supply of kidneys available for transplant but it certainly raises some ethical concerns and as a Jewish man I'm not sure I'd want a kidney from a pig. It's also not an optimal solution because far more immunosuppressants are required to make this work than for a normal kidney. It's likely that these kidneys will have a shorter half-life after transplantation and leave the patient in a weaker state than a regular human kidney but if the outcomes are still better than dialysis that could be a worthwhile tradeoff. \n\nThe second approach to growing real kidneys is to quite literally grow them in a lab using stem cells. This approach is still in its infancy and although [there has been progress](https://www.nature.com/articles/s41587-022-01429-5) I would not expect this to be available to patients for another couple decades at least. Ultimately this *could* be the holy grail: a full human kidney, grown for little cost in a lab with customized antibodies to prevent rejection completely without the use of immunosuppressants. This is the approach that is furthest from being ready but it is the ideal and should be invested in far more than it is today. The science is still young and the hurdles to making this a reality are massive but it's a moonshot that we should chase.\n\n### Building an Artificial Kidney\nThe last approach, and the one I'm particularly excited about, similarly aims to solve the transplant supply issue while being financially cheaper than both transplanted kidneys and dialysis *and* also being available far sooner than grown kidneys. The efforts to [design and build an artificial kidney](https://pharm.ucsf.edu/kidney) are being led by Dr. Shuvo Roy and William Fissell, MD at UCSF and Vanderbilt respectively. The idea is that when it comes to filtering the blood within the human body you don't need a full biological kidney and a silicon-based implantable device can be manufactured for cheap and replace the need for human kidney donors.  \n\nThe device consists of two main parts: a hemofilter and biochamber which respectively work to separate toxins from the blood and produce urine just like a normal kidney would. The hemofilter is built around a semipermeable silicon wafer with slit-shaped pores just 7nm in width. When blood flows over this membrane it is partitioned at a molecular level as big protein molecules --- such as albumin --- cannot pass through the pores while water, salt, and small toxins can. Using [photolithography](https://en.wikipedia.org/wiki/Photolithography#:~:text=Photolithography%20is%20a%20subclass%20of,magnetic%20fields%2C%20or%20scanning%20probes.) and other techniques used in the manufacturing of computer chips it's possible to design these semipermeable membranes with the precision and scale that's required for this selective filtration. \n\nThe albumin and other proteins that don't pass through the membrane are immediately recycled back into the blood stream while the water, salt, and toxins dissolved in them are passed into the biochamber. The biochamber is the only part of the device containing biological material and consists of human renal tubular cells which are responsible for reabsorption of the salt and water. The cells transport these water and salt molecules to a separate channel where they are recycled back into the blood just like they do in a real kidney. This leaves only the toxins remaining where they condense as urine and are passed directly into the bladder. \n\nThe beautiful part of this device is the lack of a power source. The internal blood pressure of a patient is enough to push blood through the device just like a regular kidney so no pump is needed which means this can be implanted in a human much easier than other solutions. The lack of dialysate also means there is no consumable element of this device so as long as the semipermeable membrane remains structurally sound and the renal cells remain alive this device can remain in the patient for the rest of their life. \n\nFurther, because only the dissolved water, salt, and toxins are entering the biochamber the patient's immune systems won't even be aware of the presence of external cells. The only organic part of the device is completely separated from the rest of the blood by the silicon membrane. This would allow a patient to not only restore their kidney functionality but also keep their immune system intact.\n\nThe challenges --- of which there are many --- come down to ensuring that no part of the device --- especially the semipermeable membrane --- form blood clots over time, culturing the renal cells, making sure they stay alive within the patient, and monitoring the performance of the device. The problem with silicon is that it's naturally not very hemocompatible and blood clots will form on the membrane over time. To prevent this Dr. Roy and his team applied a polyethylene glycol (PEG) coating to the membrane which successfully prevented blood from clotting but was not durable over time longer time periods. PEG is aqueous so it's not a great candidate for durability in the human body. More recently they experimented with polysulfobetaine methacrylate which showed extremely little erosion over time, is non-toxic, and prevented blood clotting even better than PEG. The existence of these coatings and the ability to find new, better coatings, will only improve and I'm confident that this part of the device is already at a stage where it can be commercialized.\n\nThe bigger challenges surround the renal cells. For the renal cells to perform their task they need to be cultured to the point of [differentiation](https://en.wikipedia.org/wiki/Cellular_differentiation) which is where they express specific genes to perform the function they are designed for. Typically renal cells have been difficult to differentiate in a lab which means they would not actually perform their jobs of transporting the water and salt ions but Dr. Roy and his team have not only discovered how to do it effectively they've even tested these cells in a device implanted in a pig and they performed as expected. The key then is to ensure they can handle the throughput necessary for a human. In a real kidney these cells perform many functions beyond the reabsorption of salt and water but in this artificial device we only need that one function. By genetically engineering these cells to be more efficient at reabsorbing salt and water we can make them capable of handling human loads. Dr. Roy and his team are working to optimize that process now.\n\nAnd then in the end we need to monitor the device so that any loss of functionality or structural damage can be diagnosed and dealt with. Once a device is in a patient it will not be easy to inspect the device but low-powered onboard chips and sensors can be used to wirelessly transmit important diagnostics for monitoring. These chips would need to be powered by the human body as the device will not have a power source itself. \n\nJust about all of the remaining problems to overcome for this artificial kidney are engineering in nature and do not require a deep insight. I'm confident that with enough funding and time Dr. Roy and his team will be able to create a fully functioning form of this device at a scale for humans to use.\n\n## Path to Market\n\nI'm hopeful about the future of ESRD treatment because we are seeing a convergence of many different solutions all at once but also because the non-technological factors at play are coming together in a way that should make progress possible. For any of these treatments to reach real patients and make a dent on the problem they need to pass regulatory bodies and be financially viable for companies to both invest in and for patients to pay for. When it comes to solving the non-technological problems of reaching patients I believe an artificial kidney is best positioned to win and here's why.\n\n### The Tech\n\nWhen it comes to the tech better dialysis is just that. Quite frankly better dialysis would be great but in comparison to fully restoring a patients functionality and reducing adverse outcomes, it's sorely lacking. \n\nOn the other hand growing real kidneys is extremely technologically advanced. Too much so. Growing a kidney custom for each patient so that the immune system fully accepts it is the holy grail but it's still a question if that's even possible or not. Either way, the tech for that is far out and unproven. Harvesting a kidney from an animal seems to work and is already being tried in real patients --- brain-dead patients but patients altogether --- but can be considered equal or worse than getting a human kidney transplant. You still need to suppress your immune system (even more so than for a regular transplant) but at least this option seems viable. If you do not care about the optics of having an animal's organ in your body then getting a pig's kidney could definitely be preferable over dialysis if those are the only two options.\n\nAnd then there's an artificial kidney which wouldn't require suppressing the immune system at all and could in theory last the entire lifetime of the patient. Even if it had a lifetime of 20 years that could still be a superior option to anything else. The technology here is has been tested in both dogs and pigs for varying periods up to 30 days and is simple which reduces costs and reduces the chance of something going wrong. Unlike better dialysis or kidney harvesting the technology here is superior but it's also far more viable and mature than custom grown kidneys.\n\nThe challenges remaining for the artificial kidney are almost fundamentally engineering in nature and not requiring immense scientific breakthroughs. Money can solve engineering problems but it can't increase the speed at which new insights are attained. This bears well for the artificial kidney.\n\n### The Regulatory Environment\nThe regulatory environment is also uniquely aligned to bring these new technologies to market. One of the big changes was President Trump signing [Executive Order 13879 on Advancing American Kidney Health](https://www.federalregister.gov/documents/2019/07/15/2019-15159/advancing-american-kidney-health) which explicitly aims to open the door towards tackling the kidney crisis. Among other initiatives to improve preventative care the Order explicitly calls for policy to **\"increase patient choice through affordable alternative treatments for ESRD by encouraging higher value care, educating patients on treatment alternatives, and encouraging the development of artificial kidneys.\"**\n\nThe Order goes on to explicitly call for regulatory bodies such as the FDA and Congress to increase their support and collaboration with the private sector to develop an artificial kidney.\n\n> **Sec. 6**. _Encouraging the Development of an Artificial Kidney._ Within 120 days of the date of this order, in order to increase breakthrough technologies to provide patients suffering from kidney disease with better options for care than those that are currently available, the Secretary shall:\n>\n> (a) announce that the Department will consider requests for premarket approval of wearable or implantable artificial kidneys in order to encourage their development and to enhance cooperation between developers and the Food and Drug Administration; and\n> \n> (b) produce a strategy for encouraging innovation in new therapies through the Kidney Innovation Accelerator (KidneyX), a public-private partnership between the Department and the American Society of Nephrology.\n\nDr. Roy and his team has been awarded multiple prizes by KidneyX for their work on the artificial kidney and has been in contact with the FDA for years now, ironing out what it would take to get to clinical trials. The FDA granted Dr. Roy's device [Breakthrough Device](https://www.fda.gov/medical-devices/how-study-and-market-your-device/breakthrough-devices-program) designation which speeds up the regulatory review process during premarket development and in discussions with Dr. Roy he's described to me the criteria the FDA has laid out before they grant approval for clinical trials:\n\n1. The device must not produce blood clots\n2. The device must not activate the immune system\n3. The device must successfully produce urine.\n\nIf they device can be shown to fulfill all of the above for a duration of 30 continuous days in a pig without breaking and without any assistance from the pig's natural kidneys then they will grant clinical trial approval. \n\nBecause the components of the device have been developed in different stages each part of the criteria has been tested to varying degrees. Animal ethics boards will not allow you to test a full device for 30 days right out the gate so instead each experiment needs to be tested for 3 days, then 7 days, then 30 days. The semipermeable silicon membrane was developed first and has thus been tested for 30 days successfully. The biochamber was developed second and has been shown to not trigger the immune system for up to 7 days successfully. The last component of the biochamber which is the proper functionality of the renal cells to produce urine has been shown to successfully work for up to 3 days in a pig. The last few experiments for those components are in the process of happening as his lab waits for more funding. In the meantime they are working to improve the throughput of the device to meet the scale of a human body. **It's very possible this device will enter clinical trials within a couple years.**\n\nIt's so rare for medical devices and medical innovations with such a large potential impact on the world to have the bureaucratic machine removing roadblocks for it. This isn't just limited to the work of Dr. Roy but it does inspire confidence that if this technology fails to reach the markets it won't be because the FDA killed it prematurely.\n\n### Financial Viability\nThe last component that determines whether a technology will reach the market is its financial viability. This includes both how much it'll cost to develop it as well as how much it'll cost to produce it once developed. I am less familiar with the financial environment for other branches of progress but I can talk about what it looks like for the artificial kidney and the market as a whole.\n\nDr. Roy has been working on the artificial kidney for nearly two decades by relying exclusively on federal grants, private donors, and university funding. He believes today that he only needs $10m to achieve approval for clinical trials. To date his lab has raised around $13m over the past two decades. These are paltry numbers compared to the investments VC's regularly pour into startups and the potential impact of such a device vastly outstrips the potential of said startups. This is also an order of magnitude cheaper than it would cost to develop the science to grow real kidneys in a lab. In terms of R&D the science around developing a silicon-based artificial kidney is far cheaper than the R&D for fully growing a kidney.\n\nOnce it is developed Dr. Roy believes early versions of the artificial kidney will be comparable in price to normal transplants which puts it at around $200k but the ongoing lifetime cost of the device is far less than a transplant because the patient will not require expensive immunosuppressants. It's not unreasonable to believe this price will go down as production of the device is scaled and I can envision a world where this price is driven down to be even cheaper than dialysis.\n\nThe interesting wrench in the market around the device is who the buyer actually is. Namely, it's not the patient who's paying for the device and it's not necessarily even their insurance. It's Medicare. To understand how kidney treatment works today you need to go back to 1972 when Congress passed the [Social Security Amendments](https://arc.net/l/quote/tfockhwf) that guaranteed coverage for treatment of ESRD regardless of age effectively making Medicare the biggest customer in this market. This move was in large part due to the mistaken idea that dialysis was \"the cure\" and that by heavily subsidizing it the government could prevent a large chunk of the population from dying or being unproductive. Unfortunately now most dialysis patients still die and are not economically productive until that happens. \n\nMedicare pays for dialysis treatments after 3 months for anyone with ESRD, subsidizes kidney transplants, and pays for immune-suppressing drugs ~~for 3 years~~ (EDIT: **Comprehensive Immunosuppressive Drug Coverage for Kidney Transplant Patients Act** passed in 2020 extends coverage to the lifetime of the patient) post surgery even if they are under the age of 65. In 2019 Medicare spent nearly [$90,000 per patient](https://www.cdc.gov/kidneydisease/basics.html#:~:text=Total%20Medicare%20fee%2Dfor%2Dservice,the%20Medicare%20paid%20claims%20costs.) with ESRD totaling $37 billion in costs. These patients make up 1% of the Medicare beneficiaries but account for 7% of total Medicare costs. The cost per patient living with a kidney transplant averages $30,000 per year just to pay for their immune drugs. These staggering costs is a large reason why the government is actively trying to encourage better solutions to the kidney crisis and Dr. Roy's team, in conjunction with a medical economist, concluded that even conservative estimates show their artificial kidney would save Medicare $10 billion annually.\n\nThis subsidization by Medicare screws up the incentives for any product or service trying to enter the market. Insurance companies do not feel the need to find or fund a solution because once a patient reaches ESRD they can pawn them off to the government and the pharmaceutical companies are happy to sell the immunosuppressants no matter who is buying. Any solution that aims to reach the market needs to get the stamp of approval from Medicare so that it can be reimbursed or payed for by the government just like dialysis is so Dr. Roy has tried to get this approval ahead of time but their answer is clear: they want a better solution and are open to changing the rules around what's covered but they need to see clinical approval first. So for now, it's all about developing the device further to get it tested in real patients.\n\n## Looking Forward\n\nThe kidney crisis is a problem that threatens the health of the nation. It drains our Medicare system of its funds, it takes hundreds of thousands (and soon millions) of people out of work, and leaves our country weaker. When speaking to Dr. Roy it's obvious that he's passionate about this problem and his team has been making incredible progress the past two decades. Besides him there are incredible researchers and doctors working around the world to materialize a revolution in kidney treatment with many of them showing promise. I personally believe an artificial kidney such as the one that Dr. Roy is designing offers the best potential outcomes with the most achievable hurdles to overcome. I'm hopeful that in my lifetime (and hopefully quite soon!) we can see the kidney crisis become a thing of the past and I hope if I ever find myself in need of another kidney to complement the one I have that I can reach for a solution that gets me back to full health without compromises.","src/posts/020-kidney-crisis.mdx","936337b18518fce4","full-gluten-tolerance",{"id":228,"data":230,"body":235,"filePath":236,"digest":237,"deferredRender":22},{"title":231,"slug":228,"date_published":232,"description":233,"thumbnail":73,"tags":234},"Full Gluten Tolerance",["Date","2024-03-25T00:00:00.000Z"],"In the summer of 2019 I became violently ill and lost the ability to eat gluten. Over the past two years I've slowly gained some tolerance back and I outline my plan herein to regain full tolerance for eating gluten.",[],"**Overview**: Summer of 2019 [I became violently ill](/living-with-buggy-hardware/) and only recovered after cutting out all [FODMAPs](https://www.hopkinsmedicine.org/health/wellness-and-prevention/fodmap-diet-what-you-need-to-know#:~:text=FODMAP%20stands%20for%20fermentable%20oligosaccharides,digestive%20distress%20after%20eating%20them.) for a significant portion of time. Over time I successfully reintroduced most FODMAPs except for gluten. Even up to a year ago gluten would trigger an immediate and severe immune response which resulted in rashes, red skin, and bloating. Today after two years of cultivating my microbiome through diet and behavior I can now eat small amounts of gluten with less severe immune responses. The following protocol is designed to accelerate the last bit of recovery and get me back to full gluten tolerance.\n\n**Thesis:** Dysbiosis[^1] & disregulation of intestinal tight junctions[^2] lead to immunogenic gluten peptides[^3] crossing the intestinal lining and triggering an immune response. Altering intestinal microbiome composition and fixing tight junction functionality via the reduction of zonulin[^4] will restore gluten tolerance.\n\n**Timeline:** Mar 17 - Jun 29 (14 Weeks)\n\n**Goal:** Achieve full gluten tolerance.\n\n## Protocol\n### Stress Reduction\n| Metric | 7d avg | 4w avg | Goal |\n| -------| -------------| -----| -----| \n| Resting Heartrate| 53bpm | 52bpm | 47bpm |\n| HRV | 60ms | 59ms | 80ms |\n| Stress Score| 30 | 32 | 15 |\n| Sleep Score| 77 | 75 | 95 |\n[^5]\n\n- 60mg full spectrum CBD daily (30mg x 2 daily)[^6]\n- 600mg KSM-66 Ashwagandha (300mg x 2 daily)[^7]\n- 1000mcg Vitamin B12 daily[^8]\n- L-Theanine 200mg daily[^9]\n- 20min breath-work daily (10min x 2)[^10]\n- 30min sunlight daily[^10]\n\n### Microbiome Rehabilitation\n- 24h fast biweekly[^11]\n- 72h fast once[^11]\n- 20g insoluble fiber daily[^12]\n- 10g soluble fiber daily[^12]\n- Fermented foods with each meal[^13]\n- Reduced animal proteins[^14]\n- 800g of vegetables daily (6-8) different sources[^15]\n- Low FODMAP, low GI meals[^16]\n- Acidic component to every meal[^17]\n\n### Exclusion List\n- Alcohol[^18]\n- Weed[^18]\n- Caffeine/Coffee[^19]\n\n## Philosophy\nSince I got sick most of the symptoms and recovery has been very much what you would expect with an autoimmune disease. My family is at risk for a variety of autoimmune disorders and we have a history of psoriasis. It certainly *seems* like my immune system is being activated when I eat gluten and so it might make sense to take drugs designed for those sorts of problems. [Biologics](https://www.fda.gov/about-fda/center-biologics-evaluation-and-research-cber/what-are-biologics-questions-and-answers) like Humira are a powerful tool for people with autoimmune problems like this. That being said I do not want to take that path because \n1) those drugs are expensive and it would be one more hassle to worry about if my health insurance changes. (edit: literally just quit my job before posting this so my health insurance will, in fact, change)\n2) those drugs have nasty side effects and don't travel super well due to refrigeration needs.\n\nI was healthy my whole life without drugs and I see no fundamental reason why that cannot be my future. I believe the following: a switch was flipped one day that made me intolerant to gluten (I do not have CD according to blood tests) so I just need to flip that switch back.\n\nThis protocol is not designed for the rest of my life it's designed for right now. There are clearly people who drink alcohol and coffee and eat worse diets than me who can digest gluten just fine because the body is a resilient system. But the body is also a complex system-of-systems and in such complexity positive feedback loops can occur that prevent the return to homeostasis. I'm hoping this protocol can get my body back to a functioning state so that I can remain healthy even while living a less strict life.\n\nI expect this protocol to adjust over the course of these 17 weeks and I won't have 100% adherence. I will track my progress and any changes to the protocol and make that data available on this blog at a later date. At the end of this time I will undergo a gluten challenge where I eat gluten normally for a full week and write up the results. The biggest constraint here is my bodyweight. When I became sick I very quickly lost 30lbs and I've regained 15 of those pounds over the past two years of recovery. I'd like to keep gaining weight but I suspect this protocol will make that difficult due to the reduction of red meat consumption as well as regular fasting. I will have to track my weight over these weeks to ensure I do not lose weight. I do believe if my gut heals then we could see my weight go up as I'll be inclined to eat more and absorb more of the nutrients in my food. \n\n## Science + References\n\n[^1]: [Dysbiosis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4838534/#:~:text=Dysbiosis%20is%20defined%20by%20an,bacterial%20distribution%20within%20the%20gut) is a broad term that means an imbalance in the composition of gut bacteria. The food you eat doesn't feed you it feeds the bacteria in your gut which break it down into components that your body absorbs along with byproducts called [metabolites](https://www.cancer.gov/publications/dictionaries/cancer-terms/def/metabolite) which affect various systems in your body. The composition of your gut bacteria matters because different strains of bacteria feed on different foods and produce different metabolites. These metabolites can promote or suppress inflammation, regulate the intestinal lining of your gut, affect your mood, and change the way your body absorbs various nutrients. Different strains of bacteria also breakdown food into different components. As it relates to gluten, depending on how this complex protein is broken down can determine if it results in immunogenic molecules or not.\n[^2]: Intestinal tight junctions are protein complexes in the intestinal skin that regulate the movement of molecules across the gut barrier. It is critical for nutrient absorption and controls the balance between tolerance and immunity to non-self antigens. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6311762/#:~:text=Adjacent%20intestinal%20epithelia%20form%20tight,water%20across%20the%20intestinal%20epithelium)\n[^3]: Immunogenic gluten peptides are components of gluten that when isolated during digestion cause an immune response. These peptides are not always exposed during gluten digestion and thus its hypothesized that many gluten-related problems may be the result of incorrect gluten digestion. My hypothesis is that if this is what's occuring inside me then fixing my gut composition will fix this.\n[^4]: Zonulin is the only human protein discovered to date to directly modulate functionality of tight junctions. Zonulin overproduction has been shown as a biomarker of impaired gut barrier functionality and is a specific marker for many autoimmune diseases. Zonulin inhibitors like Larazotide acetate have been shown to significantly reduce autoimmune symptoms for patients with celiac disease. It can be hypothesized that the overproduction of zonulin leads to intestinal tight junction impairment and what's commonly known as leaky gut syndrome which leads to immune response. If this is the case then if I reduce serum zonulin levels I should see a reduction in immune reactions to gluten. The composition of the microbiome as well as stress *may* both lead to zonulin production which is why a big part of this protocol focuses on the reduction of baseline stress levels. [Source](https://www.frontiersin.org/articles/10.3389/fnut.2020.00152/full) [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3384703/) [Source](https://sci-hub.se/10.1016/j.biopsycho.2018.08.013) [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10569989/)\n[^5]: There are other ways to measure stress such as a cortisol reading from a blood test but I am using these proxies instead because I can get somewhat reliable continuous monitoring of them from my garmin. Heartrate and HRV are also good proxies because they correlate strongly with your internal vagal tone. We know that stress causes dysfunction of the intestinal lining by stimulating production of zonulin. The key here is I'm trying to reduce baseline stress not peak stress. When I work out or run hard I will experience peak stress and in those times I actually have a very good stress response because I'm a fit individual. The real problem is all the other moments when I should be relaxed but my baseline level of stress is just a little too high causing this constant drip of zonulin and cortisol. To understand how to reduce baseline levels of stress you need to understand the nervous system, namely the autonomic and sympathetic parts of it. The sympathetic nervous system activates the fight or flight mode in humans while the autonomic nervous system balances it out and calms you down. Normally these two systems are in a tug of war with the autonomic system keeping you calm most of the time and your sympathetic nervous system giving you energy in acute moments when you need it. It's possible for the autonomic system to become weak and unable to effectively balance out the sympathetic system leading to higher levels of baseline stress and it's this sort of imbalance that can lead to a bad positive feedback loop: higher stress leads to improper digestion leads to less nutrition absorption leads to worse sleep leads to more stress. So my main strategy for reducing baseline stress levels is to boost the functionality of autonomic nervous system and the biggest component of that is the [Vagus nerve](https://my.clevelandclinic.org/health/body/22279-vagus-nerve). The vagus nerve is one of the key pathways in which the gut communicates with the brain and vice versa and there is [evidence](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5859128/) that various vagus nerve therapies can reduce inflammation. HRV is a [great proxy](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6996447/#:~:text=The%20link%20between%20vagus%20nerve,established%2C%20correlating%20with%20vagal%20tone.) for understanding the health of the vagus nerve.\n[^6]: CBD has been shown to be significantly effective in controlling stress responses in humans. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8704602/)\n[^7]: Ashwagandha, specifically the KSM-66 variety has been shown to be significantly effective in controlling stress response in humans. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8762185/)\n[^8]: Vitamin B12 is highly correlated with HRV levels specifically when studied among stroke patients but this is unsurprising considering B12 is critical for nerve health. I believe that adequate B12 levels would correlate to a healthier vagus nerve which would lead to improved HRV. that being said my B12 levels are not low nowadays (I unfortunately don't have data from when I was sick for this metric) so I don't expect this to make a huge difference. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10118344/)\n[^9]: L-theanine has been shown to reduce stress, anxiety, and improve sleep in humans. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6836118/)\n[^10]: I feel I do not need to even provide sources for these two. Breathwork has been shown to clinically reduce stress levels and Vitamin D is critical for reguating the immune system and stress levels. I prefer raw, organic, unfiltered sunlight beyond just Vitamin D supplementation and I live in an area of the world where I should be able to get 30 minutes of sunlight a day but in days where I can't I will supplement.\n[^11]: Fasting can have a profound effect on both the immune system and the gut's microbiome. Studies have reported significant positive changes in the composition of gut bacteria for people undergoing intermittent fasting as well as prolonged fasting. Dysbiosis is simply an imbalance in gut bacteria usually because one or two strains have grown too large and are outcompeting the other strains. Prolonged fasting can be effective at reconsituting this composition by restricting energy to the dominant strains. Fasting is also effective at retraining the immune system. Many studies show that a 72hr water fast is a tipping point where the immune system activates different pathways to recycle old damaged cells and replace them with new ones. I'll admit I do not 100% understand the mechanisms here and I need to read more but I'm hoping that near the end of this protocol I will have fixed the root of the issue (leaky gut) and a 3-day fast can help retrain my immune system almost as a \"factory reset.\" It's possible that intermittent fasting would actually be more effective here but I worry about my tendency to easily lose weight and I feel it would be easier to maintain or even gain weight while doing more targeted prolonged  water fasts. Fasting is valuable but I do not want to sacrifice my weight so if I find bi-weekly to be too often I'll adjust. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10495574/) [Source](https://www.cell.com/cell-stem-cell/fulltext/S1934-5909(14)00151-9)\n[^12]: Fiber is incredibly important for the composition of the gut's microbiome due to the generation of SCFAs and the bacteria that it supports. **If there is an 80/20 for improving gut health then fiber is a part of it!** It effectively lowers the GI of meals by protecting starchy carbohydrates from being atttacked by enzymes which slows the conversion into glucose. High fiber diets have been shown to correlate with a reduction of symptoms for a variety of autoimmune diseases including psoriasis. Fiber regulates inflammation in the gut and the SCFAs like butyrate play an important role in protecting the gut's mucus layer and inducing new generation of Treg cells which help calm the immune system. Dietary fiber does come in insoluble and soluble form and they do behave differently in the body. Generally I'm trying to get a total of 30g of fiber which is the recommended daily intake amount but specifically want to focus on insoluble fiber for its role in generating SCFAs. This is harder to get through just pure eating and will probably have to be supplemented and I will also be careful to slowly ramp up my intake to not overwhelm my system. Also most importantly fiber acts as prebiotic that supports valuable strains of gut bacteria and can help rebalance the composition of the microbiome. [Source](https://pubmed.ncbi.nlm.nih.gov/29950699/) [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7432353/#B28-ijms-21-05405) [Source](https://www.gisymbol.com/low-gi-explained/) [Source](https://www.ucsfhealth.org/education/increasing-fiber-intake) [Source](https://www.todaysdietitian.com/newarchives/0816p34.shtml) [Source](https://www.todaysdietitian.com/newarchives/AS20p24.shtml)\n[^13]: Just about every civilization in human history has had a diet with a fermented food as its staple and the effect they have on the gut can be profound both in the short and long term. One of the most effective changes I've made over the past two years has been to increase the amount of fermented foods I eat (saurkraut, kimchi, miso, etc) and I credit it to a large part of my recovery. These fermented foods have live cultures which seed the gut with valuable bacteria and lead to long term diversity gains in the microbiome. I'm aiming to eat a portion of something fermented with every meal following --- or along with --- the intake of fiber so that these cultures have a better time colonizing in my gut. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9003261/)\n[^14]: This one is controversial and there's a lot of conflicting evidence but it does seem like animal proteins and red meats specifically create more oxidative stress which can lead to gut inflammation. Red meat is abundant in saturated fatty acids which induces inflammation and heme which in turn leads to gut dysbiosis and reduces the synthesis of butyrate. Red meat intake is also correlated with autoimmune diseases but there's so many confounding factors in such studies that it's hard to know if it plays any significant role. I want to maintain my weight and strength and I'm already so limited on what calories I can consume that I will not cut it out completely but just reduce my intake. [Source](https://pubmed.ncbi.nlm.nih.gov/29759553/)\n[^15]: This basically just amounts of getting enough fiber plus some good micronutrients. Should be easy.\n[^16]: FODMAPs are sugars that are absorbed poorly and ferment in the small intestine. Cutting out FODMAPs was originally how I began to recover and whenever I get a bad flare up it is a strategy that helps control it. I maintain a mostly low FODMAP diet today but with this protocol I want to be stricter there for the time being which mostly amounts to cutting out various sources of sugar. Glycemic Index (GI) is a measure of how carbohydrate foods affect blood glucose levels. High GI foods spike blood glucose and lead to crashes that result in a food coma. Low GI foods are absorbed by the body slowly and give more steady levels of energy over the course of a day. When your blood glucose spikes your body releases more insulin which causes a whole host of problems including diabetes. Higher blood glucose can lead to inflammation and immune activation which is what I'm specifically trying to avoid.  [Source](https://www.gisymbol.com/low-gi-explained/) [Source](https://www.levelshealth.com/blog/metabolic-health-101) \n[^17]: The presence of acid in the stomach slows down the conversion of carbohydrates into glucose which lowers the overall GI of a meal. This is one of the reasons fermented foods are so healthy. [Source](https://www.gisymbol.com/low-gi-explained/)\n[^18]: Alcohol is just not good for the gut, it's not good for the immune system, and it's literally just bad. I probably won't be able to cut it out completely during these 3 months of spring but I will significantly reduce my consumption which is already low. I am not certain of marijuana's effect on inflammation but I tend to either have or notice more inflammation oftentimes when I smoke so I will cut that out for now too.\n[^19]: There is limited evidence concerning coffee and the microbiome. It's generally accepted that coffee alters the composition of the microbiome in a significant manner but it's not clear from what I've read if it's a good thing or a bad thing. My prior is that coffee is bad for the microbiome but recent studies show that it may increase microbiome diversity and reduce inflammation. It's hard to know what's real so I will overweight my priors for now and simply maintain a reduced consumption of coffee. If I need the occasional caffeine I will use green tea. [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7282261/) [Source](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096519/)","src/posts/021-full-gluten-tolerance.mdx","1bd1323f620f8f43","visceral-moments",{"id":238,"data":240,"body":245,"filePath":246,"digest":247,"deferredRender":22},{"title":241,"slug":238,"date_published":242,"description":243,"thumbnail":73,"tags":244},"Visceral Moments",["Date","2024-06-24T00:00:00.000Z"],"There are moments in life that are more than just mere memories of events. They are memories of feelings stored in the body itself and they are what makes a life full.",[],"There are distinct memories in life, like birthdays or breakups, but then there are moments that are far more real. They stay with me only as a feeling. For some of those moments I will never experience them again such as the last day of school before summer break with all the apprehension and excitement in the air before hearing the final bell ring and running out of the air conditioned building to feel the warm air on my face knowing that for two months, I was free. But for many of these moments I can and do experience them again now as an adult and when they happen I find myself anchored in the present. They do more than just remind of specific memories and events they make me remember what it's like to live every moment totally absorbed in reality rather than living in the abstract space created by my prefrontal cortex. They are memories stored in the body itself, reminding me about the physical world rather than the world of information.\n\nMany of these moments are felt most strongly when getting ready for sleep. Watching the snow fall outside in the waning light as I sit cozy in a cabin, the only sound coming from the crackling and popping of the fire and the breathing of my family. The stillness and quiet that accompanies a snowfall has a way of putting me at ease better than any meditation ever could. The warmth of a fire and its soft glow activates a mechanism in me that I can only assume to be a primal conditioning that extends to my ancestors thousands of years ago. It tells me to pull my family close and quiet my thoughts and sleep peacefully knowing that I am safe. \n\nOr laying in bed during a thunderstorm with the slow rolling percussion and the brown noise of rainfall is something I experienced many times as a kid. Now those stormy nights transport me back to my childhood. Perhaps it's the knowledge that I am dry and warm and safe that make those nights feel so satisfying or maybe it's just that bedtime is when I had the opportunity to take a breath and exist in the moment. Even waking up on a winter weekend morning to a howling northeastern wind and knowing that I could sleep in and take my time in the warmth of my blankets would fill me with comfort and gratitude. \n\nAnd sometimes a bed wasn't even involved such as the many moments driving home after a long day in the city with my parents and pretending to be asleep in the back of the car so that they would have to carry me inside. I would map out every turn and traffic light and stop sign so that I could pretend to sleep from miles away and still know how close we were to home without needing to open my eyes. And sometimes I would even fall asleep for real only to wake up just before arriving at home but those were the times I had to pretend I was sleeping extra hard. I wasn't going to miss an opportunity to be carried to bed after having legitimately slept!\n\nNot all these moments involve sleep, though. There's something distinctly unique about a hot day at the beach. Running and swimming. Working up a sweat and then washing it off with a dip in the ocean and then drying off in the heat of the sun. But it's the moment after that sticks with me. Heading back to the house and taking an outdoor shower to wash off all the sand and salt. Feeling the lukewarm freshwater clean and cool me down feels like a day well spent. \n\nThere were long summer days without a single responsibility and only a giant book to read were a staple of my childhood. I finished multiple 500-page books on days like that, usually while finding some new way to arrange myself on the couch every hour. \n\nAnd the class right after a big lunch and long recess full of running where I had to prop my head in one hand while leaning over my desk so I could try to pay just enough attention so the teacher wouldn't call me out. It was always these moments when I was physically exhausted and content when I had the most boring classes with a teacher that would drone on and on in just the right way to make me fall asleep. I think the school system designs the curriculum in such a way to be a challenge for students in those moments.\n\nAnd there were the days after the first big snowfall of the year when the snowplows would come down our street and pile snow into big dunes 10 feet high! Gearing up and running out to play king of the hill on those giant snow mounds with my siblings was one of the best parts of winter followed by digging tunnel networks and little caves that we play in and then summarily destroy.\n\nBut perhaps the best feeling is the first warm day of spring. When finally after months of gray skies and biting winds the sun comes out and the breeze carries warm air and suddenly you realize there's been a shift and it's officially spring, regardless of what the calendar says. That day is still my favorite even as an adult and anyone who lives in NYC is acutely aware of it because the whole city seems to go mad with optimism and hope. The energy is palpable and infectious. \n\nSo many of these moments are specific to the weather and the nature of changing seasons and that is perhaps the best blessing of growing up in the American Northeast and being exposed to the ultimate form of each season. As I've grown older I've grown to appreciate it so much more and it's why I do not think I could live the rest of my life in the endless mild spring of a San Francisco.\n\nI'm sure there are many visceral moments such as these that I've forgotten and I hope to experience more as I age. The beauty of these feelings is that they are stored deep within the cells of my body and all it takes is one experience to bring them back to the forefront of my conscious mind. They are not lost. I believe the fullness of a life can be measured by the frequency of these moments and I hope to be able to give my own children these experiences so that they can grow up knowing a world full of wonder and contentment.","src/posts/022-visceral-moments.mdx","ae6ec1eb2013ac0f","cloud-hasnt-been-won",{"id":248,"data":250,"body":256,"filePath":257,"digest":258,"deferredRender":22},{"title":251,"slug":248,"date_published":252,"description":253,"thumbnail":254,"tags":255},"The Cloud Hasn't Been Won",["Date","2024-09-16T00:00:00.000Z"],"Cloud hosting is one of the biggest markets in the world and it's right there for the taking.","cloud_marketshare.jpg",[],"import Aside from '../components/Aside.astro';\n\nMatthew Parkhurst & I founded [Antimetal](https://antimetal.com/) in April of 2022 to bring my vision around \"the Cloud\" to life. I left the company to focus on my health shortly after but it's been fascinating to watch how my thesis has played out over the past two and a half years. I haven't talked in-depth about my original vision since then but I figure now is a good time to put it all in writing as some parts of my thesis have been validated, the market has matured, and there's still plenty of opportunity left.\n\n## Market Context\n\nCloud hosting is a huge market. AWS is at $100B run rate and it's growth is [accelerating](https://www.cnbc.com/2024/04/30/aws-q1-earnings-report-2024.html). Azure is estimated to be around $60B in annual revenue with GCP around $30B. The numbers are astronomical and all the players are growing fast even at their already massive size. You only need to capture a fraction of the market to generate millions in revenue like Vercel who recently reported passing $100m in run rate -- a far cry from the top of the market but still a great outcome for a much newer company with far less capabilities than the top players.\n\nThe growth of the entire market and the sheer size of it make it an attractive area for businesses trying to generate venture-scale returns... and as a result theres many companies trying to do that. To fully understand the landscape of the market and the origin of this thesis you need to understand some of the history.\n\nIn the beginning, any company that used or sold software had to manage its own servers. Entire departments of sys-admins, IT professionals would buy and manage physical servers in a datacenter or often-times in the company's office itself. Engineering teams that wanted to deploy a new service would have to wait for new servers to be bought and installed or if an existing application had a surge in traffic then it became necessary to find extra servers to handle the load. Then came [AWS](https://aws.amazon.com/) in 2006, [GCP](https://cloud.google.com/?hl=en) in 2008, and [Azure](https://azure.microsoft.com/en-us) in 2010 and they exposed their own server hardware running in their data centers through online APIs. What this meant was that if you wanted to host some code you had written you didn't have to go talk to Greg in IT, try to get some server space reserved, and then call Greg again when the machine in your company's basement caught fire. Instead you told AWS you needed a certain amount of compute power, memory, and storage and a couple minutes later you would have that machine up and running in an AWS-managed data center and you could just put your code on it instantly through the internet. They provided Infrastructure as a Service (IaaS) and thus the Cloud was born.\n\nThese early cloud companies owned the full stack from hardware to software and grew rapidly. Today they define what the cloud is and own over 60% of the world's cloud infrastructure. They are commonly referred to as **hyperscalers** because in theory, they have enough compute in their clouds to meet the needs of any given company. If your company managed its own servers and you wanted to deploy a new application they might not have a server for you! It wasn't uncommon to wait weeks to deploy something while new compute was bought and shipped and installed. The hyperscalers on the other hand can scale workloads on demand and as a user of them you can practically assume that there's no limit to how much you can scale as long as you can pay.\n\nThen another group of clouds started to pop up. [Heroku](https://www.heroku.com/) was founded in 2007 and [Digital Ocean](https://www.digitalocean.com/) in 2011 and both of their value propositions were how much _simpler_ they were to use. The hyperscalers were powerful but they were (and still are) [complicated](https://x.com/brianleroux/status/1218252704348172288). Heroku simply ran on AWS and exposed an interface for deploying Ruby on Rails apps in one click (or one git push) rather than the maze of configuration that was required for AWS. Heroku didn't manage their own servers, AWS still did that for them, but they provided a better experience for the end-user than AWS could. They became the first Platform as a Service (PaaS) and quickly came to dominate among smaller companies and indie developers.\n\nHeroku was acquired by Salesforce in 2010 and continued to expand its offerings. It became the gold standard for developer experience but then the Salesforce [rot](https://news.ycombinator.com/item?id=31313779) began to seep in. The company stagnated, eventually began to run into reliability issues, and today is a former shell of what it once was. Heroku is technically still around but for all intents and purposes Heroku, as a platform that aims to grow and capture serious market share, is [dead](https://lancecarlson.com/posts/heroku-is-dead/).\n\nBy 2020 it seemed clear that Heroku was dying and almost everyone was looking for what would come next. And things came. [Vercel](https://vercel.com/home) was founded in 2015, [Fly.io](https://fly.io/) in 2017, [Render](https://render.com/) in 2018, [Porter](https://www.porter.run/) and [SST](https://sst.dev/) and [Railway](https://railway.app/) in 2020. Many of these clouds entered the market with the explicit message that they were the next-generation Heroku and they all had a twist on what made them better. Crucially, all of them are Platforms as a Service with the core idea being they provide a platform for you to deploy and manage your applications while abstracting away the underlying infrastructure.\n\n**This was the context in which this thesis was formed.** The impending death of Heroku could be seen years in advance and yet no obvious successor was crowned even in 2022, leaving us with a real gap in the market for a cloud that was simple to use for startups and individuals. The newer players like Porter, SST, and Railway were all in their infancy so it wasn't clear any of them would be successful and clouds like Fly, and Render were showing traction but still very young and limited.\n\nFurthermore, I felt very strongly that trying to replicate Heroku was not the best way to achieve dominance and that all of these new players could be beaten. Below is my thesis for how and why that could be done. At the end I'll cover a little bit about what has happened since 2022 and how I think my thesis has played out.\n\n## Building a Better Product\n\nBeating the existing players and capturing market share is a simple formula really: build a better product than the incumbents.\n\n\u003CAside>\nSales and marketing matter, of course, but that's because execution as a whole matters when it comes to building a good company. When it comes to the Cloud and selling to developers it's a lot easier to succeed when your product is superior.\n\u003C/Aside>\n\n**Ultimately the quality of a cloud hosting product comes down to 3 dimensions: capabilities, convenience, and price.** As a startup it is difficult to be best-in-class in all 3 categories so how you prioritize those dimensions and solve for the main problems each one poses will shape the type of company and product you build. Every choice will have tradeoffs and those tradeoffs will determine how your platform stacks up against the others. Most players in the space focus on just 1 dimension but if you want to dominate you need to be best-in-class in a minimum of 2 of those dimensions and if you can be the best at all 3 then you may achieve the size of the hyperscalers.\n\nPerhaps my most controversial idea is that if you make the right set of tradeoffs it may be possible to become best-in-class along all 3 dimensions. That's a bold claim but it's one I hope to convince you on and only one of the current companies is even headed remotely in that direction.\n\nHere's how you win on all 3 dimensions.\n\n### Capabilities: An Uphill Battle\n\nFew entrants into the market try to compete with hyperscalers on capabilities because it's by far the hardest and therefore the worst angle to differentiate on. To truly have a capability they do not have usually means running your own servers and running your own servers is hard! Servers aren't software -- they break randomly, overheat, get disconnected, fail for mysterious reasons, and have to exist in a physical location. The sheer amount of work that goes into maintaining and running your own servers means you'll probably spend a lot of your time and resources doing that rather than building a good user-facing product for customers. What ends up happening is you have the bandwidth to beat the hyperscalars on a specific capability at the expense of everything else.\n\nSome companies do try, though. Fly.io differentiated itself by making it extremely easy to deploy containerized applications to an edge network and therefore they run their own servers to create that edge network. And to their credit Fly got a lot of great traction and support but now they're going through a [tough patch with reliability](https://news.ycombinator.com/item?id=34742946) and their product no longer feels like it's on a breakout trajectory like it otherwise could have been. Fly beat the hyperscalars on edge capabilities (although they're all catching up) but in doing so they are more expensive, less reliable, and somewhat of a one-trick pony. If I don't care about edge computing -- and if you're building B2B SaaS you probably don't care about edge computing -- then Fly isn't a super compelling offer.\n\nOf course, a cloud service that doesn't run it's own servers can also suffer on cost and reliability and it's possible that the only way to really make Fly's bet on edge computing work is to own the full stack. That's fine but then it means the success of the company is almost fully on the bet on edge computing and, personally, I think that's a bad bet.\n\nThere are exceptions to this. There are very narrow slices of capabilities that you can only serve by running your own servers and when those opportunities arise it may be a good move. For example maybe you want to provide compute in space or build an entire cloud of GPUs just for AI training or sell to a government that the current companies can't for legal reasons. This may be possible because the market is too niche (space) or because it's too new and you happen to have an edge by already owning a bunch of GPUs, or because of simple regulatory arbitrage.\n\nIn all these cases, though, when you try to compete on capability you'll build for a very narrow -- but potentially lucrative -- capability set at the expense of everything else and if your narrow capability set turns out to be lucrative enough then you can be sure the hyperscalers will use their buying power and economies of scale to provide competitive offerings eventually. It's for this reason that I think it's impossible for a startup to build a truly venture-scale cloud by focusing on hardware-driven capabilities and I'd be very hesitant about any startup trying to that from the outset.\n\nSoftware-driven capabilities are a different story and we'll get to that later.\n\n### Convenience: An Attractive Trap\n\nThe easiest way to beat the hyperscalers is through convenience and this is how nearly every PaaS enters the market. It's how Heroku did it and now it's how Vercel, Railway, Render, Porter, SST, etc are doing it. Take Vercel for example. Their whole cloud runs on AWS but they let you deploy automatically by simply pushing to your main branch on GitHub and they provide templates to make it extremely easy to automatically deploy common JavaScript frameworks. If you use their own framework, NextJS, they can automatically optimize things for you and make it easy to get an app deployed. Even their Edge Network is a simple wrapper on top of AWS Lambda but for inexperienced devs and small teams it's simply easier to use than Lambda because they're already using a framework like NextJS to write their code.\n\nThis strategy makes sense at a high level. Beating the hyperscalers on convenience and developer experience is a good idea because when it comes to those things the hyperscalers tend to be [dogshit](https://x.com/CleanPegasus/status/1820017552980111409). The hyperscalers are basically APIs over physical infrastructure but most companies care more about building their product and solving customer problems than they do about infrastructure so it's an attractive proposition if you can simplify that for them. There is a significant amount of money to be made doing this as shown by Heroku and now Vercel and it's the straightest shot to building a super valuable company.\n\nBut this strategy is a trap for a number of reasons.\n\nBeing more convenient and easy to use usually means being simple. When you look at most of these platforms they are entirely geared towards making the common path for many developers very easy so if you want to deploy a full stack web application it'll almost certainly be easier than just using AWS. But the moment you want to do something outside the beaten path then the simple platform makes it extremely difficult or impossible and as a company grows bigger the likelihood that they need to do something outside the beaten path grows. So what do you do if you're Vercel and your largest customers keep asking you to add more features and configuration options? Either you start to add those features and lose the simplicity that made you popular and gave you an edge or you tell those customers that you will not add those features and live with them churning. If you're lucky they'll seek out a hyperscaler just for that one thing you don't handle but in the common case they'll just move over everything to the hyperscaler because managing two clouds is more annoying that managing one and if you need a hyperscaler anyway then you're past the point of needing simplicity. **You either open yourselves to disruption by another platform that comes along and claims to be simpler and easier than you, or you lose your biggest customers because you couldn't provide the capabilities they need.**\n\nThis actually highlights another big problem with this simplicity-first model: the smaller the customer the more they benefit from simplicity. Your indie devs and small teams probably have one app and are using a common framework to follow the beaten path. The whole point of this model is to make the lives of these customers better but these customers are also the least able to pay. Most indie devs can't pay anything when they start out and small teams who are bootstrapping or just raised a little bit of money cannot pay a lot for just running their app. Heroku and Vercel and most of these tools all have generous free tiers because without a free tier it's quite difficult to win the hearts and minds of these core users. There's an entire cottage industry of influencers talking about how to build things fast and easy and if you don't have a free tier then you won't win over the students and hustlers trying to build their first product. In many ways the entire sales funnel for these simple PaaS offerings rely on a free tier to reduce CAC.\n\nSo you need a free tier and to do that you need to subsidize it by making enterprise plans more expensive. So what you've set up is a system where your customers start out for free and get up and running easy and that's great for everyone involved but as a few of your customers find traction and grow they go past the free tier and require paid plans and as they grow further those paid plans grow in price significantly. By the time they reach the size of a Series B startup they will be spending far more on your cloud than they would if they were on AWS. Eventually it crosses a threshold where it's literally cheaper to just hire full-time dev-ops engineers to manage an AWS instance than it does to use a \"simpler\" cloud. For reference Vercel Functions, which is just a wrapper on AWS Lambda, gives free-tier users 3600 GB-seconds of function time for free. That's great for anyone building a hobby project or just starting out. But once you get past the included free usage they charge $0.00005 per GB-second. AWS Lambda charges you immediately so it's harder to get started with if you can't put down a credit card but they only charge $0.0000166667 per GB-second. Vercel is charging 300% more than AWS just for some simplicity and it only gets worse because the more you use Lambda the _cheaper_ it gets. At the maximum usage tier Vercel is 375% more expensive per GB-second of usage than AWS.\n\n\u003CAside>\nIt's worth noting that this price comparison isn't really apples to apples. Vercel adds more to their functions than just the base Lambda. It would be more accurate to compare the price of Lambda + Shield + Global Accelerator.\n\u003C/Aside>\n\nThis is great for Vercel because they get to make a bunch of money and offer a free tier to their smallest customers which reduces CAC but if you're a startup that finds some success you're going to end up looking at your Vercel bill wondering if it's really worth it to pay over 300% more for the same infrastructure while having fewer capabilities. Between the backwards pricing model and the lack of functionality platforms that focus on simplicity end up **directly incentivizing their most successful customers to churn.** This is the biggest limiting factor for most of the PaaS providers today and it's a dynamic that needs to be resolved if you want to create a new cloud that can eclipse all of the existing non-hyperscalers.\n\n### Price: A Common Painpoint\n\nIf you speak to people who use the Cloud the most common complaint is the price. Early on in the cycle of Cloud adoption there was a lot of talk about how the Cloud was cheaper for companies because they didn't need to buy hardware and hire all these people to manage servers. Most of that sentiment has gone away because it seems that for every individual you could fire that was managing physical servers you now need to hire a DevOps engineer and on a per-unit of compute basis, owning your own server is far cheaper than renting from someone else. Renting just happens to be more convenient than dealing with physical servers so the same way that Vercel is more expensive than AWS because it's more convenient, AWS is more expensive than physical servers because it's also more convenient. It's also elastic and you can scale your compute nearly instantly whereas with physical servers if you get a massive spike in traffic you need to go buy those extra servers, wait for them to ship, install them, etc. And if you want to manage peak loads you then have to own extra servers even when you don't have peak load which is wasteful. With the Cloud you can just pay for extra compute when you need it and then scale back down when you don't. Still, everyone agrees on net the Cloud is expensive.\n\nThe problem is, if you're not going to manage your own servers and you just want to build a PaaS on top of AWS then you can't really charge cheaper prices because that would not make any economical sense. Even if you are going to run your own servers you won't have the economies of scale that AWS has so you also probably won't be cheaper than AWS. It's for this reason that I don't think _any_ non-hyperscaler claims to be cheaper than AWS apart from free tiers for small users. And when it comes to free tiers most don't even come close to the free credits AWS gives out like candy. Just about any company can go and [immediately get $1,000](https://aws.amazon.com/startups?lang=en-US) in free AWS credits and if you're part of an accelerator or have any institutional investors it's usually trivial to get up to $100,000 in free credits. So while not advertised as an explicit free tier AWS does have free perks and it's basically impossible for any competitor, even other hyperscalers to compete on price. If you _could_ find a way to compete on price you'd have a massive competitive advantage.\n\nPricing is the most common complaint and I identified it as one of the main wedges when we started Antimetal. There's a couple ways you can handle pricing to be competitive with AWS. The first way is to let the user bring their own cloud like Porter and SST who don't even have their own cloud and just orchestrate everything within your AWS account. Because it's your account you have full control and if you have free credits from AWS you can just apply them automatically. This is a really good way to pass on cheaper hyperscaler costs to your customers but it means it's way harder to generate usage-based revenue which is how most of the revenue is made for someone like Vercel.\n\nThere's also another dynamic at play. There's the absolute price that something costs such as that calculation above around Vercel vs AWS per GB-second pricing but then there's also the predictability of pricing. So often when people complain about the pricing of the Cloud they are specifically talking about how it's really hard to predict the bill you'll be stuck with at the end of the month. Because billing in the Cloud is usage-based and the whole point of the cloud is that you can scale up and down your usage with ease it's pretty common to end up paying way more than you thought you would have to. It doesn't take very much searching to find numerous [horror stories](https://news.ycombinator.com/item?id=22719573) of small teams or [indie hackers](https://www.reddit.com/r/nextjs/comments/12dngvg/small_mistake_leads_to_3000_bill_from_vercel_and/) hosting a small project that goes viral overnight leaving them with a bill in the tens or even [hundreds of thousands of dollars](https://x.com/zemotion/status/1798558292681343039).\n\nThere's a hidden assumption in here that I'll posit: **companies generally care more about the predictability of cost than the absolute number.** If you can clearly telegraph that a company will pay $X over the next quarter they will probably be happier with that than paying an unpredictable $Y even if Y \u003C X. The hyperscalers generally have some alerts you can set on spend so that when you reach a certain threshold in your budget it sends you some emails but as far as I'm aware there's no hard limits you can set in AWS or any of the clouds to make sure you do not overspend. The spend management experience in the cloud is abysmal.\n\n## New Trends: On Prem\n\nThose were the three big dimensions that really stood out to me back in 2022 but since then there are new trends as well. Specifically how more companies are moving back workloads to their own private clouds. Dropbox is probably the highest profile company to [move off of AWS ](https://www.wired.com/2016/03/epic-story-dropboxs-exodus-amazon-cloud-empire/) and they did it quite a while ago. Since then DHH and Hey have made a big stink of their [cloud exodus](https://world.hey.com/dhh/we-have-left-the-cloud-251760fb) and recent reports claim that the vast [majority of enterprises are planning doing the same](https://datacanopy.com/back-to-private-cloud/). This is almost 100% driven by cost. The cloud _is_ more expensive but it's really convenient and elastic. The thing is most companies don't need super elastic compute! You'd be surprised how even some of the biggest companies in the world really don't get as much internet traffic as you'd think and usually if there are spikes in traffic it's due to predictable demand surges around holidays or other special events.\n\nWhat I predict will happen is that most companies will begin to move some core workloads off the cloud and use the cloud for the workloads that need hyper-critical reliability or are extremely variable in their usage. This needs to be taken into consideration when attempting to build a new cloud platform. Today some of the hyperscalers allow you to connect their public clouds to your private cloud so you can manage workloads across all of them. I predict this sort of functionality will become increasingly important for big companies and I think this type of hybrid cloud will be common enough that a unicorn can be built on catering to this model.\n\nTo my knowledge, only [Oxide](https://oxide.computer/) seems really well positioned to capitalize on this phenomenon as well as the traditional legacy server vendors. The big takeaway in this new dynamic of multi-cloud architecture is you'll need a hardware component like Oxide but also a software component that can make it super easy to orchestrate resources across the multiple clouds. I believe Oxide is trying to also address the software side of things but it's not clear to me if they'll be able to do both because any software solution that's successful probably won't be tied to a specific hardware stack.\n\n## Putting It All Together: The Right Tradeoffs\n\nOkay so I explained these different dimensions and how some of the players deal with them but I mostly just described some of the big problems without describing my solutions. How did I want to approach it with Antimetal? My full vision was a PaaS platform that sat on top of the hyperscalers similar to a Heroku or Vercel. I wanted it to be extremely easy to get started with but contain all the capabilities necessary for enterprise companies. I wanted it to make _more_ sense for an enterprise team than any other PaaS while not being too complex for small teams. And critically, I wanted it to have the best cost-management experience out of any cloud.\n\nOn the pricing side I wanted to implement price controls where a customer could set soft and hard limits on spend for various resources and groups of resources. This would allow us to create an experience where we can show them a distribution of possible spending scenarios with upper bounds on spend for upcoming quarters. These limits would also have powerful rules attached to them where you could decide what to do as the limit was approached whether it was to send alerts, keep scaling under certain circumstances (maybe there's just a spike of traffic for 2 days), or to just let the service fail under load.\n\n\u003CAside>\nEdit: It turns out some of the PaaS services these days do have a concept of spend management: [Vercel](https://vercel.com/blog/introducing-spend-management-realtime-usage-alerts-sms-notifications) [Railway](https://docs.railway.app/guides/optimize-usage)\n\u003C/Aside>\n\nThe second way I wanted to tackle pricing was to take advantage of AWS reserved instances. Reserved instances is where you pay in advance for a certain amount of compute in exchange for discounts up to 60%! Then when you use compute later you can do it from the reserved instance credits you have. The beautiful part about this is reserved instances are relatively low risk, especially as your compute needs grow, because you can resell unused credits. For an individual company just trying to build a product this might be more complexity than it's worth but for a PaaS it makes sense to reserve the compute for a discount and handle that complexity intelligently. What this unlocks is that even if we were to price our product at the same price as AWS' on-demand rate we could still have 60% margins. That's not as good as the 300% that Vercel is getting but it doesn't need to be for the services where you're simply wrapping AWS. I'll explain how we can get higher margins on other services in a moment. The end goal of these two things, though, is we could have a PaaS that basically has price parity with AWS while providing a better cost management experience than any cloud on the market today.\n\nWhen it comes to convenience I wanted an experience that worked for small teams that want simplicity and enterprise teams with complex and bespoke needs. I see only one way to solve this: code. Almost every PaaS platform like Vercel or Railway or Render all revolve around a similar core workflow: you create an account on the platform, you click some buttons to connect your GitHub account to the platform, then you press a big \"Deploy\" button. In the world of enterprise almost no one is deploying software like that.\n\nBig companies use Infrastructure as Code (IaC) tools where you use code to specify of the infrastructure you want whether it's servers or storage or domain names and then you provision infrastructure based on that specification. If you want to add a new server you generally update the spec and then push that change to the Cloud. There's a couple reasons this is preferable to clicking around in a dashboard. The first is that it's reproducible. Because it's code that's written down, if all your infrastructure gets deleted for some reason you could in theory just run the code again and bring your cloud back to the desired state. This is super useful if you want to make sure that your development or test environment matches your production environment and stays in sync. Another reason this is helpful is once it's written down you can version it automatically because your codebase is already being versioned anyway. If someone makes a change that breaks some infrastructure in theory you can find which change created the break and then rollback that change easily. And lastly, if you want to change a bunch of resources all at once -- such as changing all your bucket names to have a certain prefix -- you can do that a lot easier in a code editor than clicking around a dashboard.\n\nOkay, so what? Well, if you want a platform that works for big teams you need to have first-class support for IaC and it just so happens that if you want to allow multiple levels of complexity in one product then code is the best way to do that! Let's say you're a small team and you literally just want to deploy your NextJS app. A PaaS that offers IaC might let you do that like follows:\n```javascript\nconst domain = new CustomDomain({\n\t...\n})\nconst site = new NextJSApp({\n\tname: \"my-next-app\",\n\tdomain: domain\n})\n```\n\nThat's pretty simple! That would be very easy for any small team or even an individual developer but let's say now you're working on a big team that's using NextJS and wants a lot more control over how it's deployed. Well you could do something like:\n\n```javascript\nconst domain = new CustomDomain({...})\nconst queue = new Redis({...})\nconst cdn = new CDN()\nconst site = new NextJSApp({\n\tname: \"my-next-app\",\n\tdomain: domain,\n\tfunctions: {\n\t\truntime: \"edge\",\n\t\ttimeout: \"15m\",\n\t\tmemory: \"512mb\",\n\t},\n\tcdn: cdn,\n\tqueue: queue\n})\n...\n```\n\nOr you can go even lower level and have more control:\n\n```javascript\nconst vpc = new VPC({...});\nconst storage = new DurableStorage({\n\tsize: \"16gb\",\n\t...\n})\nconst vm = new VM({\n\tmemory: \"4gb\",\n\tvcpu: 2,\n\tstorage: storage,\n\tvpc: vpc,\n\tscaling: {\n\t\t...\n\t}\n})\n```\n\nThis is all half-baked pseudocode to illustrate a point: when you're specifying things in code you can have multiple interfaces for the same thing and you can make one interface have multiple levels of complexity. You can make it so if all someone wants to do is tell you the domain to host their app on you can figure out the rest for them just like Vercel or Render would do but if they want more control they can just start configuring more of the options. You can also have a concept of primitives that build up to higher level concepts. For the power users in big companies you give them primitives to configure VM's with exactly the memory and compute power they want and allow them to configure all the networking rules, etc. For the simpler user you give them a construct like `NextJSApp` which is simple but under the hood it just provisions a VM with NodeJS and handles the configuration for them.\n\nThis is such a powerful way to manage infrastructure that it's a real shame more PaaS platforms don't do this by default. The way I see it, this _has_ to be a first class citizen of a platform to be viable for enterprise customers but I wanted to go as far as making our dashboard completely read-only. I was not going to let people provision or deploy things by clicking on a dashboard and instead provide super easy recipes and starter templates and helpers with a CLI for all the common frameworks. It's kind of funny that most PaaS platforms don't do this. I wonder if they just think their target customers would be scared off by code but for anyone who's done any sort of serious programming they'll know this is preferable to clicking around a dashboard. You get type-safety, the power of your editor's auto complete, and every other benefit of IaC.\n\nI believe any cloud that started with these two solutions for convenience and price controls would be competitive very quickly. It would be a platform that can scale and work for large teams as well as small ones.\n\nBut it doesn't have to end there. Let's talk about capabilities. Earlier I mentioned how difficult it is to compete on capabilities because it usually means running your own servers and dealing with hardware is hard. You can however compete on software capabilities and improve the margins by doing so.\n\nLet's look at an AWS service like RDS (Relational Database Service) as an example. RDS is how most companies run their database on AWS but under the hood it's really just a combination of other AWS services. It uses their ec2 VMs, their storage, and then some software to orchestrate all that to make it useful for database management. I don't say that to mean it's a simple service -- RDS is incredibly complex and extremely valuable -- I am simply illustrating that just how you can combine primitives in the IaC spec you can combine cloud primitives with software to create new services and capabilities.\n\nEvery SaaS company needs a number of capabilities that are serviced by various other entire companies but they don't need to be. You can have an Auth service and an Email service and a feature flag service, etc.\n```javascript\nconst emailProvider = new cloud.Email(\"MyEmail\", {\n\tsender: \"example.com\",\n\tdmarc: \"v=DMARC1; p=quarantine; adkim=s; aspf=s;\"\n});\n```\n\nUse the hyperscalers for their base infrastructure and accept lower margins when wrapping that but write your own software to power higher-level services and charge more for those. Simply wrapping AWS Lambda? Don't mark it up by 300% like Vercel. But do you have an Auth service that customers can provision which is just a number of Lambda functions under the hood for performing token exchanges? Charge more for that.\n\nYou can create a platform where any sort of primitive a SaaS company might need they can have and it would be as easy for them to use as simply adding another few lines to their infrastructure spec. And because these services aren't simple wrappers over AWS you can charge more for them. Eventually you have a cloud that isn't just the easiest and best place to deploy your code but also the best platform for building a company.\n\nYou don't even necessarily have to build all these services yourself! AWS has a concept of a marketplace where you can buy software but it probably doesn't work how you expect. You can buy software there but it's usually just a funnel to get you into the sales org of the respective company. You don't actually get the software in your own AWS account you usually just get the lowest-tier license. This model can be improved upon. Any SaaS app that is hosted on your cloud could technically be made into a standalone service because it would exist as an IaC spec which is a combination of your core primitives plus some extra software on top. These SaaS providers could then list their apps on a marketplace and anyone else using your cloud could buy it and **have it deployed to their own accounts.**\n\nThis happens today when enterprise companies ask SaaS vendors to self-host their products and I've seen multiple companies spend years refactoring code to enable that and usually even dedicating a percentage of ongoing engineering time to just maintain and support those self-hosted instances . Imagine a world where standing up a new service in your own cloud tenant was as simple as signing a contract on the marketplace. The cloud could manage the contract, the payment, and the provisioning. The cloud could expose granular cross-tenant permissions so that support engineers from the vendor could go modify or observe that specific service in the customer's tenant when appropriate.\n\nI really think this is an underrated effect of all of this and it's something that should really be it's own blog post. To really understand just how impactful this would be you have to be able to think about 2nd and 3rd order effects of a platform that does everything with IaC and provides the right primitives to combine. If it became extremely easy to provision complex SaaS services into customer tenants while still enabling support and DRM and contract enforcement you could drastically change the business model for the tech landscape. Companies could change how they do procurement and sales to be far more streamlined and efficient. If, as a SaaS provider, you're not running the compute for your customer you can experiment with different business models because your COGS would be far lower. Even the way apps are built could be simplified if you knew that the app would always run in a tenant isolated by the cloud itself. You could even experiment with things like Software as a Product instead of as a Service because in theory there's no reason different tenants can't be running different versions of the same product meaning it would be viable to charge people one-time prices for different releases. Many things would change if a cloud platform was capable of supporting this.\n\nThis is the only way I can imagine a PaaS that doesn't manage its own servers to compete on all dimensions. There's even some things I left out. For example, I think customers should be able to bring their own cloud so they can take advantage of better cost savings and they don't need to churn just because they got bigger. I also wanted to allow the connection to GCP and Azure as well as AWS and make it relatively seamless to manage infrastructure across them which would be useful for giant companies that are adopting a multi-cloud strategy. Once again, IaC makes that easy for the user and this could even allow for private cloud integration as long as a company's private servers expose a certain interface.\n\nUltimately these are not easy ideas and anyone who tries to build something like this needs to be prepared for a long road but in my opinion it's the best way to build a generational company in the cloud. There are certainly going to be pitfalls and things that make this approach extremely difficult but in my opinion it's really the only way to get the optimal tradeoff along all 3 dimensions and I think it's the tradeoff that allows someone to build a better cloud than anything that exists today.\n\n## How It's Playing Out\n\nWell, Antimetal went in a slightly different direction than what I originally had envisioned but I think that was smart of them. To implement price controls and create a better spend experience in the way I envisioned I needed to have a platform in the first place. Matt, my ex- cofounder, found a better way. He said to hell with having an actual cloud and just went ahead and built a platform that sits within your own cloud and orchestrates reserved instances for you so that you can get cost savings. This was a genius move because it meant they could avoid all the complexity of building a PaaS and just focus on selling a product where they only make money if they save their customer money. That tends to be an easy business model to sell and now they are installed in hundreds of customers' clouds earning their trust and gaining momentum. I don't know if they want to even branch out into the PaaS model at this point and I don't even think it would make sense for them to do so but they would be in a pretty good position if they tried.\n\nBesides Antimetal, it appears that Vercel is winning in the short term as the PaaS of choice for many. I'm skeptical of Vercel, however. The vibes feel off, React and NextJS seem to be undergoing somewhat of a schism within the community, and I think many people feel that Vercel does not tend to act in [good faith](https://x.com/thdxr/status/1780710481084432849). They are in the lead amongst PaaS platforms but $100 million in revenue is far from $100 billion in revenue and I still fundamentally think the way they've created their product for ultra simplicity has put a very big ceiling that will be hard for them to break out of. Most companies that will pay a lot for cloud hosting do not care about 1-click deployments through a dashboard.\n\nIn my opinion edge computing is also turning out to not be a really good bet and I feel validated in that. There are some operations that work well on the edge but any operation that needs to rely on a database in a central location nullifies the entire benefit of the edge. There are new serverless database offerings that are growing in popularity, though, so it's possible that this calculus changes over time. Still, if you're building a B2B SaaS then 30ms ping vs 120ms ping isn't the difference between your company's product getting customers or not. It seems quite clear to me that if performance really matters for your application you're better off just doing local-first with a smart sync engine than using the edge and if performance doesn't matter that much then you don't need the edge.\n\nAnd that brings me to SST which is the only player in the space building something that aligns with what I had in mind. This is not an ad for SST I just get excited about it because their founders seem to really [\"get\"](https://x.com/thdxr/status/1830990051322237260) what I had in mind 2 years ago. Remember that example code snippet I used up above to illustrate how you could theoretically let someone send emails from within their product? That's actually a [code example](https://sst.dev/docs/start/aws/email/) from SST! To deploy any infrastructure with SST you need to define it in a type-safe IaC specification built on top of the [Pulumi](https://www.pulumi.com/) engine. They've created shims on top of AWS and Cloudflare providers in Pulumi to allow for a simpler interface for many of the services while still letting you set basically any complex configuration if you want to.\n\nThey also let you seamlessly deploy to multiple clouds at once because of their use of IaC! Here's a snippet creating an email provider in AWS and configuring it's dns to use Cloudflare. Do you know how wild it is to be able to deploy this sort of configuration this easily?\n\n```javascript\nexport const email = new sst.aws.Email(\"Email\", {\n  sender: domain,\n  dns: sst.cloudflare.dns(),\n});\n```\n\nAnd because they're using Pulumi and simply deploying resources to your own AWS instance any capability that they do not provide with the SST provider you can still use with other Pulumi providers. You can even orchestrate your other SaaS tools like Stripe and then link them to your resources. No fiddling with the Stripe dashboard to set up a new webhook anymore.\n```javascript\nimport { domain } from \"./dns\";\n\nsst.Linkable.wrap(stripe.WebhookEndpoint, (endpoint) => {\n  return {\n    properties: {\n      id: endpoint.id,\n      secret: endpoint.secret,\n    },\n  };\n});\n\nexport const webhook = new stripe.WebhookEndpoint(\"StripeWebhook\", {\n  url: $interpolate`https://openapi.${domain}/hook/stripe`,\n  metadata: {\n    stage: $app.stage,\n  },\n  enabledEvents: [\n    \"payment_method.attached\",\n    \"payment_method.detached\",\n    \"payment_method.updated\",\n    \"product.created\",\n    \"product.updated\",\n    \"product.deleted\",\n    \"price.created\",\n    \"price.updated\",\n    \"price.deleted\",\n  ],\n});\n```\n\nI've never seen ergonomics this powerful from a PaaS but it's really an obvious conclusion when you think about the 2nd and 3rd-order effects of IaC and the cloud.\n\nStill, there are open questions to me about their success. For one it's not clear to many how they make money because their entire platform is open source and they run all the services in your cloud so they don't host anything themselves. From what I gather they charge for parts of their [Console](https://sst.dev/docs/console/#pricing) product which makes it easy to view and manage deployments (also, notice how their pricing gets cheaper the more you use the product, just like AWS). This is pretty limited monetization, though, and so if I had to guess at revenue I'd imagine they're lower than the competitors. This means they're not raising tons of money and instead they seem to want a lean and independent team with a long time horizon. I personally like that style of work but building a cloud platform that can do a billion in revenue one day is a really hard thing to do and part of me wonders if it's just too _big_ to do if you aren't going to go the typical VC hyper-growth route. Then again, it's possible that by taking the approach they're taking they can more easily avoid the local minima that the other platforms fall into. Only time will tell.\n\nThe last two things they have going against them are that they are very focused on the serverless aspect of the cloud. This _may_ be a good long term bet and I sometimes marvel at how simple it makes things when digging through example apps built with SST but at the same time there's so many open questions around serverless. I hear so many horror stories about people accidentally racking up bills, misconfiguring lambdas and getting charged for IPs, etc. I want more confidence that what I'm doing with serverless is best practice and I want more insight into how much things will cost and how to avoid blowing my own foot off. Part of this might just be better documentation or maybe it is creating primitives that let you set spend limits but overall I do wonder if this positioning holds them back. It should be noted you don't _need_ to use lambdas to use SST and they support deploying containers and, again, you can always deploy raw ec2 instances using Pulumi but still most of their branding is around serverless so they will be associated with the vibes of serverless and right now it seems to be a buzzword with mixed feelings amongst devs.\n\nAnd the last big problem facing SST is that it _is_ too complex for beginners. I can't imagine how many users they lose at the top of the funnel when those prospects realize they need to create their own AWS account, [configure it a certain way](https://sst.dev/docs/aws-accounts/), write code, and only then will they be able to try SST. That's too much overhead. SST should really create a shared managed tenant where someone can go to the SST website, create an account, connect to a GitHub repo and then have a default SST spec opened as a PR in that repo automatically and deployed to a common AWS instance that SST manages. That would allow them to have an experience on par in simplicity to Vercel and it would give them the opportunity to charge users for more than just support. Most users would eventually bring their own cloud and that's okay! But you can't underestimate the power of a sales funnel like that.\n\nSo two and a half years later the space is still as fascinating as it was before. It's matured a lot and there's a ton of really interesting players but SST is the only one that has me really excited, especially with the release of their v3 platform, Ion. I'm also keeping my eye on Oxide because they could potentially be the biggest beneficiary to the movement to repatriate workloads but guess what? The best way to help companies orchestrate infrastructure across multiple clouds, including private ones, happens to also be what SST is doing. Ultimately I think it's still anyone's market and no one is invincible and I'm extremely excited to see how it plays out in the coming years.","src/posts/023-cloud-hasnt-been-won.mdx","b9d936afbe04ab14","ai-hasnt-helped-most-engineers",{"id":259,"data":261,"body":267,"filePath":268,"digest":269,"deferredRender":22},{"title":262,"slug":259,"date_published":263,"description":264,"thumbnail":265,"tags":266},"AI Hasn't Helped Most Engineers (yet)",["Date","2024-12-18T00:00:00.000Z"],"Most of the productivity gains from AI and other DevTools of the past decade have not made their way to the engineers working on large, mature codebases. If we want to make our biggest companies more productive we need a better system of record for the engineering org.","ai_help.webp",[],"The [F-35](https://en.wikipedia.org/wiki/Lockheed_Martin_F-35_Lightning_II) is one of the most advanced man-made machines ever created. It can fly at 1.6x the speed of sound, is virtually undetectable by radar, can hover in place, and provides a total 360-degree field of view to the pilot.\n\nIt's a marvel of human achievement, but it‚Äôs constantly plagued by [delays and cost overruns](https://www.reuters.com/business/aerospace-defense/us-resumes-taking-f-35-after-delays-over-software-upgrade-2024-07-20/). A common source of the issues? Software.\n\n> _\"The hardware of [[Technology Refresh-3](https://www.lockheedmartin.com/en-us/news/statements-speeches/2024/lockheed-martin-update-on-f-35-technology-refresh-3.html)] seems to be coming along fine but the software is lagging,\"_\n>\n> _‚Äî Secretary of the Air Force Frank Kendall_\n\n**How can it be that the most advanced machine on earth is delayed because of software?** How is it that, time and time again, it's harder for companies to write competent code than it is to literally fly humans faster than the speed of sound?\n\nThis is the epitome of the [Software Crisis](https://olivergilan.com/blog/software-crisis/).\n\n_Despite all intuition to the contrary, it appears to be harder for us as a civilization to build in the world of bits than in the world of atoms._\n\nAnd, most of our progress in developer tooling and AI hasn‚Äôt done much to change this. It‚Äôs not like there hasn‚Äôt been progress in developer tooling. It's never been easier to start a project and go from 0 to 1 ‚Äî a solo developer can spin up new projects faster than ever with AI-powered text editors, robust UI libraries, one-click deploys, auth in a box, and Stripe ‚Äî but none of those productivity gains have made their way to teams working in big companies.\n\nThe senior engineer working on a 10-year-old codebase at a Fortune-50 insurance company or the engineer writing software for our nation‚Äôs military is stuck in an unproductive past.\n\nOur DMVs need software. Our financial institutions need software. Our cars and planes need software. Our schools need software. Our farms need software. Our logistics companies need software. We'll only see the AI's full impact on technology and society when we can find a way to drive productivity for engineers working on these kinds of large, mature codebases.\n\n## How We Got Here\n\n**The software development lifecycle happens across the local development environment, repository environment, and runtime environment.**\n\nMost of the last decade's developer tools fall into the first layer: new JavaScript frameworks, terminal emulators, text editors powered by AI, code-gen chatbots, and more.\n\nTools like [Vercel‚Äôs v0](https://v0.dev/) can help create complex user interfaces with AI (which is great if you‚Äôre working on a greenfield project using NextJS) but a principal engineer at a company like Chase Bank does not build new UIs often ‚Äî let alone with a framework like NextJS. They probably just finished a multi-year project to upgrade some COBOL service to use Java 8, which they‚Äôll be sticking with for another decade (at least). Tooling in the first layer makes for great demos, but it often doesn‚Äôt help engineers working on mature systems.\n\n**A senior engineer working in a big company usually spends way less time writing code and way more time managing a living codebase:** reviewing code, responding to outages, maintaining code quality, focusing on architecture, keeping dependencies up-to-date, optimizing hot paths, engaging in large-scale refactors/migrations, and overcoming coordination problems throughout the org. We need DevTools to make this type of work 10x easier.\n\nSome of this work has been improved by developer tooling in the third layer (with the Cloud, observability platforms, infrastructure-as-code, etc), but, frankly, it hasn't changed enough (partly because of hyperscalers' complexity and the fragmented ecosystem of complementary tools). This layer has had less impact on productivity than one would expect.\n\nIn other words, we need a lot more innovation in the second layer of development ‚Äî the repository. **The repository is the canonical source of truth and the common denominator for an engineering organization.** It‚Äôs where code changes are reviewed, issues discussed and prioritized, deployments orchestrated, dependencies managed, and where most of the work on a mature codebase is done. We need to make the repository itself far more powerful than it is today if we want to significantly improve the productivity of engineers managing large codebases.\n\n## The Repository as a Living Codebase\n\n**Today, the moment a line of code gets merged into production, it begins to rot.** We don't think about this much when building greenfield or hobby projects but when you're working in a legacy codebase, you feel this pain. Every line of code has a maintenance burden and a debt associated with it. Senior engineers are paid to suffer with this.\n\nConsider the engineer who needs to upgrade Java versions or update a dependency to get the latest security updates. Or the senior engineer called in to fix a flaky CI test when no one else can. These problems don‚Äôt affect greenfield projects, but they almost universally eat up significant time in any mature codebase.\n\nRepositories should be full of agents working constantly in the background, analyzing the codebase and all of its activity while opening up PRs that address most of the maintenance work. They should scan codebases for known bad patterns and write fixes for them. They should find outdated dependencies or ones with security updates and do the work to update them and handle any necessary refactors. If there's a need to migrate Java versions or migrate a service from one language to another or break up a monolith, agents should help plan (and implement!) the changes.\n\n**Repositories should be alive by default.** Code shouldn't fall into disrepair simply due to time.\n\n## Reducing Toil\n\nSometimes working on a mature codebase is slow because the problems are hard and sometimes it‚Äôs slow because there‚Äôs just so much _toil._ There‚Äôs so much toil in the average enterprise codebase that most engineers have [schlep blindness](https://paulgraham.com/schlep.html) to their daily work.\n\nI‚Äôve been on teams where CI times took nearly an hour and then we started having flaky tests so it was common to wait 40 minutes to merge a PR only to have the test suite fail and require a re-run. Sometimes the toil is simply trying to download the context of a big PR so that you can review it effectively while navigating through a sea of formatting changes and other noise unrelated to the core changes in the PR. Enforcing smaller, [stacked PRs](https://www.stacking.dev/), can help the reviewer but that often just shifts the toil onto the author to find the right pieces to pull out of a branch into another, rewrite commits, etc. If you‚Äôre an open source maintainer your toil probably involves managing the inflow of user-submitted Issues, prioritizing real problems, filtering out duplicates, labeling issues correctly. Sometimes the toil is simply co-ordination related and not knowing who to assign to a PR whether that means finding the person on your team with the most bandwidth or finding an appropriate person to tag from a sister team.\n\nIn the same way that the repository should be intelligent enough to help maintain a codebase the repository plays a critical role in reducing toil when working collaboratively on a team. The repository should have agents identifying and fixes flaky CI tests, optimizing CI times, and improving test coverage. It should be dead simple to split up large PRs into smaller separate PR stacks that can be reviewed faster (it should even detect formatting or irrelevant changes and offer to automatically extract those into a separate PR). It should have agents suggesting fixes automatically for any nitpick comment so the author can just one-click approve them. It should be easy to automatically route PRs to the teammate with the smallest current workload (which can be determined a number of ways) or tag the most relevant engineers to review specific files. It should flag potential duplicate Issues, help label and triage them, and even solve small Issues when possible. It should summarize long discussion chains on contentious Issues, highlighting proposed solutions and important points from each side, so maintainers can stay caught up easier. It should reduce toil around communication overhead by presenting an intelligent Inbox so it‚Äôs always clear what PRs are blocked on your review, which Issues are the most contentious, what tests cases are flaking the most, what parts of the codebase are causing the most error logs, etc.\n\nMost codebases are large interdependent systems with complex state that can behave in unexpected ways. The repository should be smart enough to recognize these moving pieces and reduce the toil that naturally arises from it so that engineers can spend more of their time on the interesting problems they were hired to solve.\n\n## The Repository as the System of Record\n\nThe repository layer is more than just the lines of code in text files. **It‚Äôs a system of record that operates across all the different codebases in an organization, enforcing team processes, facilitating co-ordination, and serving as the source of truth for the various services and products being built and operated.**\n\nTo be maximally effective, the repository needs to have context of far more than just the code. It should be aware of the issue management system and its work items, team compositions, code ownership, CI pipelines, deployment environments, and other external systems that eventually derive their behavior from the codebase.\n\nGitHub, the leader in the space, only has a faint concept of different deployment environments and repository secrets. It doesn‚Äôt have any understanding of feature flags or other configuration options that might affect a program when it runs. Only open-source projects use GitHub Issues to manage their work items and most people use external services that add weak integrations to GitHub themselves. Its CI platform is a bunch of untyped YAML actions [riddled with security vulnerabilities](https://cycode.com/blog/github-actions-vulnerabilities/) that aren‚Äôt easy to test or debug and even simple pipelines workflows like staged rollouts or rollbacks can be a pain to implement. Despite the common case of microservices it has no concept of multi-repository PRs or Issues and co-ordinating across team and codebase can often be a real challenge.\n\nThe more parts of the software development cycle that can be version controlled and meaningfully tied into the repository with deep linking the more effective automation can be. If tickets originate in the repository instead of being linked to PRs once they‚Äôre done then an intelligent repository could plan and scaffold an implementation. If feature flags and environment variables are version controlled you could more easily track down the cause of bugs that may not correlate with recent commits. If infrastructure footprints are linked to the repository it becomes easier to generate and optimize deployment pipelines.\n\nI don‚Äôt believe the only solution is to rebuild all of these products internally but instead, a successor to GitHub will need to be proactive about building integrations with the surrounding ecosystem instead of waiting for everyone to integrate with it. It‚Äôll have workflows and connectors designed to pull in data from other tools so that all the context of a living codebase can be tied back and version controlled effectively. In doing so the repository can finally become the proper system of record engineering teams need.\n\n## The Next Generation of Repositories\n\n**The company that solves those problems laid out above will look a lot like GitHub, just better in every way. It‚Äôll have a lot of the same primitives: pull requests, issues, CI, etc. but every part of it will be _smarter._**\n\nPull requests will be simplified, stacked, and cleaned up by agents before a human reviews them. Issues will be triaged, categorized, and de-duplicated before a maintainer has to look at them. In some cases an agent will even open a PR to solve an Issue on its own. The repositories will have a concept of linking and pull requests, Issues, and CI runs will be able to span multiple repos for various workflows. Environment variables and secrets will be completely manageable alongside the repository with versioning and branching support. 2-way sync will enable local-first realtime collaboration for every part of the platform so that engineers are empowered to work on things synchronously and improve feedback cycles. It‚Äôll integrate with local environments to enable fully reproducible development environments that can be spun up and collaborated on for specific features or changes. Complex git operations that allow you to maintain a clean history will be made easy and even root causing errors will be simplified. Agents will constantly scan codebases to find bad patterns or outdated dependencies and resolve them. Long running initiatives like refactors will be spearheaded and augmented by agents working in realtime with human engineers. I predict agents will even be able to ingest logs to update repository linting rules and best practices to help eliminate classes of bugs that repeatedly appear. _Nearly every part of the platform will be extensible via built-in and custom agents._\n\n**Mesa is building towards this future and if that excites you please reach out.** Realizing this vision means tackling a variety of technical challenges such as building RAG systems to power intelligence on multiple codebases with current SOTA models, backend systems design to build low-latency scalable git servers, sync engines for performant local-first clients with realtime collaboration, and product design so that a highly technical product can be both approachable and easy to use while containing depth of functionality.\n\nIf any of these problems excite you, and you want to change the way massive teams build software you can reach me at oliver@mesa.dev","src/posts/024-ai-hasnt-helped-most-engineers.mdx","3278ceb750fc57e9","resetting-the-frame",{"id":270,"data":272,"body":277,"filePath":278,"digest":279,"deferredRender":22},{"title":273,"slug":270,"date_published":274,"description":275,"thumbnail":73,"tags":276},"AI requires resetting the frame",["Date","2025-08-03T00:00:00.000Z"],"In a world where intelligence is too cheap to meter, is the generic chat box the final UI? I argue that the best products of this generation will go deeper, and reset the frame entirely on workflows.",[],"import Figure from '../components/Figure.astro';\n\nEvery company in the world is thinking about how to add AI to their existing products and new products built from scratch. With intelligence too cheap to meter, you'd think we'd be seeing deep integration into existing products and novel user experiences but instead we find that most companies are converging on the same [simple](https://www.figma.com/make/) [app](https://www.airtable.com/platform/app-building) [builders](https://www.canva.com/).\n\n\u003Cdiv class=\"two-columns\">\n\u003CFigure src=\"/images/figma_make.png\" alt=\"Figma make chatbox\" />\n\u003CFigure src=\"/images/canva_make.png\" alt=\"Canva app builder\" />\n\u003CFigure src=\"/images/airtable_make.png\" alt=\"Airtable app builder\" />\n\u003CFigure src=\"/images/codegen.png\" alt=\"Codegen\" />\n\u003C/div>\n\nIn a way, the chatbox is the pinnacle of UX design: a dead simple canvas with infinite possibility. Why even bother with product design if you can just talk to an agent and ask it to make the company's stock go up by 10% next quarter?\n\nMaybe we get that future but, for now, I'll take the other side of that bet. The products that define the next decade will be those that deeply integrate AI into their user experience beyond just a chat box. These products will have designers deeply embedded in engineering and product teams, working closely with users and builders to re-think fundamental workflows to build novel user experiences.\n\n## Infinity as a Constraint\n\nAI provides too many open-ended possibilities, both today and for the future. It's difficult to figure out how to deeply integrate AI into existing products and workflows in ways that will 10x the user experience and it's even more difficult to know if that integration will make sense in the future.\n\nA year ago the LLM models on the market had a fraction of the power and intelligence of the current models. It's wise to expect another jump in capabilities in the coming years -- or not. No one really knows where things are headed and the massive error bars around any prediction regarding LLM progress makes it difficult to take big bets on an opinionated product direction. Any work to deeply integrate an LLM today may find itself outdated in a year, and actually hindering the adoption of a newer, better model.\n\nCompanies are shipping chat boxes because they don't know what else to ship. The chat box is unopinionated and becomes more powerful as the models become more powerful.\n\nAnd yet, these models aren‚Äôt infinitely capable. The chat box is oppressive in its limitless possibility. Perhaps if the models were capable enough to handle infinity it would be a more respectable user experience but as they stand today, AI benefits from constraints and guardrails, as do humans. Users don't want infinity, they want well-designed tools, and constrained sandboxes that allow them to use those tools effectively to solve their problems.\n\nIt's these unopinionated chat boxes that will get steamrolled by the models as they improve and it's the products that take an opinionated bet and provide a deeply well-thought out user experience that endure deep into the future. So how can we intelligently take that bet?\n\n## Functional Ergonomics\n\nFunctional ergonomics is all about how easy it is to do what you want to do as a user. The ergonomics of your product is the most important factor for designing a great user experience.\n\nThis means a lot more than having a simple or pretty UI. Having good ergonomics means understanding your users and their problems and tailoring the software to them.\n\n- If your users handle large datasets, do your data tables support bulk actions?\n- If you're building a developer tool do you have keyboard shortcuts? Do you integrate into existing stacks easily?\n- Do users frequently open multiple tabs just to compare data in separate deeply-nested, normalized views?\n- If it's a collaborative product, do you support multiplayer editing?\n\n_This_ is the heart of good UX and it's, unsurprisingly, the least likely to be solved by formula. Performance can be measured easily, aesthetics can improve with some basic principles, but it's up to you to do the hard work of understanding your users and their problems and then make it easy for them to solve their problems.\n\nWhen companies like Airtable or Figma release a chat box to generate some vibe-coded slop, they're being lazy. Both of these companies have become billion-dollar businesses off the success of wildly novel and complex products that re-defined the user experience for their respective workflows. Instead of adding depth to their existing products through AI, they've shipped the lowest common denominator.\n\n## Resetting the Frame\n\nGreat functional ergonomics comes from resetting the frame. The opposite of the chat boxes are the [horseless carriages](https://koomen.dev/essays/horseless-carriages/) most companies are building by shoving AI into existing workflows as a tacked-on sidebar or chat overlay.\n\nAt [Mesa](https://mesa.dev) we're building real-time collaborative code repositories that allow engineering teams to use AI agents throughout the SDLC. We started by building a Pull Request review agent and UI but as agents continue to get better we keep asking ourselves: _‚Äúwill pull requests even need to exist as a concept in a couple years?‚Äù_\n\nThe current frame says: _how can we use AI to review pull requests?_ Resetting the frame says: _do pull requests as a concept even make sense anymore?_ Users don‚Äôt care about pull requests, they care about change control. Enforcing quality, security, and organizational standards at the point where changes are introduced into the system. With AI, can we achieve these goals without pull requests altogether?\n\nThe biggest challenge in product design today isn't figuring out how to design a specific workflow, but figuring out which workflows even need to exist. Every product is asking these questions now. The lazy answer is to build a general purpose chat box, but the products that define the next decade will take an opinionated bet and build products with emergent properties that become more than just a great LLM and great traditional software.\n\nAt Mesa we're building a deep user experience. We have a strong thesis on where these models are heading and we are building the best possible user experience for humans working with these models in the realm of software development. If you're a designer or engineer and you want to take part in resetting the frame for software development, reach out: oliver@mesa.dev","src/posts/025-resetting-the-frame.mdx","109ac428222ec4f5"]